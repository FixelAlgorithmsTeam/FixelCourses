{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io/)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## UnSupervised Learning - Anomaly Detection - Local Outlier Factor (LOF) - Exercise\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 27/02/2023 | Royi Avital | First version                                                      |\n",
    "|         |            |             |                                                                    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethods/2023_01/0045AnomalyDetectionLocalOutlierFactorExercise.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import math\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "DATA_FILE_URL = r'https://github.com/FixelAlgorithmsTeam/FixelCourses/raw/master/DataSets/NewYorkTaxiDrives.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixel Algorithms Packages\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection by Local Outlier Factor (LOF)\n",
    "\n",
    "In this exercise we'll use the LOF algorithm to identify outlier in a time series data.  \n",
    "The data we'll use is the number of taxi drives in New York City at 01/07/2014-01/02/2015 (Over 6 months).\n",
    "\n",
    "In this notebook:\n",
    "\n",
    " - We'll build a time series features.\n",
    " - Fit the LOF model to data.\n",
    " - Visualize outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Feature Generation\n",
    "lWinLength      = [12, 24, 48, 12, 24, 48, 24, 48]\n",
    "lWinOperators   = ['Mean', 'Mean', 'Mean', 'Mean', 'Standard Deviation', 'Standard Deviation', 'Standard Deviation', 'Median', 'Median']\n",
    "\n",
    "# Model\n",
    "#===========================Fill This===========================#\n",
    "# 1. Set the parameters of the LOF Model.\n",
    "# !! Tweak this after looking at the data.\n",
    "numNeighbors        = ???\n",
    "contaminationRatio  = ???\n",
    "#===============================================================#\n",
    "\n",
    "# Anomaly\n",
    "#===========================Fill This===========================#\n",
    "# 1. Set the threshold for the LOF score.\n",
    "# !! Tweak this after looking at the data.\n",
    "# !! Use the guidelines as studied.\n",
    "lofScoreThr = ???\n",
    "#===============================================================#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def PlotScatterData(mX: np.ndarray, vL: np.ndarray, hA:plt.Axes = None, figSize: Tuple[int, int] = FIG_SIZE_DEF, markerSize: int = MARKER_SIZE_DEF, lineWidth: int = LINE_WIDTH_DEF, axisTitle: str = None):\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = figSize)\n",
    "    else:\n",
    "        hF = hA.get_figure()\n",
    "    \n",
    "    vU = np.unique(vL)\n",
    "    numClusters = len(vU)\n",
    "\n",
    "    for ii in range(numClusters):\n",
    "        vIdx = vL == vU[ii]\n",
    "        hA.scatter(mX[vIdx, 0], mX[vIdx, 1], s = ELM_SIZE_DEF, edgecolor = EDGE_COLOR, label = ii)\n",
    "    \n",
    "    hA.set_xlabel('${{x}}_{{1}}$')\n",
    "    hA.set_ylabel('${{x}}_{{2}}$')\n",
    "    if axisTitle is not None:\n",
    "        hA.set_title(axisTitle)\n",
    "    hA.grid()\n",
    "    hA.legend()\n",
    "\n",
    "    return hA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "The data set is composed of a timestamp (Resolution on 30 minutes) and the number of drives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "dfData = pd.read_csv(DATA_FILE_URL)\n",
    "\n",
    "\n",
    "print(f'The features data shape: {dfData.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data Frame\n",
    "\n",
    "dfData.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process\n",
    "\n",
    "Convert the string into a Date Time format of Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the `Time Stamp` column into valid Pandas time stamp\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Use Pandas' `to_datetime()` to convert the `Time Stamp` column.\n",
    "dfData['Time Stamp'] = ???\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data Using PlotLy\n",
    "# This will create an interactive plot of the data (You may zoom in and out).\n",
    "hF = px.line(data_frame = dfData, x = 'Time Stamp', y = ['Drives'], title = 'NYC Taxi Drives', template = 'plotly_dark')\n",
    "hF.update_layout(autosize = False, width = 1200, height = 400, legend_title_text = 'Legend')\n",
    "hF.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Do you see some patterns in data?\n",
    "* <font color='red'>(**?**)</font> Can you spot some outliers? Why?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Time series features engineering is an art.  \n",
    "Yet the basic features are the work on windows to extract statistical features: Mean, Standard Deviation, Median, etc...  \n",
    "\n",
    "The `Pandas` package has simple way to generate windows using the [`rolling()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample Data for Hour Resolution\n",
    "dfData = dfData.set_index('Time Stamp', drop = True, inplace = False)\n",
    "\n",
    "# Resample per hour by summing\n",
    "dfData = dfData.resample('H', axis = 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Result\n",
    "\n",
    "dfData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data Using PlotLy\n",
    "hF = px.line(data_frame = dfData, x = dfData.index, y = ['Drives'], title = 'NYC Taxi Drives', template = 'plotly_dark')\n",
    "hF.update_layout(autosize = False, width = 1200, height = 400, legend_title_text = 'Legend')\n",
    "hF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Window Operator\n",
    "\n",
    "def ApplyRollingWindow( dsI: pd.Series, winLength: int, winOperator: str ) -> pd.Series:\n",
    "    # dsI - Input data series.\n",
    "    # winLength - The window length to calculate the feature.\n",
    "    # winOperator - The operation to apply on the window.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Apply window functions by the string in `winOperator`: 'Standard Deviation', 'Median', 'Mean'.\n",
    "# 2. Look at `rolling()`, `std()`, `median()` and `mean()`.\n",
    "# 3. The pattern should be chaining the operation to the rolling operation: `dsI.rolling(winLength).std()`.\n",
    "    ?????\n",
    "#===============================================================#\n",
    "    \n",
    "    return dsO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='green'>(**@**)</font> You may add more statistical features.\n",
    "* <font color='red'>(**?**)</font> Are those features applicable for this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Feature Extraction / Generation\n",
    "\n",
    "lColNames = ['Drives']\n",
    "for winLen, opName in zip(lWinLength, lWinOperators):\n",
    "    colName = opName + f'{winLen:03d}'\n",
    "    lColNames.append(colName)\n",
    "    dfData[colName] = ApplyRollingWindow(dfData['Drives'], winLen, opName)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='green'>(**@**)</font> You may tweak the selection of window length and operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results on the Data Frame\n",
    "\n",
    "dfData.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why are there `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data Using PlotLy\n",
    "hF = px.line(data_frame = dfData, x = dfData.index, y = lColNames, title = 'NYC Taxi Drives', template = 'plotly_dark')\n",
    "hF.update_layout(autosize = False, width = 1200, height = 400, legend_title_text = 'Legend')\n",
    "hF.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='green'>(**@**)</font> Replace the features with local features such as:\n",
    "  - Ratio between the value to the mean value (Scaled by STD).\n",
    "  - Ratio between the value to the median value (Scaled by Median deviation)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "\n",
    "Our model can not handle missing values.  \n",
    "Hence we must impute or remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the NaN Values to the first not NaN value in the column\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Loop over each column of the data frame.\n",
    "# 2. Find the first valid index in each column (Use `first_valid_index()`).\n",
    "# 3. Fill the NaN's up to the first valid value with the valid value.\n",
    "?????\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Results\n",
    "# Should be no NaN's.\n",
    "\n",
    "dfData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LOF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Construct the model.\n",
    "# 2. Use `fit_predict()` on the data.\n",
    "# 3. Extract the LOF Score.\n",
    "# !! Mind the default LOF score sign.\n",
    "oLofOutDet = ???\n",
    "vL         = ???\n",
    "vLofScore  = ???\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data Using PlotLy\n",
    "hF = px.histogram(x = vLofScore, title = 'LOF', template = 'plotly_dark')\n",
    "hF.update_layout(autosize = False, width = 1200, height = 400)\n",
    "\n",
    "hF.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What threshold would you set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the LOF Score\n",
    "dfData['LOF Score'] = vLofScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Anomaly\n",
    "\n",
    "dfData['Anomaly'] = 0\n",
    "\n",
    "dfData.loc[dfData['LOF Score'] > lofScoreThr,'Anomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Anomalies \n",
    "hF = px.line(data_frame = dfData, x = dfData.index, y = ['Drives'], title = 'NYC Taxi Drives', template = 'plotly_dark')\n",
    "hF.update_layout(autosize = False, width = 1200, height = 400, legend_title_text = 'Legend')\n",
    "\n",
    "hF.add_scatter(x = dfData[dfData['Anomaly'] == 1].index, y = dfData.loc[dfData['Anomaly'] == 1, 'Drives'], name = 'Anomaly', mode = 'markers')\n",
    "\n",
    "hF.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
