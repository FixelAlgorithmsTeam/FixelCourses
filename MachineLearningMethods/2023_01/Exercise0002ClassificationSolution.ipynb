{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Exercise 002 - Classification\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 30/01/2023 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethods/2023_01/Exercise0002ClassificationSolution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import urllib.request\n",
    "\n",
    "# Load MAT Files\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF = (8, 8)\n",
    "ELM_SIZE_DEF = 50\n",
    "CLASS_COLOR = ('b', 'r')\n",
    "EDGE_COLOR  = 'k'\n",
    "\n",
    "TEST_DATA_FILE_NAME  = 'TestData.mat'\n",
    "TRAIN_DATA_FILE_NAME = 'TrainData.mat'\n",
    "\n",
    "L_CLASSES   = ['Red', 'Green', 'Blue']\n",
    "IMG_SIZE    = [100, 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixel Algorithms Packages\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "This exercise introduces:\n",
    "\n",
    " - Concept of _Features Transform_ to reduce the amount of data.\n",
    " - Optimizing a classifier by the accuracy score.\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> While in this case the _dimensionality reduction_ of data is done manually by domain knowledge, later in the course we'll learn ML based methods.\n",
    "* <font color='brown'>(**#**)</font> There is more than one way to implement the exercise. Feel free to wander.\n",
    "\n",
    "In this exercise we'll work on images which are composed in a matrix.  \n",
    "Each image is of size `100 x 100 x 3` yet it is spread in a _column stack_ fashion as a row in the data matrix.  \n",
    "The train data has `2700` images in a matrix, so the matrix size is `2_700 x 30_000`.\n",
    "\n",
    "The objective is being able to classify the color of the image: `Red: 0`, `Green: 1`, `Blue: 2`.  \n",
    "The image colors isn't uniform but contains many colors, but the idea is to identify the dominant color.  \n",
    "The concept of _red_ / _green_ / _blue_ is not a single color but the _family_ of colors.\n",
    "\n",
    "1. Download the data `zip` file from https://drive.google.com/file/d/17-IWjWCPuXMSO0uUWKVDIO-NT38SoB8J.  \n",
    "   Unzip it to the **same folder as this notebook**.\n",
    "2. Extract features from the images for the training data.\n",
    "3. Train a Kernel SVM (`rbf`) model on the data. Optimize the `C` and `gamma` parameters for accuracy using grid search.\n",
    "4. Extract the same features from the test images into test data.\n",
    "5. Plot the _confusion matrix_ of the best model on the test data.\n",
    "\n",
    "Optimize features (repeat if needed) to get accuracy of at least `85%` per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Think of the parameters to optimize per model (See above).\n",
    "# 2. Select the set to optimize over.\n",
    "# 3. Set the number of folds in the cross validation.\n",
    "lC = [0.1, 0.5, 1, 3]\n",
    "lγ = ['scale', 'auto', 0.05, 0.5, 1.00, 3.00]\n",
    "numFold = 5\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def PlotImage(vX, imgClass = None, imgSize = IMG_SIZE, hA = None):\n",
    "\n",
    "    mI = np.reshape(vX, (imgSize[0], imgSize[1], 3), order = 'F') #<! Data is coming from MATLAB\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (4, 4))\n",
    "    \n",
    "    hA.imshow(mI)\n",
    "    hA.tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "\n",
    "    if imgClass is not None:\n",
    "        hA.set_title('Image Class: {imgClass}')\n",
    "\n",
    "    return hA\n",
    "\n",
    "\n",
    "def PlotImages(mX: np.ndarray, vY: np.ndarray, numRows: int, numCols: int, lClass = L_CLASSES, hF = None):\n",
    "\n",
    "    numSamples  = mX.shape[0]\n",
    "    numPx       = mX.shape[1]\n",
    "\n",
    "    numImg = numRows * numCols\n",
    "\n",
    "    tFigSize = (numRows * 3, numCols * 3)\n",
    "\n",
    "    if hF is None:\n",
    "        hF, hA = plt.subplots(nrows = numRows, ncols = numCols, figsize = tFigSize)\n",
    "    else:\n",
    "        hA = hF.axis\n",
    "    \n",
    "    hA = np.atleast_1d(hA) #<! To support numImg = 1\n",
    "    hA = hA.flat\n",
    "\n",
    "    vIdx = np.random.choice(numSamples, numImg, replace = False)\n",
    "    \n",
    "    for kk in range(numImg):\n",
    "        imgIdx  = vIdx[kk]\n",
    "\n",
    "        PlotImage(mX[imgIdx], hA = hA[kk])\n",
    "        hA[kk].set_title(f'Index = {imgIdx}, Label = {lClass[vY[imgIdx]]}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def PlotLabelsHistogram(vY: np.ndarray, hA = None, lClass = None):\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (8, 6))\n",
    "    \n",
    "    vLabels, vCounts = np.unique(vY, return_counts = True)\n",
    "\n",
    "    hA.bar(vLabels, vCounts, width = 0.9, align = 'center')\n",
    "    hA.set_title('Histogram of Classes / Labels')\n",
    "    hA.set_xlabel('Class')\n",
    "    hA.set_ylabel('Number of Samples')\n",
    "    hA.set_xticks(vLabels)\n",
    "    if lClass is not None:\n",
    "        hA.set_xticklabels(lClass)\n",
    "\n",
    "    return hA\n",
    "\n",
    "def PlotConfusionMatrix(vY: np.ndarray, vYPred: np.ndarray, normMethod: str = None, hA: plt.Axes = None, lLabels: list = None, dScore: dict = None, titleStr: str = 'Confusion Matrix') -> plt.Axes:\n",
    "\n",
    "    # Calculation of Confusion Matrix\n",
    "    mConfMat = confusion_matrix(vY, vYPred, normalize = normMethod)\n",
    "    oConfMat = ConfusionMatrixDisplay(mConfMat, display_labels = lLabels)\n",
    "    oConfMat = oConfMat.plot(ax = hA)\n",
    "    hA = oConfMat.ax_\n",
    "    if dScore is not None:\n",
    "        titleStr += ':'\n",
    "        for scoreName, scoreVal in  dScore.items():\n",
    "            titleStr += f' {scoreName} = {scoreVal:0.2},'\n",
    "        titleStr = titleStr[:-1]\n",
    "    hA.set_title(titleStr)\n",
    "    hA.grid(False)\n",
    "\n",
    "    return hA, mConfMat\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "\n",
    "dTestData  = loadmat(TEST_DATA_FILE_NAME)\n",
    "dTrainData = loadmat(TRAIN_DATA_FILE_NAME)\n",
    "\n",
    "mXTrain, vYTrain    = dTrainData['mX'], np.squeeze(dTrainData['vY'])\n",
    "mXTest, vYTest      = dTestData['mX'], np.squeeze(dTestData['vY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of the Data\n",
    "print(f'The number of training data samples: {mXTrain.shape[0]}')\n",
    "print(f'The number of training features per sample: {mXTrain.shape[1]}') \n",
    "\n",
    "\n",
    "print(f'The number of test data samples: {mXTest.shape[0]}')\n",
    "print(f'The number of test features per sample: {mXTest.shape[1]}') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data (Some Images)\n",
    "\n",
    "# Train Data\n",
    "PlotImages(mXTrain, vYTrain, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data (Some Images)\n",
    "\n",
    "# Test Data\n",
    "PlotImages(mXTest, vYTest, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Classes\n",
    "\n",
    "# Train\n",
    "hA = PlotLabelsHistogram(vYTrain, lClass = L_CLASSES)\n",
    "hA.set_title(hA.get_title() + ' - Train Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Classes\n",
    "\n",
    "# Test\n",
    "hA = PlotLabelsHistogram(vYTest, lClass = L_CLASSES)\n",
    "hA.set_title(hA.get_title() + ' - Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Is the data balanced or imbalanced?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data and Feature Engineering / Extraction\n",
    "\n",
    "The vector of values doesn't fit, as is, for classification with SVM.  \n",
    "It misses a lot of the information given in the structure of the image or a color pixel.  \n",
    "In our case, the important thing is to give the classifier information about the structure of color, a vector of 3 values: `[r, g, b]`.  \n",
    "Yet, the classifier input is limited to a list of values. This is where the concept of metric comes into play.  \n",
    "\n",
    "We need to create information about distance between colors.  \n",
    "We also need to extract features to represent the colors in the image.\n",
    "\n",
    "In this section the task are:\n",
    "\n",
    "1. Implement functions to extract features from the data.\n",
    "2. Arrange the features in a _matrix_ / _data frame_ for processing.\n",
    "3. Explore the features using _SeaBorn_. Specifically if the features extracts meaningful information.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Don't include _test data_ in the analysis for feature extraction. Other wise, a data leakage will happen.\n",
    "\n",
    "### Ideas for Features\n",
    "\n",
    "1. The distance between the the _mean_ / _median_ / _mode_ color of the image to the per _mean_ / _median_ / _mode_ color per class.\n",
    "2. The distance between the quantized histogram of `R` / `G` / `B` color channels of the image to the class.\n",
    "3. The distance of the mean color at the center of the image to the mean color of the class.\n",
    "4. The channel with the maximum value (Is this a continuous value? Does it fit the SVM model?).\n",
    "5. Use of the _HSL_ color space.\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You're encouraged to think on more features!\n",
    "* <font color='brown'>(**#**)</font> Pay attention to dimensionality fo the data. For instance, how do you define the _median color_?\n",
    "* <font color='brown'>(**#**)</font> For simplicity we use the RGB Color Space. Yet color distance might be better calculated in other color spaces (See LAB for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Color Per Class\n",
    "def CalcMeanColorPerClass( mX, vY, imgSize = IMG_SIZE ):\n",
    "    # Assuming input data is UINT8\n",
    "    \n",
    "    vClass = np.unique(vY)\n",
    "    mColor = np.zeros(shape = (vClass.shape[0], 3)) #<! Each row is a class\n",
    "\n",
    "    for ii, classIdx in enumerate(vClass):\n",
    "        numImg = np.sum(vY == classIdx)\n",
    "        mD = np.reshape(mX[vY == classIdx], (numImg, imgSize[0] * imgSize[1], 3), order = 'F') #<! Data is column stacked\n",
    "        mColor[ii, :] = np.mean(mD, axis = (0, 1))\n",
    "    \n",
    "    return mColor / 255.0\n",
    "\n",
    "# Mean Color per Image\n",
    "def CalcMeanColor( vX, imgSize = IMG_SIZE ):\n",
    "\n",
    "    mI = np.reshape(vX, (imgSize[0] * imgSize[1], 3), order = 'F') #<! Data is column stacked\n",
    "\n",
    "    return np.mean(mI, axis = 0) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Histogram per Channel per Class\n",
    "def CalcRgbHistPerClass( mX, vY, imgSize = IMG_SIZE, lHist = [0, 64, 128, 192, 255]):\n",
    "\n",
    "    vClass = np.unique(vY)\n",
    "    tH = np.zeros(shape = (3, len(lHist) - 1, 3)) #<! Color x #Bins x #Classes\n",
    "\n",
    "    for ii, classIdx in enumerate(vClass):\n",
    "        numImg = np.sum(vY == classIdx)\n",
    "        mD = np.reshape(mX[vY == classIdx], (numImg * imgSize[0] * imgSize[1], 3), order = 'F') #<! Data is column stacked\n",
    "        for jj in range(3):\n",
    "            # Color Channel\n",
    "            # mD is ((numImg * imgSize[0] * imgSize[1]) x 3)\n",
    "            vH, _ = np.histogram(mD[:, jj], bins = lHist)\n",
    "            tH[jj, :, ii] = vH / np.sum(vH)\n",
    "    \n",
    "    return tH\n",
    "\n",
    "# Histogram per Channel (Single Image)\n",
    "def CalcHistogram( vX, imgSize = IMG_SIZE, lHist = [0, 64, 128, 192, 255] ):\n",
    "\n",
    "    mH = np.zeros(shape = (3, len(lHist) - 1))\n",
    "\n",
    "    mI = np.reshape(vX, (imgSize[0] * imgSize[1], 3), order = 'F') #<! Data is column stacked\n",
    "\n",
    "    for ii in range(3):\n",
    "        vH, _ = np.histogram(mI[:, ii], bins = lHist)\n",
    "        mH[ii] = vH / np.sum(vH)\n",
    "    \n",
    "    return mH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Value to Mean Value Ratio\n",
    "# The ratio between the mean value of the channel to the mean value of all pixels\n",
    "def MeanChannelValueMeanValueRatio(vX, imgSize = IMG_SIZE):\n",
    "    \n",
    "    vMeanColor = CalcMeanColor(vX, imgSize = imgSize)\n",
    "    \n",
    "    return vMeanColor / np.mean(vMeanColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lFeatureName = ['Red vs. Mean', 'Green vs. Mean', 'Blue vs. Mean', 'Red Channel Hist Distance Class 0', 'Green Channel Hist Distance Class 0', 'Blue Channel Hist Distance Class 0', 'Red Channel Hist Distance Class 1', 'Green Channel Hist Distance Class 1', 'Blue Channel Hist Distance Class 1', 'Red Channel Hist Distance Class 2', 'Green Channel Hist Distance Class 2', 'Blue Channel Hist Distance Class 2', 'Mean Pixel Distance Class 0', 'Mean Pixel Distance Class 1', 'Mean Pixel Distance Class 2']\n",
    "\n",
    "# Creating the Features Matrix\n",
    "# The matrix is numSamples x numFeatures\n",
    "# The features are (15): ratioR, ratioG, ratioB, redHistDisCls0, greenHistDisCls0, blueHistDisCls0, redHistDisCls1, greenHistDisCls1, blueHistDisCls1, redHistDisCls2, greenHistDisCls2, blueHistDisCls2, meanPxDisCls0, meanPxDisCls1, meanPxDisCls2\n",
    "# Hence the matrix is 2700x15\n",
    "\n",
    "def CalcFeaturesMatrix( mD, tH, mC ):\n",
    "\n",
    "    numSamples = mD.shape[0]\n",
    "\n",
    "    mX = np.zeros(shape = (numSamples, 15))\n",
    "    \n",
    "    for ii in range(numSamples):\n",
    "        vR = MeanChannelValueMeanValueRatio(mD[ii])\n",
    "        mH = CalcHistogram(mD[ii])\n",
    "        vC = CalcMeanColor(mD[ii])\n",
    "        for jj in range(15):\n",
    "            if jj < 3:\n",
    "                mX[ii, jj] = vR[jj]\n",
    "            # The next section could be written in a vectorized manner yet written for clarity\n",
    "            elif jj == 3:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[0] - tH[0, :, 0]) #!< Red Channel, Class 0\n",
    "            elif jj == 4:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[1] - tH[1, :, 0]) #!< Green Channel, Class 0\n",
    "            elif jj == 5:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[2] - tH[2, :, 0]) #!< Blue Channel, Class 0\n",
    "            elif jj == 6:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[0] - tH[0, :, 1]) #!< Red Channel, Class 0\n",
    "            elif jj == 7:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[1] - tH[1, :, 1]) #!< Green Channel, Class 0\n",
    "            elif jj == 8:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[2] - tH[2, :, 1]) #!< Blue Channel, Class 0\n",
    "            elif jj == 9:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[0] - tH[0, :, 2]) #!< Red Channel, Class 0\n",
    "            elif jj == 10:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[1] - tH[1, :, 2]) #!< Green Channel, Class 0\n",
    "            elif jj == 11:\n",
    "                mX[ii, jj] = np.linalg.norm(mH[2] - tH[2, :, 2]) #!< Blue Channel, Class 0\n",
    "            elif jj == 12:\n",
    "                mX[ii, jj] = np.linalg.norm(vC - mC[0]) #!<Class 0\n",
    "            elif jj == 13:\n",
    "                mX[ii, jj] = np.linalg.norm(vC - mC[1]) #!<Class 1\n",
    "            elif jj == 14:\n",
    "                mX[ii, jj] = np.linalg.norm(vC - mC[2]) #!<Class 2\n",
    "    \n",
    "    return mX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Features Matrix for the Training Data Set\n",
    "mC = CalcMeanColorPerClass(mXTrain, vYTrain) #<! Mean pixel per Class\n",
    "tH = CalcRgbHistPerClass(mXTrain, vYTrain) #<! Mean histogram per channel per class\n",
    "mF = CalcFeaturesMatrix(mXTrain, tH, mC) #<! The features matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> One could optimize the histogram by creating a 3D histogram."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Analysis\n",
    "\n",
    "In this section the relation between the features and the labels is analyzed.  \n",
    "You should visualize / calculate measures which imply the features makes the classes identifiable.\n",
    "\n",
    "#### Ideas for Analysis\n",
    "\n",
    "1. Display the histogram / density of each feature by the label of sample.\n",
    "2. Display the correlation between the feature to the class value (Pay attention this is a mix of continuous values and categorical values).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may find SeaBorn's `kdeplot()` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hF, hA = plt.subplots(nrows = 5, ncols = 3, figsize = (12, 8))\n",
    "\n",
    "for ii, featName in enumerate(lFeatureName):\n",
    "    sns.kdeplot(x = mF[:, ii], hue = vYTrain, ax = hA.flat[ii])\n",
    "    hA.flat[ii].set_title(f'Distribution of {featName}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Classifiers\n",
    "\n",
    "In this section we'll train a Kernel SVM model with optimized hyper parameters: `C` and `gamma`.  \n",
    "The score should be the regular accuracy.\n",
    "\n",
    "1. Build the dictionary of parameters for the grid search.\n",
    "2. Construct the grid search object (`GridSearchCV`).\n",
    "3. Optimize the hyper parameters by the `fit()` method of the grid search object.\n",
    "\n",
    "* <font color='red'>(**?**)</font> Why is the accuracy a reasonable score in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciKit Learn requires vY to be matrix form for `_ThresholdScorer()` (See https://github.com/scikit-learn/scikit-learn/blob/7b13a8f120a6d67112b0f50a8834d65e2258f045/sklearn/metrics/_scorer.py#L366)\n",
    "# Hence we'll use accuracy measure.\n",
    "\n",
    "# def RocAucSvm( vY, mDecFun ):\n",
    "    \n",
    "#     mP      = sp.special.softmax(mDecFun, axis = 1)\n",
    "#     aucVal  = roc_auc_score(vY, mP, multi_class = 'ovr')\n",
    "    \n",
    "#     return aucVal\n",
    "\n",
    "# RocAucSvmScore = make_scorer(RocAucSvm, needs_threshold = True)\n",
    "\n",
    "# oGsSvc = GridSearchCV(estimator = SVC(kernel = 'rbf', decision_function_shape = 'ovr'), param_grid = dParams, scoring = RocAucSvmScore, cv = numFold, verbose = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Grid Search object \n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Set the parameters to iterate over and their values\n",
    "dParams = {'C': lC, 'gamma': lγ}\n",
    "#===============================================================#\n",
    "\n",
    "oGsSvc = GridSearchCV(estimator = SVC(kernel = 'rbf'), param_grid = dParams, scoring = None, cv = numFold, verbose = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Apply the grid search phase\n",
    "oGsSvc = oGsSvc.fit(mF, vYTrain)\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix on Test Data \n",
    "\n",
    "In this section we'll test the model on the test data.\n",
    "\n",
    "1. Extract the best estimator from the grid search.\n",
    "2. If needed, fit it to the train data.\n",
    "3. Calculate the test set features. Make sure to avoid data leakage.\n",
    "4. Display the _confusion matrix_.\n",
    "\n",
    "The objective is to get at least `85%` accuracy per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Best Model\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Get the best model with the optimized hyper parameters\n",
    "bestModel = oGsSvc.best_estimator_\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Does the best model need a refit on data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the test data set features\n",
    "# Pay attention to not use of leak of data from the test set to the model / features.\n",
    "# One way to obey this is assume you got the test data one by one.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Features of the Test Data\n",
    "mFTest = CalcFeaturesMatrix(mXTest, tH, mC)\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "hF, hA = plt.subplots(figsize = (10, 10))\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "hA, mConfMat = PlotConfusionMatrix(vYTest, bestModel.predict(mFTest), lLabels = L_CLASSES, hA = hA)\n",
    "#===============================================================#\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> If results are good, can you spot the dominant feature for them if there is?\n",
    "* <font color='green'>(**@**)</font> Check results with a single feature: The channel with the highest mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
