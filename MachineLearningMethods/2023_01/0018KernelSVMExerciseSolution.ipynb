{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io/)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Supervised Learning - Kernel SVM - Exercise Solution\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.001 | 24/05/2023 | Royi Avital | Scaling data into `[0, 1]`                                         |\n",
    "| 0.1.000 | 28/01/2023 | Royi Avital | First version                                                      |\n",
    "|         |            |             |                                                                    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethods/2023_01/0018KernelSVMExerciseSolution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import auc, confusion_matrix, precision_recall_fscore_support, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Miscellaneous\n",
    "import gzip\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import urllib.request\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF = (8, 8)\n",
    "ELM_SIZE_DEF = 50\n",
    "CLASS_COLOR = ('b', 'r')\n",
    "EDGE_COLOR  = 'k'\n",
    "\n",
    "# Fashion MNIST\n",
    "TRAIN_DATA_SET_IMG_URL = r'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz'\n",
    "TRAIN_DATA_SET_LBL_URL = r'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz'\n",
    "TEST_DATA_SET_IMG_URL  = r'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'\n",
    "TEST_DATA_SET_LBL_URL  = r'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "TRAIN_DATA_IMG_FILE_NAME = 'TrainImgFile'\n",
    "TRAIN_DATA_LBL_FILE_NAME = 'TrainLblFile'\n",
    "TEST_DATA_IMG_FILE_NAME  = 'TestImgFile'\n",
    "TEST_DATA_LBL_FILE_NAME  = 'TestLblFile'\n",
    "\n",
    "TRAIN_DATA_SET_FILE_NAME = 'FashionMnistTrainDataSet.npz'\n",
    "TEST_DATA_SET_FILE_NAME  = 'FashionMnistTestDataSet.npz'\n",
    "\n",
    "TRAIN_DATA_NUM_IMG  = 60_000\n",
    "TEST_DATA_NUM_IMG   = 10_000\n",
    "\n",
    "D_CLASSES = {0: 'T-Shirt', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Boots'}\n",
    "L_CLASSES = ['T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixel Algorithms Packages\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameter Optimization with Kernel SVM\n",
    "\n",
    "In this exercise we'll apply the Cross Validation automatically to find the optimal hyper parameters for the Kernel SVM Model.  \n",
    "In order to achieve this we'll do a [Grid Search for Hyper Parameters Optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization).\n",
    "\n",
    "1. Load the [Fashion MNIST Data Set](https://github.com/zalandoresearch/fashion-mnist) manually (Done by me).\n",
    "2. Train a baseline Linear SVM model.\n",
    "3. Find the optimal Kernel SVM model using Grid Search.\n",
    "4. Extract the optimal model.\n",
    "5. Plot the Confusion Matrix of the best model on the training data.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may and should use the functions in the `Auxiliary Functions` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "numSamplesTrain = 4_000\n",
    "numSamplesTest  = 1_000\n",
    "numImg = 3\n",
    "\n",
    "# Linear SVM (Baseline Model)\n",
    "paramC      = 1\n",
    "kernelType  = 'linear'\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Think of the parameters to optimize\n",
    "# Select the set to optimize over\n",
    "# Set the number of folds in the cross validation\n",
    "lC      = [0.1, 1, 3]\n",
    "lKernel = ['poly', 'rbf']\n",
    "lγ      = ['scale', 'auto', 0.1, 1, 10]\n",
    "numFold = 5\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def DownloadDecompressGzip(fileUrl, fileName):\n",
    "    # Based on https://stackoverflow.com/a/61195974\n",
    "\n",
    "    # Read the file inside the .gz archive located at url\n",
    "    with urllib.request.urlopen(fileUrl) as response:\n",
    "        with gzip.GzipFile(fileobj = response) as uncompressed:\n",
    "            file_content = uncompressed.read()\n",
    "        # write to file in binary mode 'wb'\n",
    "        with open(fileName, 'wb') as f:\n",
    "            f.write(file_content)\n",
    "            f.close()\n",
    "        return\n",
    "\n",
    "def ConvertMnistDataDf(imgFilePath: str, labelFilePath: str):\n",
    "    numPx = 28 * 28\n",
    "    # Merge of https://pjreddie.com/projects/mnist-in-csv/ and https://github.com/keras-team/keras/blob/master/keras/datasets/fashion_mnist.py\n",
    "    f = open(imgFilePath, \"rb\")\n",
    "    l = open(labelFilePath, \"rb\")\n",
    "\n",
    "    lCol = [f'Px {ii:04}' for ii in range (numPx)]\n",
    "    lCol.append('Label')\n",
    "\n",
    "    vY = np.frombuffer(l.read(), np.uint8, offset = 8)\n",
    "    mX = np.frombuffer(f.read(), np.uint8, offset = 16)\n",
    "    # mX = np.reshape(mX, (numPx, len(vY))).T\n",
    "    mX = np.reshape(mX, (len(vY), numPx))\n",
    "\n",
    "    f.close()\n",
    "    l.close()\n",
    "\n",
    "    return mX, vY\n",
    "\n",
    "def PlotMnistImages(mX, vY, numImg, lClasses = list(range(10)), hF = None):\n",
    "\n",
    "    numSamples  = mX.shape[0]\n",
    "    numPx       = mX.shape[1]\n",
    "\n",
    "    numRows = int(np.sqrt(numPx))\n",
    "\n",
    "    tFigSize = (numImg * 3, numImg * 3)\n",
    "\n",
    "    if hF is None:\n",
    "        hF, hA = plt.subplots(numImg, numImg, figsize = tFigSize)\n",
    "    else:\n",
    "        hA = hF.axis\n",
    "    \n",
    "    hA = np.atleast_1d(hA) #<! To support numImg = 1\n",
    "    hA = hA.flat\n",
    "\n",
    "    \n",
    "    for kk in range(numImg * numImg):\n",
    "        idx = np.random.choice(numSamples)\n",
    "        mI  = np.reshape(mX[idx, :], (numRows, numRows))\n",
    "    \n",
    "        # hA[kk].imshow(mI.clip(0, 1), cmap = 'gray')\n",
    "        hA[kk].imshow(mI, cmap = 'gray')\n",
    "        hA[kk].tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "        hA[kk].set_title(f'Index = {idx}, Label = {lClasses[vY[idx]]}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def PlotLabelsHistogram(vY: np.ndarray, hA = None):\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (8, 6))\n",
    "    \n",
    "    vLabels, vCounts = np.unique(vY, return_counts = True)\n",
    "\n",
    "    hA.bar(vLabels, vCounts, width = 0.9, align = 'center')\n",
    "    hA.set_xticks(vLabels)\n",
    "    hA.set_title('Histogram of Classes / Labels')\n",
    "    hA.set_xlabel('Class')\n",
    "    hA.set_ylabel('Number of Samples')\n",
    "\n",
    "    return hA\n",
    "\n",
    "def PlotConfusionMatrix(vY: np.ndarray, vYPred: np.ndarray, normMethod: str = None, hA: plt.Axes = None, lLabels: list = None, dScore: dict = None, titleStr: str = 'Confusion Matrix') -> plt.Axes:\n",
    "\n",
    "    # Calculation of Confusion Matrix\n",
    "    mConfMat = confusion_matrix(vY, vYPred, normalize = normMethod)\n",
    "    oConfMat = ConfusionMatrixDisplay(mConfMat, display_labels = lLabels)\n",
    "    oConfMat = oConfMat.plot(ax = hA)\n",
    "    hA = oConfMat.ax_\n",
    "    if dScore is not None:\n",
    "        titleStr += ':'\n",
    "        for scoreName, scoreVal in  dScore.items():\n",
    "            titleStr += f' {scoreName} = {scoreVal:0.2},'\n",
    "        titleStr = titleStr[:-1]\n",
    "    hA.set_title(titleStr)\n",
    "    hA.grid(False)\n",
    "\n",
    "    return hA, mConfMat\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "if os.path.isfile(TRAIN_DATA_SET_FILE_NAME):\n",
    "    dData = np.load(TRAIN_DATA_SET_FILE_NAME)\n",
    "    mXTrain, vYTrain = dData['mXTrain'], dData['vYTrain']\n",
    "else:\n",
    "    if not os.path.isfile(TRAIN_DATA_IMG_FILE_NAME):\n",
    "        DownloadDecompressGzip(TRAIN_DATA_SET_IMG_URL, TRAIN_DATA_IMG_FILE_NAME) #<! Download Data (GZip File)\n",
    "    if not os.path.isfile(TRAIN_DATA_LBL_FILE_NAME):\n",
    "        DownloadDecompressGzip(TRAIN_DATA_SET_LBL_URL, TRAIN_DATA_LBL_FILE_NAME) #<! Download Data (GZip File)\n",
    "    mXTrain, vYTrain = ConvertMnistDataDf(TRAIN_DATA_IMG_FILE_NAME, TRAIN_DATA_LBL_FILE_NAME)\n",
    "    np.savez_compressed(TRAIN_DATA_SET_FILE_NAME, mXTrain  = mXTrain, vYTrain = vYTrain)\n",
    "\n",
    "if os.path.isfile(TEST_DATA_SET_FILE_NAME):\n",
    "    dData = np.load(TEST_DATA_SET_FILE_NAME)\n",
    "    mXTest, vYTest = dData['mXTest'], dData['vYTest']\n",
    "else:\n",
    "    if not os.path.isfile(TEST_DATA_IMG_FILE_NAME):\n",
    "        DownloadDecompressGzip(TEST_DATA_SET_IMG_URL, TEST_DATA_IMG_FILE_NAME) #<! Download Data (GZip File)\n",
    "    if not os.path.isfile(TEST_DATA_LBL_FILE_NAME):\n",
    "        DownloadDecompressGzip(TEST_DATA_SET_LBL_URL, TEST_DATA_LBL_FILE_NAME) #<! Download Data (GZip File)\n",
    "    mXTest, vYTest = ConvertMnistDataDf(TEST_DATA_IMG_FILE_NAME, TEST_DATA_LBL_FILE_NAME)\n",
    "    np.savez_compressed(TEST_DATA_SET_FILE_NAME, mXTest = mXTest, vYTest = vYTest)\n",
    "\n",
    "\n",
    "vSampleIdx = np.random.choice(mXTrain.shape[0], numSamplesTrain)\n",
    "mXTrain = mXTrain[vSampleIdx, :]\n",
    "vYTrain = vYTrain[vSampleIdx]\n",
    "\n",
    "vSampleIdx = np.random.choice(mXTest.shape[0], numSamplesTest)\n",
    "mXTest = mXTest[vSampleIdx, :]\n",
    "vYTest = vYTest[vSampleIdx]\n",
    "\n",
    "\n",
    "print(f'The number of train data samples: {mXTrain.shape[0]}')\n",
    "print(f'The number of train features per sample: {mXTrain.shape[1]}') \n",
    "print(f'The number of test data samples: {mXTest.shape[0]}')\n",
    "print(f'The number of test features per sample: {mXTest.shape[1]}') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process Data\n",
    "\n",
    "The image data is in the `UInt8` data form with values in `{0, 1, 2, ..., 255}`.   \n",
    "Scale it into `[0, 1]` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Data\n",
    "# Scale data into [0, 1] range\n",
    "\n",
    "mXTrain = mXTrain / 255\n",
    "mXTest  = mXTest / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data\n",
    "\n",
    "PlotMnistImages(mXTrain, vYTrain, numImg, lClasses = L_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Classes\n",
    "hA = PlotLabelsHistogram(vYTrain)\n",
    "hA.set_xticks(range(len(L_CLASSES)))\n",
    "hA.set_xticklabels(L_CLASSES)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear SVM Classifier\n",
    "\n",
    "This will be the base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model\n",
    "#===========================Fill This===========================#\n",
    "# Construct a baseline model (Linear SVM)\n",
    "# Train the model\n",
    "# Score the model (Accuracy)\n",
    "oSVM  = SVC(C = paramC, kernel = kernelType).fit(mXTrain, vYTrain)\n",
    "modelScore = oSVM.score(mXTest, vYTest)\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The model score (Accuracy) on the data: {modelScore:0.2%}') #<! Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Kernel SVM\n",
    "\n",
    "In this section we'll train a Kernel SVM. We'll find the optimal kernel by cross validation.\n",
    "In order to optimize on the following parameters: `C`, `kernel` and `gamma` we'll use `GridSearchCV()`.  \n",
    "The idea is iterating over the grid of parameters of the model to find the optimal one.  \n",
    "Each parameterized model is evaluated by a Cross Validation.\n",
    "\n",
    "In order to use it we need to define:\n",
    " - The Model (`estimator`) - Which model is used.\n",
    " - The Parameters Grid (`param_grid`) - The set of parameter to try.\n",
    " - The Scoring (`scoring`) - The score used to define the best model.\n",
    " - The Cross Validation Iterator (`cv`) - The iteration to validate the model.\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Pay attention to the expected run time. Using `verbose` is useful.\n",
    "* <font color='brown'>(**#**)</font> This is a classic grid search which is not the most efficient policy. There are more advanced policies.\n",
    "* <font color='brown'>(**#**)</font> The `GridSearchCV()` is limited to one instance of an estimator. Yet using Pipelines we may test different types of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Grid Search object \n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Set the parameters to iterate over and their values\n",
    "dParams = {'C': lC, 'kernel': lKernel, 'gamma': lγ}\n",
    "#===============================================================#\n",
    "\n",
    "oGsSvc = GridSearchCV(estimator = SVC(), param_grid = dParams, scoring = None, cv = numFold, verbose = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> You may want to have a look at the `n_jobs_` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (Hyper Parameter Optimization)\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# The model trains on the train data using Stratified K Fold cross validation\n",
    "oGsSvc = oGsSvc.fit(mXTrain, vYTrain)\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the attributes of the best model\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Extract the best score\n",
    "# Extract a dictionary of the parameters\n",
    "bestScore   = oGsSvc.best_score_\n",
    "dBestParams = oGsSvc.best_params_\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The best model had the following parameters: {dBestParams} with the CV score: {bestScore:0.2%}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> In production one would visualize the effect of each parameter on the model result. then use it to fine tune farther the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Best Mode\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Extract the best model\n",
    "# Score the best model on the test data set\n",
    "bestModel = oGsSvc.best_estimator_\n",
    "modelScore = bestModel.score(mXTest, vYTest)\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The model score (Accuracy) on the data: {modelScore:0.2%}') #<! Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With proper tuning one can bet the baseline model by `~5%`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Best Model on the Train Data Set\n",
    "\n",
    "In production we take the optimal Hyper Parameters and then retrain the model on the whole training data set.  \n",
    "This is the model we'll use in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Model with Optimal Parameters\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# Construct the model\n",
    "# Train the model\n",
    "oSvmCls = SVC(**dBestParams)\n",
    "oSvmCls = oSvmCls.fit(mXTrain, vYTrain)\n",
    "#===============================================================#\n",
    "\n",
    "modelScore = oSvmCls.score(mXTest, vYTest)\n",
    "\n",
    "print(f'The model score (Accuracy) on the data: {modelScore:0.2%}') #<! Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Is the value above exactly as the value from the best model of the grid search? If so, look at the `refit` parameter of `GridSearchCV`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics / Scores\n",
    "\n",
    "In this section we'll analyze the model using the _confusion matrix_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "hF, hA = plt.subplots(figsize = (10, 10))\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "hA, mConfMat = PlotConfusionMatrix(vYTest, bestModel.predict(mXTest), lLabels = L_CLASSES, hA = hA)\n",
    "#===============================================================#\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Which class has the best accuracy?\n",
    "* <font color='red'>(**?**)</font> Which class has a dominant false prediction? Does it make sense?\n",
    "* <font color='red'>(**?**)</font> What's the difference between $p \\left( \\hat{y}_{i} = \\text{coat} \\mid {x}_{i} = \\text{coat} \\right)$ to $p \\left( {y}_{i} = \\text{coat} \\mid \\hat{y}_{i} = \\text{coat} \\right)$?\n",
    "* <font color='blue'>(**!**)</font> Make the proper calculations on `mConfMat` or the function `PlotConfusionMatrix` to answer the questions above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2e25f61d437a570f4a5ebab9620676b76d9d78268156eb24f90e74ea13ca7ad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
