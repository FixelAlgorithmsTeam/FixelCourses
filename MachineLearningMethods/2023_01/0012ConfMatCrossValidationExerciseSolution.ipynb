{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Supervised Learning - Cross Validation - Exercise Solution\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 21/01/2023 | Royi Avital | First version                                                      |\n",
    "|         |            |             |                                                                    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethods/2023_01/0012ConfMatCrossValidationExerciseSolution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_predict, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF = (8, 8)\n",
    "ELM_SIZE_DEF = 50\n",
    "CLASS_COLOR = ('b', 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixel Algorithms Packages\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation with the SVM\n",
    "\n",
    "In this exercise we'll apply the Cross Validation manually to find the optimal `C` parameter for the SVM Model.  \n",
    "Instead of using `cross_val_predict()` we'll do a manual loop on the folds and average the score.\n",
    "\n",
    "1. Load the [MNIST Data set](https://en.wikipedia.org/wiki/MNIST_database) using `fetch_openml()`.\n",
    "2. Split the data using Stratified K Fold.\n",
    "3. For each model (Parameterized by `C`):\n",
    "    - Train model on the train sub set.\n",
    "    - Score model on the test sub set.\n",
    "4. Plot the score per model.\n",
    "5. Plot the Confusion Matrix of the best model on the training data.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Make sure to chose small number of models and folds at the beginning to measure run time and scale accordingly. \n",
    "* <font color='brown'>(**#**)</font> We'll use `LinearSVC` class which optimized `SVC` with kernel `linear` as it fits for larger data sets.  \n",
    "* <font color='brown'>(**#**)</font> You may and should use the functions in the `Auxiliary Functions` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "numSamples  = 10_000\n",
    "numImg = 3\n",
    "\n",
    "maxItr = 5000 #<! For the LinearSVC model\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "numFold = 5\n",
    "lC = list(np.linspace(0.0005, 1.5, 15))\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def PlotMnistImages(mX, vY, numImg, hF = None):\n",
    "\n",
    "    numSamples  = mX.shape[0]\n",
    "    numPx       = mX.shape[1]\n",
    "\n",
    "    numRows = int(np.sqrt(numPx))\n",
    "\n",
    "    tFigSize = (numImg * 3, numImg * 3)\n",
    "\n",
    "    if hF is None:\n",
    "        hF, hA = plt.subplots(numImg, numImg, figsize = tFigSize)\n",
    "    else:\n",
    "        hA = hF.axis\n",
    "    \n",
    "    hA = np.atleast_1d(hA) #<! To support numImg = 1\n",
    "    hA = hA.flat\n",
    "\n",
    "    \n",
    "    for kk in range(numImg * numImg):\n",
    "        idx = np.random.choice(numSamples)\n",
    "        mI  = np.reshape(mX[idx, :], (numRows, numRows))\n",
    "    \n",
    "        # hA[kk].imshow(mI.clip(0, 1), cmap = 'gray')\n",
    "        hA[kk].imshow(mI, cmap = 'gray')\n",
    "        hA[kk].tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "        hA[kk].set_title(f'Index = {idx}, Label = {vY[idx]}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def PlotLabelsHistogram(vY: np.ndarray, hA = None):\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (8, 6))\n",
    "    \n",
    "    vLabels, vCounts = np.unique(vY, return_counts = True)\n",
    "\n",
    "    hA.bar(vLabels, vCounts, width = 0.9, align = 'center')\n",
    "    hA.set_title('Histogram of Classes / Labels')\n",
    "    hA.set_xlabel('Class')\n",
    "    hA.set_ylabel('Number of Samples')\n",
    "\n",
    "    return hA\n",
    "\n",
    "def PlotConfusionMatrix(vY: np.ndarray, vYPred: np.ndarray, hA: plt.Axes = None, lLabels: list = None, dScore: dict = None, titleStr: str = 'Confusion Matrix'):\n",
    "\n",
    "    # Calculation of Confusion Matrix\n",
    "    mConfMat = confusion_matrix(vY, vYPred)\n",
    "    oConfMat = ConfusionMatrixDisplay(mConfMat, display_labels = lLabels)\n",
    "    oConfMat = oConfMat.plot(ax = hA)\n",
    "    hA = oConfMat.ax_\n",
    "    if dScore is not None:\n",
    "        titleStr += ':'\n",
    "        for scoreName, scoreVal in  dScore.items():\n",
    "            titleStr += f' {scoreName} = {scoreVal:0.2},'\n",
    "        titleStr = titleStr[:-1]\n",
    "    hA.set_title(titleStr)\n",
    "    hA.grid(False)\n",
    "\n",
    "    return hA\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "mX, vY = fetch_openml('mnist_784', version = 1, return_X_y = True, as_frame = False, parser = 'auto')\n",
    "#===============================================================#\n",
    "\n",
    "# The data has many samples, for fast run time we'll sub sample it\n",
    "\n",
    "vSampleIdx = np.random.choice(mX.shape[0], numSamples)\n",
    "mX = mX[vSampleIdx, :]\n",
    "vY = vY[vSampleIdx]\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(vY)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing\n",
    "\n",
    "# The image is in the range {0, 1, ..., 255}\n",
    "# We scale it into [0, 1]\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "\n",
    "mX = mX / 255.0\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data\n",
    "\n",
    "PlotMnistImages(mX, vY, numImg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Labels\n",
    "\n",
    "When dealing with classification, it is important to know the balance between the labels within the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hA = PlotLabelsHistogram(vY)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "The _Cross Validation_ process allows us to estimate the stability of performance.  \n",
    "It also the main tool to optimize the model _Hyper Parameters_. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Hyper Parameter Optimization\n",
    "\n",
    "We can also use the _Cross Validation_ approach to search for the best _Hype Parameter_.  \n",
    "The idea is iterating through the data and measure the score we care about.  \n",
    "The hyper parameter which maximize the score will be used for the production model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What kind of a problem is this? Binary Class or Multi Class?\n",
    "* <font color='red'>(**?**)</font> What kind of strategy will be used? Advise documentation.\n",
    "* <font color='brown'>(**#**)</font> When using `LinearSVC`:\n",
    "    *   If #Samples > #Features -> Set `dual = False`.\n",
    "    *   If #Samples < #Features -> Set `dual = True` (Default).\n",
    "* <font color='brown'>(**#**)</font> If you experience converging issues with `LinearSVC` use `SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for the C parameter\n",
    "numC = len(lC)\n",
    "mACC = np.zeros(shape = (numFold, numC)) #<! Accuracy per Fold and Model\n",
    "\n",
    "oStrCv = StratifiedKFold(n_splits = numFold, random_state = seedNum, shuffle = True)\n",
    "\n",
    "for ii, (vTrainIdx, vTestIdx) in enumerate(oStrCv.split(mX, vY)):\n",
    "    print(f'Working on Fold #{(ii + 1):02d} Out of {numFold} Folds')\n",
    "    #===========================Fill This===========================#\n",
    "    # Setting the Train / Test split\n",
    "    mXTrain = mX[vTrainIdx, :]\n",
    "    vYTrain = vY[vTrainIdx]\n",
    "    mXTest  = mX[vTestIdx, :]\n",
    "    vYTest  = vY[vTestIdx]\n",
    "    #===============================================================#\n",
    "    for jj, C in enumerate(lC):\n",
    "        print(f'Working on Model #{(jj + 1):02d} Out of {numC} Models with C = {C:0.4f}')\n",
    "        #===========================Fill This===========================#\n",
    "        # Set the model, train, score\n",
    "        # Set `max_iter = maxItr`\n",
    "        # Set `dual = False`\n",
    "        oSvmCls     = LinearSVC(C = C, max_iter = maxItr, dual = False)\n",
    "        # oSvmCls     = SVC(C = C)\n",
    "        oSvmCls     = oSvmCls.fit(mXTrain, vYTrain)\n",
    "        accScore    = oSvmCls.score(mXTest, vYTest)\n",
    "        #===============================================================#\n",
    "        mACC[ii, jj] = accScore\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> How can we accelerate the above calculation? Think about dependency between the scores, does it exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the score per model (Reduction)\n",
    "# Average over the different folds\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "vAvgAcc = np.mean(mACC, axis = 0)\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> In the above we used the mean as the reduction operator of many results into one. Can you think on other?\n",
    "* <font color='blue'>(**!**)</font> Try using a different reduction method and see results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA.plot(lC, vAvgAcc)\n",
    "hA.scatter(lC, vAvgAcc, s = 100)\n",
    "hA.set_title(f'Accuracy Score as a Function of C - Average of {numFold} Folds')\n",
    "hA.set_xlabel('C')\n",
    "hA.set_ylabel('Accuracy')\n",
    "hA.set_xticks(lC)\n",
    "hA.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What range would you choose to do a fine tune over?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "The confusion matrix is almost the whole story for classification problems.  \n",
    "\n",
    "Train the model with the best parameter on the whole data and plot the _Confusion Matrix_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the optimal C\n",
    "# Look at `np.argmax()`\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "optC = lC[np.argmax(vAvgAcc)]\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The optimal C value is C = {optC}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix \n",
    "\n",
    "#===========================Fill This===========================#\n",
    "oSvmCls = LinearSVC(C = optC)\n",
    "oSvmCls = oSvmCls.fit(mX, vY)\n",
    "vYPred = oSvmCls.predict(mX)\n",
    "dScore = {'Accuracy': np.mean(vYPred == vY)}\n",
    "#===============================================================#\n",
    "\n",
    "PlotConfusionMatrix(vY, vYPred, dScore = dScore) #<! The accuracy should be >= than above!\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Is the accuracy above higher or smaller than the one on the _cross validation_? Why?\n",
    "* <font color='blue'>(**!**)</font> Run the above using `SVC()` instead of `LinearSVC()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
