{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Supervised Learning - Regression - Polynomial Fit - Exercise\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 11/02/2023 | Royi Avital | First version                                                      |\n",
    "|         |            |             |                                                                    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethods/2023_01/0023RegressorPolynomialFitExercise.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "#%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "PEOPLE_CSV_URL = 'https://github.com/FixelAlgorithmsTeam/FixelCourses/raw/master/DataSets/People.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixel Algorithms Packages\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Fit\n",
    "\n",
    "In this exercise we'll build an estimator with the Sci Kit Learn API.  \n",
    "The model will employ a 1D Polynomial fit of degree `P`. \n",
    "\n",
    "We'll us the [`People.csv`](https://github.com/FixelAlgorithmsTeam/FixelCourses/blob/master/DataSets/People.csv) data set.  \n",
    "It includes 1000 samples of peoples: Sex, Age, Height (CM), Weight (KG).\n",
    "\n",
    "The objective is to estimate the weight given the height. \n",
    "\n",
    "I this exercise we'll do the following:\n",
    "\n",
    "1. Load the [`People.csv`](https://github.com/FixelAlgorithmsTeam/FixelCourses/blob/master/DataSets/People.csv) data set using `pd.csv_read()`.\n",
    "2. Create a an estimator (Regressor) class using SciKit API:\n",
    "  - Implement the constructor.\n",
    "  - Implement the `fit()`, `predict()` and `score()` methods.\n",
    "3. Verify the estimator vs. `np.polyfit()`.\n",
    "4. Display the output of the model.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> In order to let the classifier know the data is binary / categorical we'll use a **Data Frame** as the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Model\n",
    "polynomDeg = 2\n",
    "\n",
    "# Data Visualization\n",
    "gridNoiseStd = 0.05\n",
    "numGridPts = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def PlotRegressionData( mX: np.ndarray, vY: np.ndarray, hA:plt.Axes = None, figSize: Tuple[int, int] = FIG_SIZE_DEF, elmSize: int = ELM_SIZE_DEF, classColor: Tuple[str, str] = CLASS_COLOR, axisTitle: str = None ) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = figSize)\n",
    "    else:\n",
    "        hF = hA.get_figure()\n",
    "    \n",
    "    if np.ndim(mX) == 1:\n",
    "        mX = np.reshape(mX, (mX.size, 1))\n",
    "\n",
    "    numSamples = len(vY)\n",
    "    numDim     = mX.shape[1]\n",
    "    if (numDim > 2):\n",
    "        raise ValueError(f'The features data must have at most 2 dimensions')\n",
    "    \n",
    "    # Work on 1D, Add support for 2D when needed\n",
    "    # See https://matplotlib.org/stable/api/toolkits/mplot3d.html\n",
    "    hA.scatter(mX[:, 0], vY, s = elmSize, color = classColor[0], edgecolor = 'k', label = f'Samples')\n",
    "    hA.axvline(x = 0, color = 'k')\n",
    "    hA.axhline(y = 0, color = 'k')\n",
    "    hA.set_xlabel('${x}_{1}$')\n",
    "    # hA.axis('equal')\n",
    "    if axisTitle is not None:\n",
    "        hA.set_title(axisTitle)\n",
    "    hA.legend()\n",
    "    \n",
    "    return hA\n",
    "\n",
    "def PlotPolyFit( vX: np.ndarray, vY: np.ndarray, vP: np.ndarray = None, P: int = 1, numGridPts: int = 1001, hA:plt.Axes = None, figSize: Tuple[int, int] = FIG_SIZE_DEF, markerSize: int = MARKER_SIZE_DEF, lineWidth: int = LINE_WIDTH_DEF, axisTitle: str = None ):\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(1, 2, figsize = figSize)\n",
    "    else:\n",
    "        hF = hA[0].get_figure()\n",
    "\n",
    "    numSamples = len(vY)\n",
    "\n",
    "    # Polyfit\n",
    "    vW    = np.polyfit(vX, vY, P)\n",
    "    \n",
    "    # MSE\n",
    "    vHatY = np.polyval(vW, vX)\n",
    "    MSE   = (np.linalg.norm(vY - vHatY) ** 2) / numSamples\n",
    "    \n",
    "    # Plot\n",
    "    xx  = np.linspace(np.floor(np.min(vX)), np.ceil(np.max(vX)), numGridPts)\n",
    "    yy  = np.polyval(vW, xx)\n",
    "\n",
    "    hA[0].plot(vX, vY, '.r', ms = 10, label = '$y_i$')\n",
    "    hA[0].plot(xx, yy, 'b',  lw = 2,  label = '$\\hat{f}(x)$')\n",
    "    hA[0].set_title (f'$P = {P}$\\nMSE = {MSE}')\n",
    "    hA[0].set_xlabel('$x$')\n",
    "    # hA[0].axis(lAxis)\n",
    "    hA[0].grid()\n",
    "    hA[0].legend()\n",
    "    \n",
    "    hA[1].stem(vW[::-1], label = 'Estimated')\n",
    "    if vP is not None:\n",
    "        hA[1].stem(vP[::-1], linefmt = 'C1:', markerfmt = 'D', label = 'Ground Truth')\n",
    "    numTicks = len(vW) if vP is None else max(len(vW), len(vP))\n",
    "    hA[1].set_xticks(range(numTicks))\n",
    "    hA[1].set_title('Coefficients')\n",
    "    hA[1].set_xlabel('$w$')\n",
    "    hA[1].legend()\n",
    "\n",
    "    # return hA\n",
    "\n",
    "\n",
    "def PlotRegResults( vY, vYPred, hA:plt.Axes = None, figSize: Tuple[int, int] = FIG_SIZE_DEF, lineWidth: int = LINE_WIDTH_DEF, elmSize: int = ELM_SIZE_DEF, classColor: Tuple[str, str] = CLASS_COLOR, axisTitle: str = None ) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = figSize)\n",
    "    else:\n",
    "        hF = hA.get_figure()\n",
    "\n",
    "    numSamples = len(vY)\n",
    "    if (numSamples != len(vYPred)):\n",
    "        raise ValueError(f'The inputs `vY` and `vYPred` must have the same number of elements')\n",
    "    \n",
    "    \n",
    "    hA.plot(vY, vY, color = 'r', lw = lineWidth, label = 'Ground Truth')\n",
    "    hA.scatter(vY, vYPred, s = elmSize, color = classColor[0], edgecolor = 'k', label = f'Estimation')\n",
    "    hA.set_xlabel('Label Value')\n",
    "    hA.set_ylabel('Prediction Value')\n",
    "    # hA.axis('equal')\n",
    "    if axisTitle is not None:\n",
    "        hA.set_title(axisTitle)\n",
    "    hA.legend()\n",
    "    \n",
    "    return hA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "In this section we'll load the data form the provided URL.  \n",
    "We'll create a Data Frame of the data and later will separate it into features and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "\n",
    "dfPeople = pd.read_csv(PEOPLE_CSV_URL)\n",
    "\n",
    "dfPeople.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "\n",
    "sns.pairplot(data = dfPeople, hue = 'Sex')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> How would you model the data for the task of estimation of the weight of a person given his sex, age and height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Training Data \n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Extract the 'Height' column into a series `dsX`.\n",
    "# 2. Extract the 'Weight' column into a series `dsY`.\n",
    "dsX = ???\n",
    "dsY = ???\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The features data shape: {dsX.shape}')\n",
    "print(f'The labels data shape: {dsY.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data\n",
    "\n",
    "PlotRegressionData(dsX.to_numpy(), dsY.to_numpy())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Which polynomial order fits the data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polyfit Regressor\n",
    "\n",
    "The PolyFit optimization problem is given by:\n",
    "\n",
    "$$ \\arg \\min_{\\boldsymbol{w}} {\\left\\| \\boldsymbol{\\Phi} \\boldsymbol{w} - \\boldsymbol{y} \\right\\|}_{2}^{2} $$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Phi} = \\begin{bmatrix} 1 & x_{1} & x_{1}^{2} & \\cdots & x_{1}^{p} \\\\\n",
    "1 & x_{2} & x_{2}^{2} & \\cdots & x_{2}^{p} \\\\\n",
    "\\vdots & \\vdots & \\vdots &  & \\vdots \\\\\n",
    "1 & x_{N} & x_{N}^{2} & \\cdots & x_{N}^{p}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is a _polyfit_ with hyper parameter $p$.\n",
    "\n",
    "The optimal weights are calculated by linear system solvers.  \n",
    "Yet it is better to use solvers optimized for this task, such as:\n",
    "\n",
    " * NumPy: [`polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html).\n",
    " * SciKit Learn: [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) combined with [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).\n",
    "\n",
    "In this notebook we'll implement our own class based on SciKit Learn's solutions.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> For arbitrary $\\Phi$ the above becomes a _linear regression_ problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polyfit Estimator\n",
    "\n",
    "We could create the linear polynomial fit estimator using a `Pipeline` of `PolynomialFeatures` and `LinearRegression`.  \n",
    "Yet since this is a simple task it is a good opportunity to exercise the creation of a _SciKit Estimator_.\n",
    "\n",
    "We need to provide 4 main methods:\n",
    "\n",
    "1. The `__init()__` Method: The constructor of the object. It should set the degree of the polynomial model used.\n",
    "2. The `fit()` Method: The training phase. It should calculate the matrix and solve the linear regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyFitRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self, polyDeg = 2):\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Add `polyDeg` as an attribute of the object.\n",
    "        # 2. Add `PolynomialFeatures` object as an attribute of the object.\n",
    "        # 3. Add `LinearRegression` object as an attribute of the object.\n",
    "\n",
    "        # !! Configure `PolynomialFeatures` by the `include_bias` parameter and `LinearRegression` by the `fit_intercept` parameter \n",
    "        # in order to avoid setting the constants columns.\n",
    "        self.polyDeg   = ???\n",
    "        self.oPolyFeat = PolynomialFeatures(degree = ???, interaction_only = ???, include_bias = ???)\n",
    "        self.oLinReg   = LinearRegression(fit_intercept = ???)\n",
    "        #===============================================================#\n",
    "        \n",
    "        # return self #<! The `__init__()` method should not return any value!\n",
    "    \n",
    "    def fit(self, mX, vY):\n",
    "        \n",
    "        if np.ndim(mX) != 2:\n",
    "            raise ValueError(f'The input `mX` must be an array like of size (n_samples, 1) !')\n",
    "        \n",
    "        if mX.shape[1] !=  1:\n",
    "            raise ValueError(f'The input `mX` must be an array like of size (n_samples, 1) !')\n",
    "        \n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Apply `fit_transform()` for the features using `oPolyFeat`.\n",
    "        # 2. Apply `fit()` on the features using `oLinReg`.\n",
    "        # 3. Extract `coef_`, `rank_`, `singluar_`, `intercept_` and `n_features_in_` from `oLinReg`.\n",
    "        # 4. Set `vW_`, as the total weights in the order of the matrix Φ above.\n",
    "        mXX                 = ???\n",
    "        self.oLinReg        = ???\n",
    "        self.coef_          = ???\n",
    "        self.rank_          = ???\n",
    "        self.singular_      = ???\n",
    "        self.intercept_     = ???\n",
    "        self.n_features_in_ = ???\n",
    "        self.vW_            = ???\n",
    "        #===============================================================#\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, mX):\n",
    "\n",
    "        if np.ndim(mX) != 2:\n",
    "            raise ValueError(f'The input `mX` must be an array like of size (n_samples, 1) !')\n",
    "        \n",
    "        if mX.shape[1] !=  1:\n",
    "            raise ValueError(f'The input `mX` must be an array like of size (n_samples, 1) !')\n",
    "        \n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Construct the features matrix.\n",
    "        # 2. Apply the `predict()` method of `oLinReg`.\n",
    "        mXX = ???\n",
    "        vY  = ???\n",
    "        #===============================================================#\n",
    "\n",
    "        return vY\n",
    "    \n",
    "    def score(self, mX, vY):\n",
    "        # Return the RMSE as the score\n",
    "\n",
    "        if (np.size(vY) != np.size(mX, axis = 0)):\n",
    "            raise ValueError(f'The number of samples in `mX` must match the number of labels in `vY`.')\n",
    "\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Apply the prediction on the input features.\n",
    "        # 2. Calculate the RMSE vs. the input labels.\n",
    "        vYPred  = ???\n",
    "        valRmse = ???\n",
    "        #===============================================================#\n",
    "\n",
    "        return valRmse\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The model above will fail on SciKit Learn's `check_estimator()` since it limits to a certain type of input data (Single column matrix) and other things (Setting attributes in `__init__()` etc...). Yet it should work as part of a pipeline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "In this section we'll train the model on the whole data using the class implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Polynomial Regression Object\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Construct the model using the `PolyFitRegressor` class and `polynomDeg`.\n",
    "oPolyFit = ???\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Convert `dsX` into a 2D matrix `mX` of shape `(numSamples, 1)`.\n",
    "# 2. Convert `dsY` in a vector `vY` of shape `(numSamples, )`.\n",
    "# 3. Fit the model using `mX` and `vY`.\n",
    "mX = ???\n",
    "vY = ???\n",
    "\n",
    "oPolyFit = ???\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Coefficients\n",
    "\n",
    "vW = oPolyFit.vW_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Model\n",
    "\n",
    "vWRef = np.polyfit(dsX.to_numpy(), dsY.to_numpy(), deg = polynomDeg)[::-1]\n",
    "\n",
    "for ii in range(polynomDeg + 1):\n",
    "    print(f'The model {ii} coefficient: {vW[ii]}, The reference coefficient: {vWRef[ii]}')\n",
    "\n",
    "maxAbsDev = np.max(np.abs(vW - vWRef))\n",
    "print(f'The maximum absolute deviation: {maxAbsDev}') #<! Should be smaller than 1e-8\n",
    "\n",
    "if (maxAbsDev > 1e-8):\n",
    "    print(f'Error: The implementation of the model is in correct!')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Error and Score\n",
    "\n",
    "When dealing with regression there is a useful visualization which shows the predicted value vs the reference value.  \n",
    "This allows showing the results regardless of the features number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "\n",
    "PlotRegResults(vY, oPolyFit.predict(mX), hA = hA, axisTitle = f'Estimation vs. Ground Truth with RMSE = {oPolyFit.score(mX, vY):0.3f} [KG]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the features are 1D we can also show the prediction as a function of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vXX = np.linspace(120, 220, 2000)\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "\n",
    "modelTxt = '$y = '\n",
    "for ii in range(polynomDeg + 1):\n",
    "    modelTxt += f'({vW[ii]:0.3f}) {{x}}^{{{ii}}} + '\n",
    "\n",
    "modelTxt = modelTxt[:-2]\n",
    "modelTxt += '$'\n",
    "\n",
    "hA.scatter(dsX.to_numpy(), dsY.to_numpy(), color = 'b', label = 'Train Data')\n",
    "hA.plot(vXX, oPolyFit.predict(np.reshape(vXX, (-1, 1))), color = 'r', label = 'Model Estimation')\n",
    "hA.set_title(f'The Linear Regression Model: {modelTxt}')\n",
    "hA.set_xlabel('$x$ - Height [CM]')\n",
    "hA.set_ylabel('$y$ - Weight [KG]')\n",
    "hA.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What did the model predicted?\n",
    "* <font color='blue'>(**!**)</font> Try the above with the model order fo 1 and 3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2e25f61d437a570f4a5ebab9620676b76d9d78268156eb24f90e74ea13ca7ad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
