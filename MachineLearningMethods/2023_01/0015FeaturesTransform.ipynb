{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Supervised Learning - Features Transform\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 26/01/2023 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethods/2023_01/0015FeaturesTransform.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import auc, confusion_matrix, precision_recall_fscore_support, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "#%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF = (8, 8)\n",
    "ELM_SIZE_DEF = 50\n",
    "CLASS_COLOR = ('b', 'r')\n",
    "EDGE_COLOR  = 'k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixel Algorithms Packages\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM by Feature Transform\n",
    "\n",
    "In this notebook we'll imitate the effect of the _Kernel Trick_ using features transform.  \n",
    "We'll use a _XOR Data Set_, where data are located in the 4 quadrants of the $\\mathbb{R}^{2}$ space.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Some useful tutorials on Feature Engineering are given in: [Feature Engine](https://github.com/feature-engine/feature_engine), [Feature Engine Examples](https://github.com/feature-engine/feature-engine-examples), [Python Feature Engineering Cookbook - Jupyter Notebooks](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data Generation\n",
    "numSamples = 250 #<! Per Quarter\n",
    "\n",
    "# Model\n",
    "paramC      = 1\n",
    "kernelType  = 'linear'\n",
    "lC          = [0.1, 0.25, 0.75, 1, 1.5, 2, 3]\n",
    "\n",
    "# Data Visualization\n",
    "numGridPts = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def PlotBinaryClassData( mX: np.ndarray, vY: np.ndarray, hA:plt.Axes = None, figSize: Tuple[int, int] = FIG_SIZE_DEF, elmSize: int = ELM_SIZE_DEF, classColor: Tuple[str, str] = CLASS_COLOR, axisTitle: str = None ) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = figSize)\n",
    "    else:\n",
    "        hF = hA.get_figure()\n",
    "    \n",
    "    vC, vN = np.unique(vY, return_counts = True)\n",
    "\n",
    "    numClass = len(vC)\n",
    "    if (len(vC) != 2):\n",
    "        raise ValueError(f'The input data is not binary, the number of classes is: {numClass}')\n",
    "\n",
    "    vIdx0 = vY == vC[0]\n",
    "    vIdx1 = vY == vC[1] #<! Basically ~vIdx0\n",
    "\n",
    "    hA.scatter(mX[vIdx0, 0], mX[vIdx0, 1], s = elmSize, color = classColor[0], edgecolor = 'k', label = f'$C_\\u007b {vC[0]} \\u007d$')\n",
    "    hA.scatter(mX[vIdx1, 0], mX[vIdx1, 1], s = elmSize, color = classColor[1], edgecolor = 'k', label = f'$C_\\u007b {vC[1]} \\u007d$')\n",
    "    hA.axvline(x = 0, color = 'k')\n",
    "    hA.axhline(y = 0, color = 'k')\n",
    "    hA.axis('equal')\n",
    "    if axisTitle is not None:\n",
    "        hA.set_title(axisTitle)\n",
    "    hA.legend()\n",
    "    \n",
    "    return hA\n",
    "\n",
    "def PlotLabelsHistogram(vY: np.ndarray, hA = None):\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (8, 6))\n",
    "    \n",
    "    vLabels, vCounts = np.unique(vY, return_counts = True)\n",
    "\n",
    "    hA.bar(vLabels, vCounts, width = 0.9, align = 'center')\n",
    "    hA.set_xticks(vLabels)\n",
    "    hA.set_title('Histogram of Classes / Labels')\n",
    "    hA.set_xlabel('Class')\n",
    "    hA.set_ylabel('Number of Samples')\n",
    "\n",
    "    return hA\n",
    "\n",
    "def PlotConfusionMatrix(vY: np.ndarray, vYPred: np.ndarray, hA: plt.Axes = None, lLabels: list = None, dScore: dict = None, titleStr: str = 'Confusion Matrix') -> plt.Axes:\n",
    "\n",
    "    # Calculation of Confusion Matrix\n",
    "    mConfMat = confusion_matrix(vY, vYPred)\n",
    "    oConfMat = ConfusionMatrixDisplay(mConfMat, display_labels = lLabels)\n",
    "    oConfMat = oConfMat.plot(ax = hA)\n",
    "    hA = oConfMat.ax_\n",
    "    if dScore is not None:\n",
    "        titleStr += ':'\n",
    "        for scoreName, scoreVal in  dScore.items():\n",
    "            titleStr += f' {scoreName} = {scoreVal:0.2},'\n",
    "        titleStr = titleStr[:-1]\n",
    "    hA.set_title(titleStr)\n",
    "    hA.grid(False)\n",
    "\n",
    "    return hA\n",
    "\n",
    "\n",
    "def PlotDecisionBoundaryClosure( numGridPts, gridXMin, gridXMax, gridYMin, gridYMax, numDigits = 1 ):\n",
    "\n",
    "    # v0       = np.linspace(gridXMin, gridXMax, numGridPts)\n",
    "    # v1       = np.linspace(gridYMin, gridYMax, numGridPts)\n",
    "    roundFctr = 10 ** numDigits\n",
    "    \n",
    "    # For equal axis\n",
    "    minVal = np.floor(roundFctr * min(gridXMin, gridYMin)) / roundFctr\n",
    "    maxVal = np.ceil(roundFctr * max(gridXMax, gridYMax)) / roundFctr\n",
    "    v0     = np.linspace(minVal, maxVal, numGridPts)\n",
    "    v1     = np.linspace(minVal, maxVal, numGridPts)\n",
    "    \n",
    "    XX0, XX1 = np.meshgrid(v0, v1)\n",
    "    XX       = np.c_[XX0.ravel(), XX1.ravel()]\n",
    "\n",
    "    def PlotDecisionBoundary(hDecFun, hA = None):\n",
    "        \n",
    "        if hA is None:\n",
    "            hF, hA = plt.subplots(figsize = (8, 6))\n",
    "\n",
    "        Z = hDecFun(XX)\n",
    "        Z = Z.reshape(XX0.shape)\n",
    "            \n",
    "        hA.contourf(XX0, XX1, Z, colors = CLASS_COLOR, alpha = 0.3, levels = [-0.5, 0.5, 1.5])\n",
    "\n",
    "        return hA\n",
    "\n",
    "    return PlotDecisionBoundary\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "\n",
    "mX1  = np.random.rand(numSamples, 2) - 0.5 + np.array([ 1,  1]).T\n",
    "mX2  = np.random.rand(numSamples, 2) - 0.5 + np.array([-1, -1]).T\n",
    "mX3  = np.random.rand(numSamples, 2) - 0.5 + np.array([-1,  1]).T\n",
    "mX4  = np.random.rand(numSamples, 2) - 0.5 + np.array([ 1, -1]).T\n",
    "\n",
    "mX = np.concatenate((mX1, mX2, mX3, mX4), axis = 0)\n",
    "vY = np.concatenate((np.full(2 * numSamples, 1), np.full(2 * numSamples, 0)))\n",
    "\n",
    "\n",
    "PlotDecisionBoundary = PlotDecisionBoundaryClosure(numGridPts, -1.5, 1.5, -1.5, 1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data\n",
    "hA = PlotBinaryClassData(mX, vY, axisTitle = 'Samples Data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution by a Linear SVM Classifier\n",
    "\n",
    "In this section we'll try optimize the best Linear SVM model for the problem. \n",
    "\n",
    "* <font color='red'>(**?**)</font> What do you think the decision boundary will be? Think about symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model\n",
    "\n",
    "vAcc = np.zeros(shape = len(lC))\n",
    "\n",
    "for ii, C in enumerate(lC):\n",
    "    oLinSvc  = SVC(C = C, kernel = kernelType).fit(mX, vY)\n",
    "    vAcc[ii] = oLinSvc.score(mX, vY)\n",
    "\n",
    "bestModelIdx    = np.argmax(vAcc)\n",
    "bestC           = lC[bestModelIdx]\n",
    "\n",
    "oLinSvc = SVC(C = bestC, kernel = kernelType).fit(mX, vY)\n",
    "\n",
    "print(f'The best model with C = {bestC:0.2f} achieved accuracy of {vAcc[bestModelIdx]:0.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Decision Boundary\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA = PlotDecisionBoundary(oLinSvc.predict, hA)\n",
    "hA = PlotBinaryClassData(mX, vY, hA = hA, axisTitle = 'Classifier Decision Boundary')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transform\n",
    "\n",
    "In this section we'll a new feature: ${x}_{3} = {x}_{1} \\cdot {x}_{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a set of features with the new feature\n",
    "mXX = np.column_stack((mX, mX[:, 0] * mX[:, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution by Linear SVM Classifier\n",
    "\n",
    "In this section we'll try optimize the best Linear SVM model for the problem.  \n",
    "Yet, we'll train it on the features with the additional transformed one.\n",
    "\n",
    "Then we'll show the decision boundary of the best model.\n",
    "\n",
    "* <font color='red'>(**?**)</font> What do you expect the decision boundary to look like this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model\n",
    "\n",
    "vAcc = np.zeros(shape = len(lC))\n",
    "\n",
    "for ii, C in enumerate(lC):\n",
    "    oLinSvc  = SVC(C = C, kernel = kernelType).fit(mXX, vY) #<! Pay attention we train on `mXX`\n",
    "    vAcc[ii] = oLinSvc.score(mXX, vY)\n",
    "\n",
    "bestModelIdx    = np.argmax(vAcc)\n",
    "bestC           = lC[bestModelIdx]\n",
    "\n",
    "oLinSvc = SVC(C = bestC, kernel = kernelType).fit(mXX, vY)\n",
    "\n",
    "print(f'The best model with C = {bestC:0.2f} achieved accuracy of {vAcc[bestModelIdx]:0.2%}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why was the above `C` gave the best results?\n",
    "* <font color='red'>(**?**)</font> What's the accuracy of all other models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Decision Boundary\n",
    "\n",
    "hPredict = lambda mX: oLinSvc.predict(np.column_stack((mX, mX[:, 0] * mX[:, 1])))\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA = PlotDecisionBoundary(hPredict, hA)\n",
    "hA = PlotBinaryClassData(mX, vY, hA = hA, axisTitle = 'Classifier Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution by Kernel SVM - Polynomial\n",
    "\n",
    "In this section we'll apply a Kernel SVM with Polynomial kernel.\n",
    "\n",
    "* <font color='red'>(**?**)</font> What feature transform is needed for this model?\n",
    "* <font color='red'>(**?**)</font> What's the minimum degree of the polynomial to solve this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Polynomial Model\n",
    "\n",
    "pDegree     = 4\n",
    "kernelType  = 'poly'\n",
    "\n",
    "vAcc = np.zeros(shape = len(lC))\n",
    "\n",
    "for ii, C in enumerate(lC):\n",
    "    oSvc     = SVC(C = C, kernel = kernelType, degree = pDegree).fit(mX, vY)\n",
    "    vAcc[ii] = oSvc.score(mX, vY)\n",
    "\n",
    "bestModelIdx    = np.argmax(vAcc)\n",
    "bestC           = lC[bestModelIdx]\n",
    "\n",
    "oSvc = SVC(C = bestC, kernel = kernelType, degree = pDegree).fit(mX, vY)\n",
    "\n",
    "print(f'The best model with C = {bestC:0.2f} achieved accuracy of {vAcc[bestModelIdx]:0.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Decision Boundary\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA = PlotDecisionBoundary(oSvc.predict, hA)\n",
    "hA = PlotBinaryClassData(mX, vY, hA = hA, axisTitle = 'Classifier Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='green'>(**@**)</font> Do the above with the `rbf` and `sigmoid` kernels.\n",
    "* <font color='blue'>(**!**)</font> Run the above with the kernel `poly` and set `degree` to 100. What happened?\n",
    "* <font color='red'>(**?**)</font> How will the complexity of the calculation grow with the polynomial degree? \n",
    "* <font color='brown'>(**#**)</font> The issues above are the motivation for the _Kernel Trick_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
