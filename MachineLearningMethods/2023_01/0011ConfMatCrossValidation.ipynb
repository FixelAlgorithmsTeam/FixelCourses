{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Supervised Learning - Confusion Matrix and Cross Validation \n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 21/01/2023 | Royi Avital | First version                                                      |\n",
    "|         |            |             |                                                                    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethods/2023_01/0011ConfMatCrossValidation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_predict, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "#%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF = (8, 8)\n",
    "ELM_SIZE_DEF = 50\n",
    "CLASS_COLOR = ('b', 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixel Algorithms Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "numImg  = 3\n",
    "vSize   = [28, 28] #<! Size of images\n",
    "\n",
    "numSamples  = 10_000\n",
    "trainRatio  = 0.55\n",
    "testRatio   = 1 - trainRatio\n",
    "\n",
    "# Data Visualization\n",
    "elmSize     = 50\n",
    "classColor0 = 'b'\n",
    "classColor1 = 'r'\n",
    "\n",
    "numGridPts = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def PlotMnistImages(mX, vY, numImg, hF = None):\n",
    "\n",
    "    numSamples  = mX.shape[0]\n",
    "    numPx       = mX.shape[1]\n",
    "\n",
    "    numRows = int(np.sqrt(numPx))\n",
    "\n",
    "    tFigSize = (numImg * 3, numImg * 3)\n",
    "\n",
    "    if hF is None:\n",
    "        hF, hA = plt.subplots(numImg, numImg, figsize = tFigSize)\n",
    "    else:\n",
    "        hA = hF.axis\n",
    "    \n",
    "    hA = np.atleast_1d(hA) #<! To support numImg = 1\n",
    "    hA = hA.flat\n",
    "\n",
    "    \n",
    "    for kk in range(numImg * numImg):\n",
    "        idx = np.random.choice(numSamples)\n",
    "        mI  = np.reshape(mX[idx, :], (numRows, numRows))\n",
    "    \n",
    "        # hA[kk].imshow(mI.clip(0, 1), cmap = 'gray')\n",
    "        hA[kk].imshow(mI, cmap = 'gray')\n",
    "        hA[kk].tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "        hA[kk].set_title(f'Index = {idx}, Label = {vY[idx]}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def PlotLabelsHistogram(vY: np.ndarray, hA = None):\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (8, 6))\n",
    "    \n",
    "    vLabels, vCounts = np.unique(vY, return_counts = True)\n",
    "\n",
    "    hA.bar(vLabels, vCounts, width = 0.9, align = 'center')\n",
    "    hA.set_title('Histogram of Classes / Labels')\n",
    "    hA.set_xlabel('Class')\n",
    "    hA.set_ylabel('Number of Samples')\n",
    "\n",
    "    return hA\n",
    "\n",
    "def PlotConfusionMatrix(vY: np.ndarray, vYPred: np.ndarray, hA: plt.Axes = None, lLabels: list = None, dScore: dict = None, titleStr: str = 'Confusion Matrix'):\n",
    "\n",
    "    # Calculation of Confusion Matrix\n",
    "    mConfMat = confusion_matrix(vY, vYPred)\n",
    "    oConfMat = ConfusionMatrixDisplay(mConfMat, display_labels = lLabels)\n",
    "    oConfMat = oConfMat.plot(ax = hA)\n",
    "    hA = oConfMat.ax_\n",
    "    if dScore is not None:\n",
    "        titleStr += ':'\n",
    "        for scoreName, scoreVal in  dScore.items():\n",
    "            titleStr += f' {scoreName} = {scoreVal:0.2},'\n",
    "        titleStr = titleStr[:-1]\n",
    "    hA.set_title(titleStr)\n",
    "    hA.grid(False)\n",
    "\n",
    "    return hA\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "mX, vY = fetch_openml('mnist_784', version = 1, return_X_y = True, as_frame = False, parser = 'auto')\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(vY)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing\n",
    "\n",
    "# The image is in the range {0, 1, ..., 255}\n",
    "# We scale it into [0, 1]\n",
    "\n",
    "mX = mX / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Try to do the scaling with `mX /= 255.0`. It will fail, try to understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data has many samples, for fast run time we'll sub sample it\n",
    "\n",
    "vSampleIdx = np.random.choice(mX.shape[0], numSamples, replace = False)\n",
    "mX = mX[vSampleIdx, :]\n",
    "vY = vY[vSampleIdx]\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(vY)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data\n",
    "\n",
    "PlotMnistImages(mX, vY, numImg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Labels\n",
    "\n",
    "When dealing with classification, it is important to know the balance between the labels within the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split\n",
    "\n",
    "In this section we'll split the data into 2 sub sets: _Train_ and _Test_.\n",
    "\n",
    "<font color='red'>(**?**)</font> The split will be random. What could be the issue with that? Think of the balance of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciKit Learn has a built in tool for this split\n",
    "# It can take ratios or integer numbers.\n",
    "# In case only `train_size` or `test_size` is given the other one is the rest of the data.\n",
    "mXTrain, mXTest, vYTrain, vYTest = train_test_split(mX, vY, train_size = trainRatio, test_size = testRatio, random_state = seedNum)\n",
    "\n",
    "print(f'The train features data shape: {mXTrain.shape}')\n",
    "print(f'The train labels data shape: {vYTrain.shape}')\n",
    "print(f'The test features data shape: {mXTest.shape}')\n",
    "print(f'The test labels data shape: {vYTest.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of classes in train data\n",
    "\n",
    "hA = PlotLabelsHistogram(vYTrain)\n",
    "hA.set_title('Histogram of Classes for the Train Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of classes in test data\n",
    "\n",
    "hA = PlotLabelsHistogram(vYTest)\n",
    "hA.set_title('Histogram of Classes for the Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Do you see the same distribution at both sets? What does it mean?\n",
    "* <font color='blue'>(**!**)</font> Use the `stratify` option in `train_test_split()` and look at the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a K-NN Model\n",
    "\n",
    "In this section we'll train a K-NN model on the train data set and test its performance on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1\n",
    "oKnnCls = KNeighborsClassifier(n_neighbors = K)\n",
    "oKnnCls = oKnnCls.fit(mXTrain, vYTrain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>(**?**)</font> What would be the score on the _train set_?  \n",
    "<font color='red'>(**?**)</font> What would be the relation between the performance on the _train set_ vs. _test set_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the Train Set\n",
    "\n",
    "rndIdx  = np.random.randint(mXTrain.shape[0])\n",
    "yPred = oKnnCls.predict(np.atleast_2d(mXTrain[rndIdx, :])) #<! The input must be 2D data\n",
    "PlotMnistImages(np.atleast_2d(mXTrain[rndIdx, :]), yPred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the Test Set\n",
    "\n",
    "rndIdx  = np.random.randint(mXTest.shape[0])\n",
    "yPred = oKnnCls.predict(np.atleast_2d(mXTest[rndIdx, :])) #<! The input must be 2D data\n",
    "PlotMnistImages(np.atleast_2d(mXTest[rndIdx, :]), yPred, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='blue'>(**!**)</font> Find the sample in the train data set which is closest to the sample above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Score on Train and Test Sets\n",
    "\n",
    "In this section we'll evaluate the performance of the model on the train and test sets.  \n",
    "The `SciKit Learn` package has some built in functions / classes to display those: `confusion_matrix()`, `ConfusionMatrixDisplay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the prediction per set\n",
    "vYTrainPred = oKnnCls.predict(mXTrain) #<! Predict train set\n",
    "vYTestPred  = oKnnCls.predict(mXTest)  #<! Predict test set\n",
    "\n",
    "trainAcc = oKnnCls.score(mXTrain, vYTrain)\n",
    "testAcc  = oKnnCls.score(mXTest, vYTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "\n",
    "hF, hA = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 6)) #<! Figure\n",
    "\n",
    "# Arranging data for the plot function\n",
    "lConfMatData = [{'vY': vYTrain, 'vYPred': vYTrainPred, 'hA': hA[0], 'dScore': {'Accuracy': trainAcc}, 'titleStr': 'Train - Confusion Matrix'},\n",
    "{'vY': vYTest, 'vYPred': vYTestPred, 'hA': hA[1], 'dScore': {'Accuracy': testAcc}, 'titleStr': 'Test - Confusion Matrix'}]\n",
    "\n",
    "for ii in range(2):\n",
    "    PlotConfusionMatrix(**lConfMatData[ii])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Look at the most probable error per label, does it make sense?\n",
    "* <font color='red'>(**?**)</font> What do you expect to happen with a different `K`?\n",
    "* <font color='blue'>(**!**)</font> Run the above with different values of `K`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "The _Cross Validation_ process allows us to estimate the stability of performance.  \n",
    "It also the main tool to optimize the model _Hyper Parameters_. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation as a Measure of Test Performance\n",
    "\n",
    "Let's see if indeed the cross validation is a better way to estimate the performance of the test set.  \n",
    "We can do that using _Cross Validation_ on the training set. We'll predict the label of each sample using other data.\n",
    "We'll use a K-Fold Cross Validation with stratified option to keep the data distribution in tact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction the classes using Cross Validation\n",
    "numFold = 10\n",
    "\n",
    "vYTrainPred = cross_val_predict(KNeighborsClassifier(n_neighbors = K), mXTrain, vYTrain, cv = KFold(numFold, shuffle = True))\n",
    "trainAcc = np.mean(vYTrainPred == vYTrain)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='blue'>(**!**)</font> Change the values of `numFold`. Try extreme values. What happens?\n",
    "* <font color='green'>(**@**)</font> Repeat the above with `StratifiedKFold()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "\n",
    "hF, hA = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 6)) #<! Figure\n",
    "\n",
    "# Arranging data for the plot function\n",
    "lConfMatData = [{'vY': vYTrain, 'vYPred': vYTrainPred, 'hA': hA[0], 'dScore': {'Accuracy': trainAcc}, 'titleStr': 'Train - Confusion Matrix'},\n",
    "{'vY': vYTest, 'vYPred': vYTestPred, 'hA': hA[1], 'dScore': {'Accuracy': testAcc}, 'titleStr': 'Test - Confusion Matrix'}]\n",
    "\n",
    "for ii in range(2):\n",
    "    PlotConfusionMatrix(**lConfMatData[ii])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# TODO: Show in percentage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Hyper Parameter Optimization\n",
    "\n",
    "We can also use the _Cross Validation_ approach to search for the best _Hype Parameter_.  \n",
    "The idea is iterating through the data and measure the score we care about.  \n",
    "The hyper parameter which maximize the score will be used for the production model.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Usually, once we set the optimal _hyper parameters_ we'll re train the model on the whole data set.\n",
    "* <font color='brown'>(**#**)</font> We'll learn how to to automate this process later using built in tools, but the idea is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for the K parameters\n",
    "numFold = 10\n",
    "\n",
    "lK = list(range(1, 13, 2)) #<! Range of values of K\n",
    "numK = len(lK)\n",
    "\n",
    "lAcc = [None] * numK\n",
    "\n",
    "for ii, K in enumerate(lK):\n",
    "    vYTrainPred = cross_val_predict(KNeighborsClassifier(n_neighbors = K), mX, vY, cv = StratifiedKFold(numFold, shuffle = True))\n",
    "    lAcc[ii] = np.mean(vYTrainPred == vY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA.plot(lK, lAcc)\n",
    "hA.scatter(lK, lAcc, s = 100)\n",
    "hA.set_title('Accuracy Score as a Function of K')\n",
    "hA.set_xlabel('K')\n",
    "hA.set_ylabel('Accuracy')\n",
    "hA.set_xticks(lK)\n",
    "hA.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What's the optimal `K`?\n",
    "* <font color='red'>(**?**)</font> What's the _Dynamic Range_ of the results? Think again on the question above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
