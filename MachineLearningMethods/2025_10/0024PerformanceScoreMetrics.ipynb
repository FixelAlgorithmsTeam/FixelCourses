{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Supervised Learning - Classification Performance Scores / Metrics: Precision, Recall, ROC and AUC - Exercise\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 15/03/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0036PerformanceScoreMetrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Miscellaneous\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    "```python\n",
    "# You need to start writing\n",
    "?????\n",
    "```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotBinaryClassData, PlotDecisionBoundaryClosure, PlotLabelsHistogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Calibrating the Model Performance\n",
    "\n",
    "In this exercise we'll learn few approaches dealing with imbalanced data and tuning performance:\n",
    "\n",
    " - Resampling.\n",
    " - Weighing (Class / Samples).\n",
    " - Probability Threshold.\n",
    "\n",
    "We'll do that using the SVM model, though they generalize to most models.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Pay attention that in order to have the probability per class on the _SVC_ class we need to set `probability = True`.\n",
    "* <font color='brown'>(**#**)</font> The process of `probability = True` is not always consistent with the `decision_function()` method. Hence it is better to use it in the case of the `SVC`.\n",
    "* <font color='brown'>(**#**)</font> In the above, all approaches are during the training time. One could also search for the best model, score wise, using _Cross Validation_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data Generation\n",
    "numSamples0 = 950\n",
    "numSamples1 = 50\n",
    "\n",
    "noiseLevel = 0.1\n",
    "\n",
    "# Test / Train Loop\n",
    "testSize = 0.5\n",
    "\n",
    "# Model\n",
    "paramC      = 1\n",
    "kernelType  = 'linear'\n",
    "\n",
    "# Data Visualization\n",
    "numGridPts = 250\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data \n",
    "\n",
    "mX, vY = make_moons(n_samples = (numSamples0, numSamples1), noise = noiseLevel)\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(vY)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "# Class Indices\n",
    "vIdx0 = vY == 0\n",
    "vIdx1 = vY == 1\n",
    "\n",
    "# Data Samples by Class\n",
    "mX0 = mX[vIdx0]\n",
    "mX1 = mX[vIdx1]\n",
    "\n",
    "hA = PlotBinaryClassData(mX, vY, axisTitle = 'Samples Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Labels\n",
    "\n",
    "When dealing with classification, it is important to know the balance between the labels within the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Train a model and set the parameter `probability` to `True`.\n",
    "oSVM  = ??? #<! Trained model\n",
    "#===============================================================#\n",
    "\n",
    "modelScore = oSVM.score(mX, vY)\n",
    "\n",
    "print(f'The model score (Accuracy) on the data: {modelScore:0.2%}') #<! Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Decision Boundary\n",
    "\n",
    "We'll display, the linear, decision boundary of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Boundary Plotter (Per Data!)\n",
    "# Look at the implementation for an example for a Closure in Python.\n",
    "\n",
    "PlotDecisionBoundary = PlotDecisionBoundaryClosure(numGridPts, mX[:, 0].min(), mX[:, 0].max(), mX[:, 1].min(), mX[:, 1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Boundary\n",
    "# Plotting the decision boundary.\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA = PlotDecisionBoundary(oSVM.predict, hA)\n",
    "hA = PlotBinaryClassData(mX, vY, hA = hA, axisTitle = 'Classifier Decision Boundary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Confidence Level (Probability)\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Evaluate the decision function for `mX`.\n",
    "# 2. Calculate the probability function for `mX`.\n",
    "# !! You should use the `decision_function()` and `predict_proba()` methods.\n",
    "vD = ??? #<! Apply the decision function of the data set\n",
    "mP = ??? #<! Probabilities per class\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Describe the decision score of the points.\n",
    "* <font color='red'>(**?**)</font> What are the units of `vD` and `mP`? Why do they have different shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Decision Function Output vs. the Probability\n",
    "# The built in probability doesn't match the decision function of the classifier!\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "vSampleIdx = list(range(1, mX.shape[0] + 1))\n",
    "\n",
    "hA.scatter(vSampleIdx, vD > 0, s = 3 * ELM_SIZE_DEF, label = 'Class by Decision Function')\n",
    "hA.scatter(vSampleIdx, np.argmax(mP, axis = 1), s = ELM_SIZE_DEF, label = 'Class by Probability')\n",
    "hA.set_xlabel('Sample Index')\n",
    "hA.set_ylabel('Predicted Class')\n",
    "hA.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Explain the graph. Make sure you understand the calculation.\n",
    "* <font color='red'>(**?**)</font> Which one matches the trained model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Probability Function\n",
    "\n",
    "The `SVC` class uses the [_Platt Scaling_](https://en.wikipedia.org/wiki/Platt_scaling) for estimating the probabilities.  \n",
    "As such, it doesn't always match the results given by the _decision boundary_ (Though it is based on it).\n",
    "\n",
    "In this section an alternative method is presented where:\n",
    "\n",
    "$$ p \\left( \\hat{y}_{i} = 1 \\mid {d}_{i} \\right) = 0.5 \\left( 1 + \\operatorname{sign} \\left( {d}_{i} \\right) \\left( 1 - {e}^{- \\left| {d}_{i} \\right|} \\right) \\right) $$\n",
    "\n",
    "Where ${d}_{i} = \\boldsymbol{w}^{T} \\boldsymbol{x}_{i} - b$ is the \"distance\" of the point (With a sign) form the decision boundary.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The motivation of this function is giving intuition and not being a calibration process of a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What is required for ${d}_{i}$ to be the actual distance?\n",
    "* <font color='red'>(**?**)</font> In binary classification, what would be $p \\left( \\hat{y}_{i} = 0 \\mid {d}_{i} \\right)$? \n",
    "* <font color='red'>(**?**)</font> Are there any points which get probability of $1$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability function for Binary SVM Classifier\n",
    "# Idea is to create function which matches the decision function.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Create the function `SvcBinProb` to assign a probability for the SVC Classifier.\n",
    "# 2. The output is a matrix of shape `(numSamples, 2)`.\n",
    "# 3. Per class calculate the probability as defined above.\n",
    "# !! The input is the per sample output of `decision_function()` method.\n",
    "def SvcBinProb( vD: np.ndarray ) -> np.ndarray:\n",
    "    mP = ??? #<! Pre allocate the output\n",
    "\n",
    "    mP[:, 1] = ??? #<! The probability of the positive class\n",
    "    mP[:, 0] = ??? #<! The probability of the negative class\n",
    "\n",
    "    return mP\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability per Sample per Class\n",
    "# Calculate the probability matrix using `SvcBinProb`.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Calculate the probability matrix.\n",
    "# !! Each class is a column.\n",
    "mP = ???\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify visually that the classification by `mP` and `vD` match\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "vSampleIdx = list(range(1, mX.shape[0] + 1))\n",
    "\n",
    "hA.scatter(vSampleIdx, vD > 0, s = 3 * ELM_SIZE_DEF, label = 'Class by Decision Function')\n",
    "hA.scatter(vSampleIdx, np.argmax(mP, axis = 1), s = ELM_SIZE_DEF, label = 'Class by Probability')\n",
    "hA.set_xlabel('Sample Index')\n",
    "hA.set_ylabel('Predicted Class')\n",
    "hA.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Probability vs. Decision Function\n",
    "# Check programmatically that the classification by `mP` and `vD` match.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "isMatch = ???\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The decision boundary and probability score match: {isMatch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Metrics / Scores\n",
    "\n",
    "In _real world_ the score is used to tune the hyper parameter of the training loop to maximize the real world performance.  \n",
    "In this section we'll show the effect of the tuning on the performance and the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Threshold Tuning\n",
    "\n",
    "Most classifiers have a threshold based decision rule for binary classification.  \n",
    "In many cases it is based on probability on others (Such as in the SVM) on a different confidence function.  \n",
    "\n",
    "In the above we transform the confidence function of the SVM into probability.  \n",
    "Now, we'll use the probability threshold as a way to play with the _working point_ of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics by Probability\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Extract the probability of the positive class.\n",
    "# !! The array `mP` has the probability for both classes.\n",
    "#    Extract from it the probability of Class = 1.\n",
    "\n",
    "vP = ???\n",
    "#===============================================================#\n",
    "\n",
    "vFP, vTP, vThr = roc_curve(vY, vP, pos_label = 1)\n",
    "aucVal         = auc(vFP, vTP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Function\n",
    "\n",
    "hDecFunc = lambda XX, probThr: SvcBinProb(oSVM.decision_function(XX))[:, 1].reshape((numGridPts, numGridPts)) > probThr\n",
    "\n",
    "def PlotRoc( probThr: float ):\n",
    "    _, vAx = plt.subplots(1, 2, figsize = (14, 6))\n",
    "    hA = vAx[0]\n",
    "    hA.plot(vFP, vTP, color = 'b', lw = 3, label = f'AUC = {aucVal:.3f}')\n",
    "    hA.plot([0, 1], [0, 1], color = 'k', lw = 2, linestyle = '--')\n",
    "\n",
    "    vIdx = np.flatnonzero(vThr < probThr)\n",
    "    if vIdx.size == 0:\n",
    "        idx = -1\n",
    "    else:\n",
    "        idx = vIdx[0] - 1\n",
    "\n",
    "    hA.axvline(x = vFP[idx], color = 'g', lw = 2, linestyle = '--')\n",
    "    hA.set_xlabel('False Positive Rate')\n",
    "    hA.set_ylabel('True Positive Rate')\n",
    "    hA.set_title ('ROC')\n",
    "    hA.axis('equal')\n",
    "    hA.legend()\n",
    "    hA.grid()    \n",
    "    \n",
    "    hA = vAx[1]\n",
    "\n",
    "    hA = PlotDecisionBoundary(lambda XX: hDecFunc(XX, probThr), hA)\n",
    "    hA = PlotBinaryClassData(mX, vY, hA = hA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Plot\n",
    "probThrSlider = FloatSlider(min = 0.0, max = 1.0, step = 0.01, value = 0.5, readout_format = '0.2%', layout = Layout(width = '30%'))\n",
    "interact(PlotRoc, probThr = probThrSlider);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "Another way to have a better default classifier for the imbalanced data is to resample the data in a balanced way:\n",
    "\n",
    "![](https://i.imgur.com/kPGo65I.png)\n",
    "\n",
    "* <font color='brown'>(**#**)</font> There is a dedicated Python package for that called [`imbalanced-learn`](https://github.com/scikit-learn-contrib/imbalanced-learn) which automates this.  \n",
    "  It also uses some more advanced tricks. Hence in practice, if you chose resampling approach, use it.\n",
    "* <font color='brown'>(**#**)</font> While in the following example we'll resample the whole data set, in practice we'll do resampling only on the training data set.  \n",
    "  This is in order to avoid _data leakage_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling\n",
    "\n",
    "In case we have enough samples to learn from in the smaller class, this is the way to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under Sample the Class 0 Samples\n",
    "# Using Numpy `choice()` we can resample indices with or without replacement.\n",
    "# In this case we need to undersample, hence with no replacement.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "vIdx0UnderSample = ???\n",
    "mX0UnderSample   = ???\n",
    "#===============================================================#\n",
    "\n",
    "mXS = np.vstack((mX0UnderSample, mX1))\n",
    "vYS = np.concatenate((np.zeros(mX0UnderSample.shape[0], dtype = vY.dtype), np.ones(mX1.shape[0], dtype = vY.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Resampled Data\n",
    "hA = PlotBinaryClassData(mXS, vYS, axisTitle = 'Resampled Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model\n",
    "oSVM  = SVC(C = paramC, kernel = kernelType).fit(mXS, vYS) #<! Fit on the new sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Decision Boundary\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA = PlotDecisionBoundary(oSVM.predict, hA)\n",
    "hA = PlotBinaryClassData(mXS, vYS, hA = hA, axisTitle = 'Classifier Decision Boundary - Resampled Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling\n",
    "\n",
    "In this case we resample the less populated class to have similar number of samples as the more populated class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sample the Class 1 Samples\n",
    "# In this case we'll utilize `choice()` with replacement.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Calculate the number of sample to generate.\n",
    "# 2. Resample from the relevant class. \n",
    "# 3. Create the oversampled data.\n",
    "# !! Make sure you use the `replace` option properly.\n",
    "numSamplesGenerate = ???\n",
    "vIdx1OverSample = ???\n",
    "mX1OverSampleSample = ???\n",
    "#===============================================================#\n",
    "\n",
    "mXS = np.vstack((mX0, mX1OverSampleSample))\n",
    "vYS = np.concatenate((np.zeros(mX0.shape[0], dtype = vY.dtype), np.ones(mX1OverSampleSample.shape[0], dtype = vY.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Resampled Data\n",
    "hA = PlotBinaryClassData(mXS, vYS, axisTitle = 'Resampled Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model\n",
    "oSVM  = SVC(C = paramC, kernel = kernelType).fit(mXS, vYS) #<! Fit on the new sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Decision Boundary\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA = PlotDecisionBoundary(oSVM.predict, hA)\n",
    "hA = PlotBinaryClassData(mXS, vYS, hA = hA, axisTitle = 'Classifier Decision Boundary - Resampled Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Is the result the same as in the _under sample_ method? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Weighing\n",
    "\n",
    "Another approach is changing the weights of the data.  \n",
    "We have 2 methods here:\n",
    "\n",
    " - Weight per Sample  \n",
    "   This is very similar in effect to resample the sample. The difference is having ability for non integer weight.  \n",
    "   It may not be available in all classifiers on SciKit Learn (For example, `SVC` doesn't support this).\n",
    " - Weight per Class  \n",
    "   Applies the weighing on the samples according to their class.   \n",
    "   Usually applied in SciKit Learn under `class_weight`.\n",
    "   It has a `balanced` option which tries to balance imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model - Balanced Weighing\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "oSVM  = ??? #<! Trained model\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Explain the difference between the _class weight_ as part of the model and the `sample weight_ as part of the fitting process.\n",
    "* <font color='red'>(**?**)</font> Can we achieve the same as above using the class weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Decision Boundary\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA = PlotDecisionBoundary(oSVM.predict, hA)\n",
    "hA = PlotBinaryClassData(mX, vY, hA = hA, axisTitle = f'Classifier Decision Boundary: Class 0 Weight = {oSVM.class_weight_[0]:0.2f}, Class 1 Weight = {oSVM.class_weight_[1]:0.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model - Manual Weighing\n",
    "# We'll set the weight of the class 0 to 1, and class 1 to 1000.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "dClassWeight = ??? #<! Weighing dictionary\n",
    "#===========================Fill This===========================#\n",
    "\n",
    "oSVM  = SVC(C = paramC, kernel = kernelType, class_weight = dClassWeight).fit(mX, vY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Decision Boundary\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA = PlotDecisionBoundary(oSVM.predict, hA)\n",
    "hA = PlotBinaryClassData(mX, vY, hA = hA, axisTitle = f'Classifier Decision Boundary: Class 0 Weight = {oSVM.class_weight_[0]:0.2f}, Class 1 Weight = {oSVM.class_weight_[1]:0.2f}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The most efficient way to handle the imbalanced data case is by the _Loss Function_. It is commonly called Cost Sensitive Loss.  \n",
    "  See [Cost Sensitive Support Vector Machines](https://arxiv.org/abs/1212.0975) ([Python Code](https://github.com/airanmehr/cssvm)), [Optimizing for ROC Curves on Class Imbalanced Data by Training over a Family of Loss Functions](https://arxiv.org/abs/2402.05400) ([Python Code](https://github.com/klieberman/roc_lct))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
