{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Exercise 007 - Dimensionality Reduction\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.001 | 07/11/2025 | Royi Avital | Defined an objective                                               |\n",
    "| 0.1.000 | 03/03/2023 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethods/2023_01/Exercise0007DimensionalityReduction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.manifold import Isomap, MDS, SpectralEmbedding, TSNE\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Miscellaneous\n",
    "import gdown\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, List, Tuple\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "DATA_FILE_URL   = r'https://drive.google.com/uc?export=download&confirm=9iBg&id=1UXLdZgXwClgwZVszRq88UaaN2nvgMFiC'\n",
    "DATA_FILE_NAME  = r'BciData.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixel Algorithms Packages\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "In this exercise we'll use _Dimensionality Reduction_ as a feature engineering process.  \n",
    "We'll try 3 different approaches utilize the process: Linear, Non Linear and with manual feature engineering.\n",
    "\n",
    "In this exercise:\n",
    "\n",
    "1. We'll process real world EEG signals to identify movement of body parts.\n",
    "2. We'll use dimensionality reduction with a classifier to identify the part of the body.\n",
    "3. We'll optimize the combination of the dimensionality reduction and the classifier.\n",
    "4. Visualize the features in low dimension (2).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> This exercise won't have single line completions. It will require coding the whole block according to instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "numRowsPlot = 3\n",
    "numColsPlot = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def PlotLabelsHistogram(vY: NDArray, hA = None, lClass = None, xLabelRot: int = None) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (8, 6))\n",
    "    \n",
    "    vLabels, vCounts = np.unique(vY, return_counts = True)\n",
    "\n",
    "    hA.bar(vLabels, vCounts, width = 0.9, align = 'center')\n",
    "    hA.set_title('Histogram of Classes / Labels')\n",
    "    hA.set_xlabel('Class')\n",
    "    hA.set_ylabel('Number of Samples')\n",
    "    hA.set_xticks(vLabels)\n",
    "    if lClass is not None:\n",
    "        hA.set_xticklabels(lClass)\n",
    "    \n",
    "    if xLabelRot is not None:\n",
    "        for xLabel in hA.get_xticklabels():\n",
    "            xLabel.set_rotation(xLabelRot)\n",
    "\n",
    "    return hA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "In this exercise we'll use the Brain Computer Interfaces (BCI) Data from [BCI Competition IV](https://www.bbci.de/competition/iv/).  \n",
    "Specifically we'll use [data set 2a](https://www.bbci.de/competition/iv/#dataset2a) provided by the Institute for Knowledge Discovery (Laboratory of Brain-Computer Interfaces), Graz University of Technology, (Clemens Brunner, Robert Leeb, Gernot Müller-Putz, Alois Schlögl, Gert Pfurtscheller).  \n",
    "This is a recording of EEG signals while the subject is doing a cued movement of the left hand, right hand, feet or tongue.\n",
    "\n",
    "The data is composed of:\n",
    "\n",
    " * 22 EEG channels (0.5-100Hz; notch filtered).\n",
    " * 4 classes: left hand, right hand, feet, tongue.\n",
    " * 9 subjects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "# This section downloads data from the given URL if needed.\n",
    "# If it fails, download the data manually.\n",
    "\n",
    "if not os.path.exists(DATA_FILE_NAME):\n",
    "    gdown.download(DATA_FILE_URL, DATA_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading / Generating Data\n",
    "\n",
    "dData = np.load(DATA_FILE_NAME)\n",
    "mX    = dData['mX1']\n",
    "vY    = dData['vY1']\n",
    "\n",
    "# Sample: An observation of a subject.\n",
    "# Measurement: Sample in time of the EEG signal.\n",
    "# Channel: EEG Channel.\n",
    "numSamples, numMeasurements, numChannels = mX.shape \n",
    "lLabel = ['Left Hand', 'Right Hand', 'Foot', 'Tongue'] #<! The labels\n",
    "\n",
    "print(f'The data shape: {mX.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process Data\n",
    "\n",
    "Scale the pixels into the [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Image\n",
    "\n",
    "numPlots = numRowsPlot * numColsPlot\n",
    "\n",
    "hF, hAs = plt.subplots(nrows = numRowsPlot, ncols = numColsPlot, figsize = (18, 10))\n",
    "hAs = hAs.flat\n",
    "\n",
    "vIdx = np.random.choice(numSamples, numPlots, replace = False)\n",
    "\n",
    "for sampleIdx, hA in zip(vIdx, hAs):\n",
    "    mXX = mX[sampleIdx, :, :]\n",
    "    hA.plot(mXX)\n",
    "    hA.set_title(f'EEG Signals of Sample {sampleIdx:04d} with Label {lLabel[vY[sampleIdx]]}')\n",
    "    hA.set_xlabel('Measurement Index')\n",
    "    hA.set_ylabel('Measurement Value')\n",
    "\n",
    "hF.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY, lClass = lLabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What score would you use in the case above?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 001\n",
    "\n",
    "In this model we'll use a linear combination of the features with a classifier.  \n",
    "The cross validation is _leave one out_ using `cross_val_predict()`.\n",
    "\n",
    "1. Transform data into `(numSamples, numMeasurements x numChannels)`.\n",
    "2. Apply PCA with the optimal number of components.\n",
    "3. Use a **non ensemble** classifier of your choice.\n",
    "\n",
    "**Objective**: Above 35% accuracy in _Leave One Out_ cross validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What's the maximum number of components of the PCA you may use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?????"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 002\n",
    "\n",
    "In this model we'll use the covariance matrix of the data as a feature.  \n",
    "Basically we want to take advantage of the interaction between the different channels.\n",
    "\n",
    "Do the following steps:\n",
    "\n",
    "1. For each sample $\\boldsymbol{X}_{i}\\in\\mathbb{R}^{1000 \\times 22}$, compute the covariance matrix $\\boldsymbol{C}_{i}\\in\\mathbb{R}^{22\\times22}$.  \n",
    "   You may use [`np.cov()`](https://numpy.org/doc/stable/reference/generated/numpy.cov.html).\n",
    "2. Set $\\boldsymbol{c}_{i}\\in\\mathbb{R}^{22^{2}}$ as the columns stack version of each $\\boldsymbol{C}_{i}\\in\\mathbb{R}^{22 \\times 22}$.  \n",
    "   You may use [`np.reshape()`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html).\n",
    "4. Build the feature matrix based on $\\boldsymbol{c}_{i}$.\n",
    "5. Analyze the separation using a non linear dimensionality reduction model (Use `vY` for the colorization of data).\n",
    "6. Use an ensemble based classifier.\n",
    "\n",
    "You should optimize the combination of the classification model and the dimensionality reduction model.\n",
    "\n",
    "**Objective**: Above 50% accuracy in _Leave One Out_ cross validation.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You should also try no dimensionality reduction as well.\n",
    "* <font color='brown'>(**#**)</font> If you use `t-SNE`, out of consideration for _run time_, you may want to apply `PCA` before in order to reduce the data into ~50 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?????"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 003\n",
    "\n",
    "In this model we'll use the covariance matrix of the data as a feature.  \n",
    "Yet, we'll add a covariance matrix specific metric, the SPD Metric (`SpdMetric`):\n",
    "\n",
    "$$d\\left(\\boldsymbol{C}_{i},\\boldsymbol{C}_{j}\\right)=\\sqrt{\\sum_{i=1}^{d}\\log^{2}\\left(\\lambda_{i}\\left(\\boldsymbol{C}_{i}^{-1}\\boldsymbol{C}_{j}\\right)\\right)}$$\n",
    "\n",
    "Where ${\\lambda}_{i} \\left( \\cdot \\right)$ extract the $i$ -th eigen value of the matrix.\n",
    "\n",
    "We'll use this metric to apply a metric aware dimensionality reduction.\n",
    "\n",
    "Do the following steps:\n",
    "\n",
    "1. Implement the `SpdMetric` metric.  \n",
    "   The function `SpdMetric()` input is 2 column stacked covariance matrix $\\boldsymbol{c}_{i}$ and $\\boldsymbol{c}_{j}$.  \n",
    "   The function reshapes them back to the two matrices $\\boldsymbol{C}_{i}$ and $\\boldsymbol{C}_{j}$ and returns $d\\left(\\boldsymbol{C}_{i},\\boldsymbol{C}_{j}\\right)$.\n",
    "2. Based covariance features from _Model 002_ build a distance matrix `mD` based on the metric above.  \n",
    "   Namely `mD[ii, jj]` should be the distance between the covariance matrix of the `ii` sample to the `jj` sample.\n",
    "5. Analyze the separation using a non linear dimensionality reduction model (Use `vY` for the colorization of data).  \n",
    "   Make sure to utilize the distance function above.\n",
    "6. Use an ensemble based classifier applied on the dimensionality reduced data.\n",
    "\n",
    "You should optimize the combination of the classification model and the dimensionality reduction model.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may use `sp.linalg.eigvalsh(mCi, mCj)` to calculate $ \\lambda_{i}\\left(\\boldsymbol{C}_{i}^{-1}\\boldsymbol{C}_{j}\\right) $.\n",
    "\n",
    "**Objective**: Above 75% accuracy in _Leave One Out_ cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
