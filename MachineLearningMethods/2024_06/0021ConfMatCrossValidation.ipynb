{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io/)\n",
    "\n",
    "# Machine Learning Methods\n",
    "\n",
    "## Supervised Learning - Classification - Confusion Matrix and Cross Validation\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.001 | 17/03/2024 | Royi Avital | Feedback on class                                                  |\n",
    "| 1.0.000 | 10/03/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0033ConfMatCrossValidation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import cross_val_predict, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Image Processing\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "# Miscellaneous\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    " ```python\n",
    " vallToFill = ???\n",
    " ```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "???\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotConfusionMatrix, PlotLabelsHistogram, PlotMnistImages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data Generation\n",
    "numImg  = 3\n",
    "vSize   = [28, 28] #<! Size of images\n",
    "\n",
    "numSamples  = 10_000\n",
    "trainRatio  = 0.55\n",
    "testRatio   = 1 - trainRatio\n",
    "\n",
    "\n",
    "# Data Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "The _MNIST_ database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits.  \n",
    "The MNIST data is a well known data set in Machine Learning, basically it is the _Hello World_ of ML.\n",
    "\n",
    "The original black and white images from NIST were normalized to fit into a `28x28` pixel bounding box and anti aliased.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> A great EDA on the MNIST data is given at [Exploring Handwritten Digit Classification: A Tidy Analysis of the MNIST Dataset](http://varianceexplained.org/r/digit-eda).\n",
    "* <font color='brown'>(**#**)</font> There is an extended version called [EMNIST](https://arxiv.org/abs/1702.05373).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data \n",
    "\n",
    "mX, vY = fetch_openml('mnist_784', version = 1, return_X_y = True, as_frame = False, parser = 'auto')\n",
    "vY = vY.astype(np.int_) #<! The labels are strings, convert to integer\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(vY)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Data\n",
    "# Scaling the data values.\n",
    "\n",
    "# The image is in the range {0, 1, ..., 255}.\n",
    "# We scale it into [0, 1].\n",
    "\n",
    "mX = mX / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Try to do the scaling with `mX /= 255.0`. It will fail, try to understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sub Sampling\n",
    "# The data has many samples, for fast run time we'll sub sample it\n",
    "\n",
    "vSampleIdx = np.random.choice(mX.shape[0], numSamples, replace = False)\n",
    "mX = mX[vSampleIdx, :]\n",
    "vY = vY[vSampleIdx]\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(vY)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF = PlotMnistImages(mX, vY, numImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Labels\n",
    "\n",
    "When dealing with classification, it is important to know the balance between the labels within the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Looking at the _histogram_ of labels, Is the data balanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split\n",
    "\n",
    "In this section we'll split the data into 2 sub sets: _Train_ and _Test_.  \n",
    "The relevant function in SciKit Learn is [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "* <font color='red'>(**?**)</font> The split will be random. What could be the issue with that? Think of the balance of labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Test Split\n",
    "# SciKit Learn has a built in tool for this split.\n",
    "# It can take ratios or integer numbers.\n",
    "# In case only `train_size` or `test_size` is given the other one is the rest of the data.\n",
    "mXTrain, mXTest, vYTrain, vYTest = train_test_split(mX, vY, train_size = trainRatio, test_size = testRatio, random_state = seedNum)\n",
    "\n",
    "print(f'The train features data shape: {mXTrain.shape}')\n",
    "print(f'The train labels data shape: {vYTrain.shape}')\n",
    "print(f'The test features data shape: {mXTest.shape}')\n",
    "print(f'The test labels data shape: {vYTest.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Labels (Train)\n",
    "# Distribution of classes in train data.\n",
    "\n",
    "hA = PlotLabelsHistogram(vYTrain)\n",
    "hA.set_title('Histogram of Classes for the Train Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Labels (Test)\n",
    "# Distribution of classes in test data.\n",
    "\n",
    "hA = PlotLabelsHistogram(vYTest)\n",
    "hA.set_title('Histogram of Classes for the Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Do you see the same distribution at both sets? What does it mean?\n",
    "* <font color='blue'>(**!**)</font> Use the `stratify` option in `train_test_split()` and look at the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a K-NN Model\n",
    "\n",
    "In this section we'll train a K-NN model on the train data set and test its performance on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN Model\n",
    "K = 1\n",
    "oKnnCls = KNeighborsClassifier(n_neighbors = K)\n",
    "oKnnCls = oKnnCls.fit(mXTrain, vYTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>(**?**)</font> What would be the score on the _train set_?  \n",
    "<font color='red'>(**?**)</font> What would be the relation between the performance on the _train set_ vs. _test set_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the Train Set\n",
    "\n",
    "rndIdx  = np.random.randint(mXTrain.shape[0])\n",
    "yPred = oKnnCls.predict(np.atleast_2d(mXTrain[rndIdx, :])) #<! The input must be 2D data\n",
    "hF = PlotMnistImages(np.atleast_2d(mXTrain[rndIdx, :]), yPred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the Test Set\n",
    "\n",
    "rndIdx  = np.random.randint(mXTest.shape[0])\n",
    "yPred = oKnnCls.predict(np.atleast_2d(mXTest[rndIdx, :])) #<! The input must be 2D data\n",
    "hF = PlotMnistImages(np.atleast_2d(mXTest[rndIdx, :]), yPred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='blue'>(**!**)</font> Find the sample in the train data set which is closest to the sample above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Score on Train and Test Sets\n",
    "\n",
    "In this section we'll evaluate the performance of the model on the train and test sets.  \n",
    "The `SciKit Learn` package has some built in functions / classes to display those: `confusion_matrix()`, `ConfusionMatrixDisplay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "# Computing the prediction per set.\n",
    "vYTrainPred = oKnnCls.predict(mXTrain) #<! Predict train set\n",
    "vYTestPred  = oKnnCls.predict(mXTest)  #<! Predict test set\n",
    "\n",
    "trainAcc = oKnnCls.score(mXTrain, vYTrain)\n",
    "testAcc  = oKnnCls.score(mXTest, vYTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "\n",
    "hF, hA = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 6)) #<! Figure\n",
    "\n",
    "# Arranging data for the plot function\n",
    "lConfMatData = [{'vY': vYTrain, 'vYPred': vYTrainPred, 'hA': hA[0], 'dScore': {'Accuracy': trainAcc}, 'titleStr': 'Train - Confusion Matrix'},\n",
    "{'vY': vYTest, 'vYPred': vYTestPred, 'hA': hA[1], 'dScore': {'Accuracy': testAcc}, 'titleStr': 'Test - Confusion Matrix'}]\n",
    "\n",
    "for ii in range(2):\n",
    "    PlotConfusionMatrix(**lConfMatData[ii])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Look at the most probable error per label, does it make sense?\n",
    "* <font color='red'>(**?**)</font> What do you expect to happen with a different `K`?\n",
    "* <font color='blue'>(**!**)</font> Run the above with different values of `K`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "The _Cross Validation_ allows:\n",
    "\n",
    "1. Estimate the stability of performance (Different scores per fold).  \n",
    "   By applying a reduction (For instance, _averaging_) on the scores per fold, estimate the _real world performance_ (Like a _Test Set_).  \n",
    "2. Optimize the model _Hyper Parameters_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation as a Measure of Test Performance\n",
    "\n",
    "Let's see if indeed the cross validation is a better way to estimate the performance of the test set.  \n",
    "We can do that using _Cross Validation_ on the training set. We'll predict the label of each sample using other data.  \n",
    "We'll use a K-Fold Cross Validation with stratified option to keep the data distribution in tact.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> SciKit Learn's classes for K-Fold CV: [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html).\n",
    "* <font color='brown'>(**#**)</font> SciKit Learn has a function to apply _cross validation_ and return the **prediction** of each fold: [`cross_val_predict()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html).  \n",
    "  This allows a manual analysis of the estimator prediction output.\n",
    "* <font color='brown'>(**#**)</font> SciKit Learn has a function to apply _cross validation_ and return the **score** of each fold: [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html).  \n",
    "  This allows a manual analysis of the estimator score output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation & Predict\n",
    "# Prediction the classes using Cross Validation.\n",
    "numFold = 10\n",
    "\n",
    "# Returns the prediction (Label) per each sample\n",
    "vYTrainPred = cross_val_predict(KNeighborsClassifier(n_neighbors = K), mXTrain, vYTrain, cv = KFold(numFold, shuffle = True))\n",
    "trainAcc = np.mean(vYTrainPred == vYTrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='blue'>(**!**)</font> Change the values of `numFold`. Try extreme values. What happens?\n",
    "* <font color='green'>(**@**)</font> Repeat the above with `StratifiedKFold()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "\n",
    "hF, hA = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 6)) #<! Figure\n",
    "\n",
    "# Arranging data for the plot function\n",
    "lConfMatData = [{'vY': vYTrain, 'vYPred': vYTrainPred, 'hA': hA[0], 'dScore': {'Accuracy': trainAcc}, 'titleStr': 'Train - Confusion Matrix'},\n",
    "{'vY': vYTest, 'vYPred': vYTestPred, 'hA': hA[1], 'dScore': {'Accuracy': testAcc}, 'titleStr': 'Test - Confusion Matrix'}]\n",
    "\n",
    "for ii in range(2):\n",
    "    PlotConfusionMatrix(**lConfMatData[ii])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Was the the CV a good estimator of the performance of the test set?\n",
    "* <font color='blue'>(**!**)</font> Use the `normMethod` parameter to normalize the confusion matrix by rows, columns or all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Hyper Parameter Optimization\n",
    "\n",
    "We can also use the _Cross Validation_ approach to search for the best _Hype Parameter_.  \n",
    "The idea is iterating through the data and measure the score we care about.  \n",
    "The hyper parameter which maximize the score will be used for the production model.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Usually, once we set the optimal _hyper parameters_ we'll re train the model on the whole data set.\n",
    "* <font color='brown'>(**#**)</font> We'll learn how to to automate this process later using built in tools, but the idea is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for the K parameters\n",
    "numFold = 10\n",
    "\n",
    "lK = list(range(1, 13, 2)) #<! Range of values of K\n",
    "numK = len(lK)\n",
    "\n",
    "lAcc = [None] * numK\n",
    "\n",
    "for ii, K in enumerate(lK):\n",
    "    vYTrainPred = cross_val_predict(KNeighborsClassifier(n_neighbors = K), mX, vY, cv = StratifiedKFold(numFold, shuffle = True))\n",
    "    lAcc[ii] = np.mean(vYTrainPred == vY) #<! Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "hA.plot(lK, lAcc)\n",
    "hA.scatter(lK, lAcc, s = 100)\n",
    "hA.set_title('Accuracy Score as a Function of K')\n",
    "hA.set_xlabel('K')\n",
    "hA.set_ylabel('Accuracy')\n",
    "hA.set_xticks(lK)\n",
    "hA.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What's the optimal `K`?\n",
    "* <font color='red'>(**?**)</font> What's the _Dynamic Range_ of the results? Think again on the question above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
