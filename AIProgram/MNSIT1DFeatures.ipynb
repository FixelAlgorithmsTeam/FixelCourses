{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - Supervised Learning - Ensemble Methods - MNIST by 1D Features\n",
    "\n",
    "The notebook is based on [Aaron Zuspan - Classifying MNIST as 1D Signals](https://www.aazuspan.dev/blog/classifying-mnist-as-1d-signals).\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 25/08/2025 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0002PointLine.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:52:07.921383Z",
     "start_time": "2022-02-02T17:52:07.649130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Scientific Python\n",
    "\n",
    "# Image Processing & Computer Vision\n",
    "import skimage as ski\n",
    "\n",
    "# Machine Learning\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pycatch22\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "\n",
    "# Miscellaneous\n",
    "import math\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing \n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Visualization\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ?????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "# sns.set_palette(\"tab10\")\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "TU_MNIST_IMG_SIZE = (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def ConvertDataSet( mX: NDArray, /, *, resampleRes: Optional[int] = None ) -> NDArray:\n",
    "    # mX: (numSamples, 768) MNIST like Array\n",
    "    numSamples = np.size(mX, 0)\n",
    "\n",
    "    tI = np.reshape(mX, (-1, 28, 28)) #<! The last dimension is contiguous\n",
    "    tI = np.transpose(tI, (1, 2, 0))\n",
    "\n",
    "    if resampleRes is not None:\n",
    "        tI = ski.transform.resize(tI, (resampleRes, resampleRes))\n",
    "    \n",
    "    tP = ski.transform.warp_polar(tI, channel_axis = 2) #<! Polar (360, radius)\n",
    "    mP = np.sum(tP, axis = 1) #<! (360, numSamples)\n",
    "\n",
    "    return mP.T #<! Return a matrix of (numSamples, numFeatures)\n",
    "\n",
    "def PlotMnistImages( mX: np.ndarray, vY: np.ndarray, numRows: int, numCols: Optional[int] = None, tuImgSize: Tuple = (28, 28), randomChoice: bool = True, lClasses: Optional[List] = None, hF: Optional[plt.Figure] = None ) -> plt.Figure:\n",
    "\n",
    "    numSamples  = mX.shape[0]\n",
    "    numPx       = mX.shape[1]\n",
    "\n",
    "    if numCols is None:\n",
    "        numCols = numRows\n",
    "\n",
    "    tFigSize = (numCols * 3, numRows * 3)\n",
    "\n",
    "    if hF is None:\n",
    "        hF, hA = plt.subplots(numRows, numCols, figsize = tFigSize)\n",
    "    else:\n",
    "        hA = hF.axes\n",
    "    \n",
    "    hA = np.atleast_1d(hA) #<! To support numImg = 1\n",
    "    hA = hA.flat\n",
    "    \n",
    "    for kk in range(numRows * numCols):\n",
    "        idx = np.random.choice(numSamples) if randomChoice else kk\n",
    "        mI  = np.reshape(mX[idx, :], tuImgSize)\n",
    "    \n",
    "        # hA[kk].imshow(mI.clip(0, 1), cmap = 'gray')\n",
    "        if len(tuImgSize) == 2:\n",
    "            hA[kk].imshow(mI, cmap = 'gray')\n",
    "        elif len(tuImgSize) == 3:\n",
    "            hA[kk].imshow(mI)\n",
    "        else:\n",
    "            raise ValueError(f'The length of the image size tuple is {len(tuImgSize)} which is not supported')\n",
    "        hA[kk].tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, \n",
    "                           labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "        if lClasses is None:\n",
    "            hA[kk].set_title(f'Index = {idx}, Label = {vY[idx]}')\n",
    "        else:\n",
    "            hA[kk].set_title(f'Index = {idx}, Label = {lClasses[vY[idx]]}')\n",
    "    \n",
    "    return hF\n",
    "\n",
    "def PlotLabelsHistogram( vY: np.ndarray, hA: Optional[plt.Axes] = None, lClass: Optional[List] = None, xLabelRot: Optional[int] = None ) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (8, 6))\n",
    "    \n",
    "    vLabels, vCounts = np.unique(vY, return_counts = True)\n",
    "\n",
    "    hA.bar(vLabels, vCounts, width = 0.9, align = 'center')\n",
    "    hA.set_title('Histogram of Classes / Labels')\n",
    "    hA.set_xlabel('Class')\n",
    "    hA.set_xticks(vLabels, [f'{labelVal}' for labelVal in vLabels])\n",
    "    hA.set_ylabel('Count')\n",
    "    if lClass is not None:\n",
    "        hA.set_xticklabels(lClass)\n",
    "    \n",
    "    if xLabelRot is not None:\n",
    "        for xLabel in hA.get_xticklabels():\n",
    "            xLabel.set_rotation(xLabelRot)\n",
    "\n",
    "    return hA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "The role of feature engineering in the Machine Learning Pipeline in transforming the data in an optimal task oriented representation.\n",
    "\n",
    "![](https://i.imgur.com/28w7PJs.png)\n",
    "<!-- ![](https://i.postimg.cc/6qtzY9YV/image.png) -->\n",
    "\n",
    "The potential effect of _Feature Engineering_ on the quality of th process is significant. \n",
    "Specifically, in Classic _Machine Learning_, it is the most important step.\n",
    "\n",
    "Feature Engineering processing may include:\n",
    " - Feature Generation / Extraction.  \n",
    "   Generate new feature from the given data.  \n",
    "   <font color='magenta'>Example</font>: Extract the Day of Week from the date.  \n",
    "   <font color='magenta'>Example</font>: Calculate the _Skewness_ and _Kurtosis_ of the sample.\n",
    " - Feature Transform.  \n",
    "   Apply a function to generate a different representation for the feature.  \n",
    "   <font color='magenta'>Example</font>: Normalization of the features.  \n",
    "   <font color='magenta'>Example</font>: Use Polar coordinates.  \n",
    "   <font color='magenta'>Example</font>: Use the _Kernel Trick_.\n",
    " - Feature Selection.  \n",
    "   Reducing the number of features to a smaller set of features.  \n",
    "   Either selecting a sub sample of the features (\"Hard\") or by a combination (\"Soft\").  \n",
    "   The \"Soft\" approach is often applied by a Linear / Non Linear _Dimensionality Reduction_.  \n",
    "   <font color='magenta'>Example</font>: Selection by Feature Importance analysis (_Permutation Importance_).  \n",
    "   <font color='magenta'>Example</font>: Apply PCA or UMAP on the data.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Mathematically \"Feature Transform\" generalizes all cases.\n",
    "* <font color='brown'>(**#**)</font> If some transformation is applied during training, the same transformation should be applied in test (Production).\n",
    "* <font color='brown'>(**#**)</font> _Data Leakage_ is a common mistake during the feature engineering phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features for 1D Signal Classification\n",
    "\n",
    "One way to classify different features of 1D signals would be:\n",
    "\n",
    " - Statistical Features  \n",
    "   Treat the data as a set of values.    \n",
    "   Summarize data using descriptive statistics.  \n",
    "   Insensitive to the ordering of observations are included in this set.  \n",
    "   <font color='magenta'>Example</font>: Mean, Variance, Skewness, Kurtosis, Percentiles, Entropy.\n",
    " - Temporal Features  \n",
    "   Features analyze the changes and patterns in data over time.  \n",
    "   Sensitive to the order of the samples.  \n",
    "   Captures temporal correlations, trends and rate of changes.  \n",
    "   <font color='magenta'>Example</font>: Mean, Variance, Skewness, Kurtosis, Percentiles.\n",
    " - Spectral Features\n",
    " - Structural Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "numSamplesTrain = 9_000\n",
    "numSamplesTest  = 1_000\n",
    "\n",
    "numImg = 3\n",
    "\n",
    "# Features\n",
    "resampleRes = 56\n",
    "\n",
    "# Visualization\n",
    "exportFig = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MNIST Dataset\n",
    "\n",
    "The MNIST Data Set s the \"Hello World\" dataset of Machine Learning.\n",
    "\n",
    "\n",
    "* <font color='red'>(**?**)</font> Will the solution of the Squared Euclidean Distance be the same as the Euclidean Distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:53:07.834772Z",
     "start_time": "2022-02-02T17:53:07.448832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate / Load Data \n",
    "\n",
    "mX, vY = fetch_openml('mnist_784', version = 1, return_X_y = True, as_frame = False, parser = 'auto')\n",
    "vY = vY.astype(np.int_) #<! The labels are strings, convert to integer\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(vY)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing\n",
    "\n",
    "# The image is in the range {0, 1, ..., 255}\n",
    "# We scale it into [0, 1]\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Scale the values into the [0, 1] range.\n",
    "mX = mX / 255.0\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Split the data such that the Train Data has `numSamplesTrain`.\n",
    "# 2. Split the data such that the Test Data has `numSamplesTest`.\n",
    "# 3. The distribution of the classes must match the original data.\n",
    "\n",
    "numClass = len(np.unique(vY))\n",
    "mXTrain, mXTest, vYTrain, vYTest = train_test_split(mX, vY, test_size = numSamplesTest, train_size = numSamplesTrain, shuffle = True, stratify = vY)\n",
    "\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The training features data shape: {mXTrain.shape}')\n",
    "print(f'The training labels data shape  : {vYTrain.shape}')\n",
    "print(f'The test features data shape    : {mXTest.shape}')\n",
    "print(f'The test labels data shape      : {vYTest.shape}')\n",
    "print(f'The unique values of the labels : {np.unique(vY)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF = PlotMnistImages(mX, vY, numImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Image per Class\n",
    "\n",
    "tI = np.zeros(shape = (numClass, ) + TU_MNIST_IMG_SIZE)\n",
    "\n",
    "for ii in range(numClass):\n",
    "    vIdx = vY == ii\n",
    "    vF = np.mean(mX[vIdx], axis = 0) #<! (numFeatures, )\n",
    "    tI[ii] = np.reshape(vF, TU_MNIST_IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Images\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = numClass, figsize = (18, 2))\n",
    "vHa = vHa.flat\n",
    "\n",
    "for ii, hA in enumerate(vHa):\n",
    "    hA.imshow(tI[ii], cmap = 'gray')\n",
    "    hA.tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, \n",
    "                   labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "    hA.set_title(f'Label {ii}')\n",
    "\n",
    "hF.suptitle('Mean Class Image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartesian and Polar Coordinate Systems\n",
    "\n",
    "Main motivation is to transform rotations into translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartesian and Polar Coordinates for an Image\n",
    "\n",
    "hF = plt.figure(figsize = (8, 4))\n",
    "\n",
    "hAxCart  = hF.add_subplot(1, 2, 1)\n",
    "hAxPolar = hF.add_subplot(1, 2, 2, projection = 'polar')\n",
    "\n",
    "# Cartesian Grid\n",
    "Nx, Ny = 8, 8                   # grid size\n",
    "hAxCart.set_xlim(0, Nx)\n",
    "hAxCart.set_ylim(Ny, 0)         # y grows downward (like images)\n",
    "hAxCart.set_aspect('equal')\n",
    "\n",
    "# Grid\n",
    "for x in range(Nx + 1):\n",
    "    hAxCart.axvline(x, color = '0.75', lw = 1)\n",
    "for y in range(Ny + 1):\n",
    "    hAxCart.axhline(y, color = '0.75', lw = 1)\n",
    "\n",
    "# Image in (x, y) Discrete Coordinates (1 based)\n",
    "# Highlight pixel (6, 3) \n",
    "px, py = 6, 3\n",
    "patchRect = Rectangle((px - 1, py - 1), 1, 1, facecolor = '0.7', edgecolor = 'k')\n",
    "hAxCart.add_patch(patchRect)\n",
    "\n",
    "# Annotations\n",
    "hAxCart.annotate('Pixel (6, 3)', xy = (px - 0.5, py - 0.5),\n",
    "                 xytext = (px - 2.5, py + 1.3),\n",
    "                 arrowprops = dict(arrowstyle = \"->\", lw = 1.2),\n",
    "                 ha = 'center', va = 'center')\n",
    "\n",
    "hAxCart.set_title('Cartesian Coordinates')\n",
    "hAxCart.set_xlabel('x')\n",
    "hAxCart.set_xticks(range(Nx + 1))\n",
    "hAxCart.set_xticklabels([])\n",
    "hAxCart.set_ylabel('y')\n",
    "hAxCart.set_yticks(range(Ny + 1))\n",
    "hAxCart.set_yticklabels([])\n",
    "\n",
    "# Polar Grid\n",
    "nr, nt = 6, 24 #<! Radial and Angular Grid resolution\n",
    "R = nr         #<! Outer radius\n",
    "hAxPolar.set_ylim(0, R)\n",
    "hAxPolar.set_thetalim(0, 2 * math.pi)\n",
    "\n",
    "# Grid: radial circles and spokes\n",
    "hAxPolar.set_rticks(range(1, nr + 1))\n",
    "hAxPolar.set_thetagrids(np.degrees(np.linspace(0, 2 * math.pi, nt, endpoint = False)))\n",
    "hAxPolar.grid(True, lw = 0.8, color = '0.75')\n",
    "\n",
    "# Image in (r, θ) Discrete Coordinates (1 based)\n",
    "# Highlight sector / pixel (2, 4)\n",
    "ri, ti = 2, 4\n",
    "dr = R / nr\n",
    "dth = 2 * math.pi / nt\n",
    "theta0 = (ti - 1) * dth\n",
    "bottom = (ri - 1) * dr\n",
    "# Use a polar bar to draw the annular sector\n",
    "hAxPolar.bar(theta0, dr, width = dth, bottom = bottom, align = 'edge',\n",
    "             color = '0.7', edgecolor = 'k')\n",
    "\n",
    "hAxPolar.set_title('Polar Coordinates')\n",
    "hAxPolar.annotate(f'Pixel ({ri}, {ti})',\n",
    "                  xy = (theta0 + dth / 2, bottom + dr / 2),\n",
    "                  xytext = (theta0 + 1.1 * dth, bottom + 2.2 * dr),\n",
    "                  arrowprops = dict(arrowstyle = \"->\", lw = 1.2),\n",
    "                  ha = 'center')\n",
    "\n",
    "hAxPolar.set_yticklabels([]) \n",
    "\n",
    "hF.tight_layout()\n",
    "\n",
    "if exportFig:\n",
    "    hF.savefig('Coordinates.svg', transparent = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Should include the ExcaliDraw embedded in the image -->\n",
    "![](https://i.imgur.com/hh5Hnhv.png)\n",
    "<!-- ![](https://i.postimg.cc/9FP5HDQ9/Untitled-2025-05-03-2057-excalidraw.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation per Angle\n",
    "\n",
    "Summing pixels along the radial axis provides a profile of of the radial distribution around the image center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polar and Aggregation Representation per Image\n",
    "\n",
    "rndIdx = random.randrange(numSamplesTrain)\n",
    "mI = np.reshape(mXTrain[rndIdx], TU_MNIST_IMG_SIZE)\n",
    "mP = ski.transform.warp_polar(mI, output_shape = (280, 280))\n",
    "vP = np.sum(mP, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Polar and Aggregation Representation per Image \n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = 3, figsize = (12, 3))\n",
    "vHa = vHa.flat\n",
    "\n",
    "hA = vHa[0]\n",
    "hA.imshow(mI, cmap = 'gray')\n",
    "hA.tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, \n",
    "               labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "hA.set_xlabel('x')\n",
    "hA.set_ylabel('y')\n",
    "hA.set_title('Cartesian Coordinates')\n",
    "\n",
    "hA = vHa[1]\n",
    "hA.imshow(mP.T[::-1], cmap = 'gray')\n",
    "hA.tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, \n",
    "               labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "hA.set_xlabel('θ')\n",
    "hA.set_ylabel('r')\n",
    "hA.set_title('Polar Coordinates')\n",
    "\n",
    "hA = vHa[2]\n",
    "hA.plot(vP)\n",
    "hA.tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, \n",
    "               labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "hA.set_xlabel('θ')\n",
    "hA.set_ylabel('Sum of Values')\n",
    "hA.set_title('Aggregation per θ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Animation\n",
    "mP = ski.transform.warp_polar(mI, output_shape = (360, 360))\n",
    "vP = np.sum(mP, axis = 1)\n",
    "\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = 2, figsize = (8, 4))\n",
    "vHa = vHa.flat\n",
    "\n",
    "tuCenter  = (TU_MNIST_IMG_SIZE[1] // 2, TU_MNIST_IMG_SIZE[0] // 2)\n",
    "valRadius = math.sqrt(2) * max(tuCenter)\n",
    "\n",
    "hA = vHa[0]\n",
    "hA.imshow(mI, cmap = 'gray')\n",
    "lineAngle, *_ = hA.plot([tuCenter[0], tuCenter[0] + valRadius], [tuCenter[1], tuCenter[1]], color = 'r', lw = 2)\n",
    "hA.tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, \n",
    "               labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "hA.set_xlabel('x')\n",
    "hA.set_ylabel('y')\n",
    "hA.set_xlim((0, TU_MNIST_IMG_SIZE[0] - 1))\n",
    "hA.set_ylim((TU_MNIST_IMG_SIZE[1] - 1, 0))\n",
    "hA.set_title(f'θ = {0:03d} [Deg]')\n",
    "\n",
    "hA = vHa[1]\n",
    "hA.plot(vP)\n",
    "lineSum = hA.axvline(x = 0, color = 'r', lw = 2)\n",
    "hA.set_xlim((0, 360))\n",
    "\n",
    "figName = f'Figure{0:04d}.png'\n",
    "if exportFig:\n",
    "    hF.savefig(figName, dpi = 150)\n",
    "\n",
    "for ii, θ in enumerate(range(360)):\n",
    "    θRad = -math.radians(θ)  #<! Convert degrees to radians\n",
    "    xEnd = tuCenter[0] + valRadius * math.cos(θRad)\n",
    "    yEnd = tuCenter[1] - valRadius * math.sin(θRad) #<! Inverted as Y direction is down\n",
    "    lineAngle.set_data([tuCenter[0], xEnd], [tuCenter[1], yEnd])\n",
    "    lineSum.set_xdata([θ])\n",
    "    vHa[0].set_title(f'θ = {θ:03d} [Deg]')\n",
    "    \n",
    "    hF.canvas.draw() #<! Update the canvas before exporting\n",
    "\n",
    "    figName = f'Figure{(ii + 1):04d}.png'\n",
    "    if exportFig:\n",
    "        hF.savefig(figName, dpi = 150)\n",
    "# ffmpeg -framerate 10 -i Figure%04d.png -c:v libx264 -pix_fmt yuv420p -an -movflags faststart -loop 1 output.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection Visualization\n",
    "\n",
    "<iframe width=\"853\" height=\"480\" src=\"//sendvid.com/embed/kh2a1tox\" frameborder=\"0\" allowfullscreen></iframe>\n",
    "<!-- <iframe allow=\"fullscreen\" allowfullscreen height=\"480\" src=\"https://streamable.com/e/g1g71s?\" width=\"800\" style=\"border:none;\"></iframe> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the 1D Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Data into 1D\n",
    "mPTrain = ConvertDataSet(mXTrain, resampleRes = resampleRes)\n",
    "# Data Normalization\n",
    "vMean = np.mean(mPTrain, axis = 0)\n",
    "vStd  = np.std(mPTrain, axis = 0)\n",
    "mPTrain -= vMean\n",
    "mPTrain /= vStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Curve per Class\n",
    "\n",
    "mM = np.zeros(shape = (numClass, mPTrain.shape[1]))\n",
    "\n",
    "for ii in range(numClass):\n",
    "    vIdx = vYTrain == ii\n",
    "    vF = np.mean(mPTrain[vIdx], axis = 0) #<! (360, )\n",
    "    mM[ii] = vF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Mean Curve per Class\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 2, ncols = numClass // 2, figsize = (12, 4))\n",
    "vHa = vHa.flat\n",
    "\n",
    "for ii, hA in enumerate(vHa):\n",
    "    vIdx = np.flatnonzero(vYTrain == ii)\n",
    "    vIdx = np.random.choice(vIdx, size = min(25, len(vIdx)), replace = False)\n",
    "    mL = mPTrain[vIdx]\n",
    "    hA.plot(mL.T, lw = 0.5, color = 'k', alpha = 0.3)\n",
    "    hA.plot(mM[ii], lw = 2)\n",
    "    hA.tick_params(axis = 'both', left = False, top = False, right = False, bottom = False, \n",
    "                   labelleft = False, labeltop = False, labelright = False, labelbottom = False)\n",
    "    hA.set_title(f'Label {ii}')\n",
    "\n",
    "hF.suptitle('Mean Class Curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = pd.DataFrame({'Mean': np.zeros(numSamplesTrain), 'STD': np.zeros(numSamplesTrain), 'Label': vYTrain})\n",
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Mean and STD\n",
    "\n",
    "def CalcMoments( mX: NDArray ) -> Tuple[NDArray, NDArray]:\n",
    "    vMean = np.mean(mX, axis = 1)\n",
    "    vStd  = np.std(mX, axis = 1)\n",
    "    vSkew = sp.stats.skew(mX, axis = 1)\n",
    "    vKurt = sp.stats.kurtosis(mX, axis = 1)\n",
    "\n",
    "    return vMean, vStd, vSkew, vKurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuFeatures = CalcMoments(mPTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['Mean'] = tuFeatures[0]\n",
    "dfData['STD']  = tuFeatures[1]\n",
    "dfData['Skew'] = tuFeatures[2]\n",
    "dfData['Kurt'] = tuFeatures[3]\n",
    "dfData = dfData.reindex(columns = ['Mean', 'STD', 'Skew', 'Kurt', 'Label'])\n",
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair Plots\n",
    "oPairGrid = sns.pairplot(dfData, hue = 'Label', palette = 'tab10', diag_kind = 'kde', plot_kws = {'alpha': 0.5, 's': 10, 'edgecolor': 'k'}, diag_kws = {'fill': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hF, hA = plt.subplots(figsize = (8, 6))\n",
    "sns.scatterplot(data = dfData, x = 'Mean', y = 'STD', hue = 'Label', ax = hA)\n",
    "hA.set_title('Mean vs STD by Label')\n",
    "hA.set_xlabel('Mean')\n",
    "hA.set_ylabel('STD');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [SciKit Time](https://github.com/sktime/sktime).\n",
    " - [`tsfresh`](https://github.com/blue-yonder/tsfresh).\n",
    " - [Catch22](https://github.com/DynamicsAndNeuralSystems/catch22) ([`pycatch22`](https://github.com/DynamicsAndNeuralSystems/pycatch22)).\n",
    " - [`tsflex`](https://github.com/predict-idlab/tsflex).\n",
    " - [Time Series Feature Extraction Library (`tsfel`)](https://github.com/fraunhoferportugal/tsfel).\n",
    " - [Cesium](https://github.com/cesium-ml/cesium).\n",
    " - [Facebook Kats](https://github.com/facebookresearch/Kats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeaturesTSFresh( mX: NDArray, /, *, dFeatureCalculator: Dict = EfficientFCParameters(), numProc: int = 0, showProgress: bool = True ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract tsfresh features from a (numSamples, numValues) array using EfficientFCParameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mX : np.ndarray\n",
    "        Univariate time series arranged as rows (numSamples, numValues).\n",
    "    dFeatureCalculator : dict or None\n",
    "        tsfresh feature calculator dict. If None, uses EfficientFCParameters().\n",
    "    numProc : int\n",
    "        Parallel workers for tsfresh. Use 0/None for default, or -1 for all cores.\n",
    "    showProgress : bool\n",
    "        Whether to show tsfresh's progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_df : pd.DataFrame\n",
    "        Index = sample id (0..num_samples-1). Columns = extracted features.\n",
    "        Column names follow tsfresh's \"value__feature__param\" convention.\n",
    "    \"\"\"\n",
    "    if np.ndim(mX) != 2:\n",
    "        raise ValueError(\"`mX` must be 2D with shape (numSamples, numValues).\")\n",
    "\n",
    "    numSamples = np.size(mX, 0)\n",
    "    numValues = np.size(mX, 1)\n",
    "\n",
    "    numSamples, numValues = mX.shape\n",
    "\n",
    "    # Build long format DataFrame expected by tsfresh: [id, time, value]\n",
    "    vId = np.repeat(np.arange(numSamples), numValues) #<! Time Series identifier\n",
    "    vT  = np.tile(np.arange(numValues), numSamples)   #<! Time Series time indices\n",
    "    vV  = mX.reshape(-1)                              #<! Time Series values\n",
    "\n",
    "    dfLong = pd.DataFrame({'id': vId.astype(int), 'time': vT.astype(int), 'value': vV})\n",
    "\n",
    "    # Extract features\n",
    "    dfF = extract_features(\n",
    "        dfLong,\n",
    "        column_id = 'id',\n",
    "        column_sort = 'time',\n",
    "        default_fc_parameters = dFeatureCalculator,\n",
    "        n_jobs = numProc,\n",
    "        disable_progressbar = not showProgress,\n",
    "    )\n",
    "\n",
    "    # Ensure rows are ordered by sample id 0..num_samples-1\n",
    "    dfF = dfF.sort_index()\n",
    "    \n",
    "    return dfF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF = ExtractFeaturesTSFresh(mPTrain, numProc = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = EfficientFCParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFeatureCalculator = {\n",
    "    'abs_energy': None, 'absolute_maximum': None, 'absolute_sum_of_changes': None, \n",
    "    'benford_correlation': None, 'binned_entropy': [{'max_bins': 10}], 'c3': [{'lag': 1}, {'lag': 3}],\n",
    "    'change_quantiles': [{'ql': 0.05, 'qh': 0.95, 'isabs': False, 'f_agg': 'mean'}, {'ql': 0.05, 'qh': 0.95, 'isabs': False, 'f_agg': 'var'}],\n",
    "    'cid_ce': [{'normalize': True}], 'count_above_mean': None, 'count_below_mean': None, 'first_location_of_maximum': None,\n",
    "    'first_location_of_minimum': None, 'fourier_entropy': [{'bins': 20}], 'kurtosis': None, 'large_standard_deviation': [{'r': 0.25}, {'r': 0.55}],\n",
    "    'last_location_of_maximum': None, 'last_location_of_minimum': None, 'longest_strike_above_mean': None,\n",
    "    'lempel_ziv_complexity': [{'bins': 5}, {'bins': 10}, {'bins': 10}], \n",
    "    'linear_trend': [{'attr': 'pvalue'}, {'attr': 'rvalue'}, {'attr': 'intercept'}, {'attr': 'slope'}, {'attr': 'stderr'}],\n",
    "    'longest_strike_above_mean': None, 'longest_strike_below_mean': None, 'maximum': None, 'mean': None, 'mean_abs_change': None,\n",
    "    'mean_change': None, 'mean_n_absolute_max': [{'number_of_maxima': 5}, {'number_of_maxima': 10}], 'mean_second_derivative_central': None,\n",
    "    'median': None, 'minimum': None, 'number_crossing_m': [{'m': 0}], 'number_cwt_peaks': [{'n': 1}, {'n': 5}], \n",
    "    'quantile': [{'q': 0.1}, {'q': 0.25}, {'q': 0.5}, {'q': 0.75}, {'q': 0.9}], 'sample_entropy': None, 'skewness': None,\n",
    "    'spkt_welch_density': [{'coeff': 2}, {'coeff': 5}, {'coeff': 8}], 'standard_deviation': None, 'sum_values': None,\n",
    "    'symmetry_looking': [{'r': 0.05}, {'r': 0.1}, {'r': 0.25}], 'time_reversal_asymmetry_statistic': [{'lag': 1}, {'lag': 2}, {'lag': 3}],\n",
    "    'variance': None, 'variation_coefficient': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF = ExtractFeaturesTSFresh(mPTrain, dFeatureCalculator = dFeatureCalculator, numProc = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the Standard Deviation of 'value__symmetry_looking__r_0.25'. What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oCls = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oCls = oCls.fit(dFF.to_numpy(), vYTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oCls.score(dFF.to_numpy(), vYTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Data into 1D\n",
    "mPTest = ConvertDataSet(mXTest, resampleRes = resampleRes)\n",
    "# Data Normalization (Using the Train Data)\n",
    "mPTest -= vMean\n",
    "mPTest /= vStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFFTest = ExtractFeaturesTSFresh(mPTest, dFeatureCalculator = dFeatureCalculator, numProc = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oCls.score(dFFTest.to_numpy(), vYTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeaturesCatch22( mX: NDArray, /, *, shortNames: bool = True ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract Catch22 features from a (numSamples, numValues) array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mX : np.ndarray\n",
    "        Univariate time series arranged as rows (numSamples, numValues).\n",
    "    shortNames : bool\n",
    "        Whether to use short names for the features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dfF : pd.DataFrame\n",
    "        Index = sample id (0..num_samples-1). Columns = extracted features.\n",
    "        Column names follow Catch22's \"value__feature__param\" convention.\n",
    "    \"\"\"\n",
    "    if np.ndim(mX) != 2:\n",
    "        raise ValueError(\"`mX` must be 2D with shape (numSamples, numValues).\")\n",
    "\n",
    "    numSamples = np.size(mX, 0)\n",
    "    numValues  = np.size(mX, 1)\n",
    "\n",
    "    # Get names\n",
    "    dCatch22 = pycatch22.catch22_all(mX[0], catch24 = True, short_names = True)\n",
    "    # Calculate features (Should be done in parallel for large )\n",
    "    lFeat = [pycatch22.catch22_all(mX[ii], catch24 = True, short_names = shortNames)['values'] for ii in range(numSamples)]\n",
    "\n",
    "    # Extract Catch22 features\n",
    "    dfF = pd.DataFrame(lFeat)\n",
    "    dfF.columns = dCatch22['short_names'] if shortNames else dCatch22['names']\n",
    "    dfF.index = np.arange(numSamples)\n",
    "\n",
    "    return dfF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF = ExtractFeaturesCatch22(mPTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oCls = oCls.fit(dfF, vYTrain)\n",
    "oCls.score(dfF, vYTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF = ExtractFeaturesCatch22(mPTest)\n",
    "oCls.score(dfF, vYTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIProgram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
