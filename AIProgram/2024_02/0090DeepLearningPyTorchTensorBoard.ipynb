{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io/)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - Deep Learning - PyTorch TensorBoard\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 14/05/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0090DeepLearningPyTorchTensorBoard.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchinfo\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "import torchvision\n",
    "\n",
    "# Miscellaneous\n",
    "import copy\n",
    "from enum import auto, Enum, unique\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, Generator, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    " ```python\n",
    " vallToFill = ???\n",
    " ```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "???\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# Improve performance by benchmarking\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Reproducibility (Per PyTorch Version on the same device)\n",
    "# torch.manual_seed(seedNum)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark     = False #<! Makes things slower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "D_CLASSES_SVHN  = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
    "L_CLASSES_SVHN  = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "T_IMG_SIZE_SVHN = (32, 32, 3)\n",
    "\n",
    "DATA_FOLDER_PATH    = 'Data'\n",
    "TENSOR_BOARD_BASE   = 'TB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Auxiliary Modules for Google Colab\n",
    "if runInGoogleColab:\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataManipulation.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataVisualization.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DeepLearningPyTorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotLabelsHistogram, PlotMnistImages\n",
    "from DeepLearningPyTorch import NNMode\n",
    "from DeepLearningPyTorch import RunEpoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "@unique\n",
    "class ActivationLayerCls(Enum):\n",
    "    ELU         = auto()\n",
    "    GELU        = auto() #<! Common in NLP Transformers\n",
    "    LEAKY_RELU  = auto()\n",
    "    RELU        = auto()\n",
    "    SILU        = auto() #<! Common in NLP Transformers\n",
    "\n",
    "\n",
    "@unique\n",
    "class PoolLayerCls(Enum):\n",
    "    AVERAGE     = auto()\n",
    "    MAX         = auto()\n",
    "\n",
    "\n",
    "def PlotConfusionMatrix(vY: np.ndarray, vYPred: np.ndarray, hA: plt.Axes, normMethod: str = None, \n",
    "                        lLabels: List = L_CLASSES_SVHN, dScore: Optional[Dict] = None, titleStr: str = 'Confusion Matrix', \n",
    "                        xLabelRot: Optional[int] = None, valFormat: Optional[str] = None) -> Tuple[plt.Axes, np.ndarray]:\n",
    "\n",
    "    hA.clear()\n",
    "\n",
    "    # Calculation of Confusion Matrix\n",
    "    mConfMat = confusion_matrix(vY, vYPred, normalize = normMethod)\n",
    "    oConfMat = ConfusionMatrixDisplay(mConfMat, display_labels = lLabels)\n",
    "    oConfMat = oConfMat.plot(ax = hA, values_format = valFormat)\n",
    "    hA = oConfMat.ax_\n",
    "    if dScore is not None:\n",
    "        titleStr += ':'\n",
    "        for scoreName, scoreVal in  dScore.items():\n",
    "            titleStr += f' {scoreName} = {scoreVal:0.2},'\n",
    "        titleStr = titleStr[:-1]\n",
    "    hA.set_title(titleStr)\n",
    "    hA.grid(False)\n",
    "    if xLabelRot is not None:\n",
    "        for xLabel in hA.get_xticklabels():\n",
    "            xLabel.set_rotation(xLabelRot)\n",
    "\n",
    "    return hA, mConfMat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch & TensorBoard\n",
    "\n",
    "[TensorBoard](https://www.tensorflow.org/tensorboard) is a tool to analyze runs of models.    \n",
    "The concept is to save data to HD while running and display it using the server.   \n",
    "This policy prevents loss of information in case of a failure.  \n",
    "It also adds the ability to \"babysit\" the model while running.\n",
    "\n",
    "Using _TensorBoard_ is based on:\n",
    "\n",
    " * Defining a `SummaryWriter` object which documents a session.\n",
    " * Using the `SummaryWriter`'s method to add data: Scalars, Figures, Images, etc...\n",
    "\n",
    "\n",
    "This notebook shows more capabilities of [`SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard):\n",
    "\n",
    " - Working with a Scalar (`add_scalar()`).\n",
    " - Working with Scalars (`add_scalars()`).\n",
    " - Working with Figures (`add_figure()`).\n",
    " - Working with Hyper Parameters (`add_hparams()`).\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> While [TensorBoard](https://www.tensorflow.org/tensorboard) is common in the DL world, it might used to handle any ML analysis.\n",
    "* <font color='brown'>(**#**)</font> See [`torch.utils.tensorboard.writer.SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard) documentation.\n",
    "* <font color='brown'>(**#**)</font> Alternatives: [ClearML](https://clear.ml), [Weights & Biases](https://wandb.ai), [ML Flow](https://mlflow.org), [Neptune AI](https://neptune.ai).\n",
    "* <font color='brown'>(**#**)</font> [Deep Dive Into TensorBoard: Tutorial With Examples](https://neptune.ai/blog/tensorboard-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "numSamplesPerClsTrain   = 4000\n",
    "numSamplesPerClsVal     = 400\n",
    "\n",
    "# Model\n",
    "dropP = 0.5 #<! Dropout Layer\n",
    "\n",
    "# Training\n",
    "batchSize   = 256\n",
    "numWork     = 2 #<! Number of workers\n",
    "nEpochs     = 10\n",
    "\n",
    "# Visualization\n",
    "numImg = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "Load the [The Street View House Numbers (SVHN) Dataset](http://ufldl.stanford.edu/housenumbers).  \n",
    "It is composed of 73,257 RGB train and 26,032 test images of size `32x32`.  \n",
    "The data is **imbalanced**.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The dataset is retrieved using [Torch Vision](https://pytorch.org/vision/stable/index.html)'s built in datasets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "# PyTorch \n",
    "dsTrain = torchvision.datasets.SVHN(root = DATA_FOLDER_PATH, split = 'train',  download = True, transform = torchvision.transforms.ToTensor())\n",
    "dsTest  = torchvision.datasets.SVHN(root = DATA_FOLDER_PATH, split = 'test', download = True, transform = torchvision.transforms.ToTensor())\n",
    "lClass  = np.unique(dsTrain.labels)\n",
    "\n",
    "\n",
    "print(f'The training data set data shape: {dsTrain.data.shape}')\n",
    "print(f'The test data set data shape: {dsTest.data.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(lClass)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The dataset is indexible (Subscriptable). It returns a tuple of the features and the label.\n",
    "* <font color='brown'>(**#**)</font> While data is arranged as `H x W x C` the transformer, when accessing the data, will convert it into `C x H x W`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element of the Data Set\n",
    "\n",
    "mX, valY = dsTrain[0]\n",
    "\n",
    "print(f'The features shape: {mX.shape}')\n",
    "print(f'The label value: {valY}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "\n",
    "tX = dsTrain.data #<! NumPy Tensor (NDarray)\n",
    "mX = np.reshape(tX, (tX.shape[0], -1))\n",
    "vY = dsTrain.labels #<! NumPy Vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder Data\n",
    "# Data is C x H x W -> H x W x C for displaying\n",
    "mX = np.reshape(mX, (mX.shape[0], *T_IMG_SIZE_SVHN[::-1]))\n",
    "mX = np.transpose(mX, (0, 2, 3, 1))\n",
    "mX = np.reshape(mX, (mX.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF = PlotMnistImages(mX, vY, numImg, tuImgSize = T_IMG_SIZE_SVHN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> If data is converted into _grayscale_, how would it effect the performance of the classifier? Explain.  \n",
    "  You may assume the conversion is done using the mean value of the RGB pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY, lClass = L_CLASSES_SVHN)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Explain the given distribution of classes. Think about the origin of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Process Data\n",
    "\n",
    "This section:\n",
    "\n",
    " * Normalizes the data in a predefined manner.\n",
    " * Takes a sub set of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub Set of Data - Indices\n",
    "\n",
    "numCls = len(L_CLASSES_SVHN)\n",
    "mIdxTrain   = np.zeros(shape = (numSamplesPerClsTrain, numCls), dtype = np.int_)\n",
    "mIdxVal     = np.zeros(shape = (numSamplesPerClsVal, numCls), dtype = np.int_)\n",
    "\n",
    "for valCls in range(numCls):\n",
    "    mIdxTrain[:, valCls] = np.random.choice(np.flatnonzero(dsTrain.labels == valCls), size = numSamplesPerClsTrain, replace = False)\n",
    "    mIdxVal[:, valCls] = np.random.choice(np.flatnonzero(dsTest.labels == valCls), size = numSamplesPerClsVal, replace = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub Set of Data - Subset\n",
    "dsTrain = torch.utils.data.Subset(dsTrain, np.ravel(mIdxTrain))\n",
    "dsTest = torch.utils.data.Subset(dsTest, np.ravel(mIdxVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(dsTrain.dataset.labels[dsTrain.indices], lClass = L_CLASSES_SVHN)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hA = PlotLabelsHistogram(dsTest.dataset.labels[dsTest.indices], lClass = L_CLASSES_SVHN)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Transformer\n",
    "\n",
    "oDataTrns = torchvision.transforms.Compose([    #<! Chaining transformations\n",
    "    torchvision.transforms.ToTensor(),          #<! Convert to Tensor (C x H x W), Normalizes into [0, 1] (https://pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html)\n",
    "    torchvision.transforms.Normalize(0.5, 0.5),\n",
    "    ])\n",
    "\n",
    "# Update the DS transformer\n",
    "dsTrain.transform = oDataTrns\n",
    "dsTest.transform  = oDataTrns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What does the `Normalize(0.5, 0.5)` do? What are the value boundaries of the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Normalized\" Image\n",
    "\n",
    "mX, valY = dsTrain[5]\n",
    "\n",
    "hF, hA = plt.subplots()\n",
    "hImg = hA.imshow(np.transpose(mX, (1, 2, 0)))\n",
    "hF.colorbar(hImg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders\n",
    "\n",
    "This section defines the data loaded.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Adjust the size of the actual data set according to performance of the system.\n",
    "* <font color='brown'>(**#**)</font> First tuning and runs of a script might be better done with a small data.  \n",
    "* <font color='brown'>(**#**)</font> Sub sampling the data can be achieved using `torch.utils.data.Subset`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "\n",
    "dlTrain  = torch.utils.data.DataLoader(dsTrain, shuffle = True, batch_size = 1 * batchSize, num_workers = numWork, persistent_workers = True)\n",
    "dlTest   = torch.utils.data.DataLoader(dsTest, shuffle = False, batch_size = 2 * batchSize, num_workers = numWork, persistent_workers = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why is the size of the batch twice as big for the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate on the Loader\n",
    "# The first batch.\n",
    "tX, vY = next(iter(dlTrain)) #<! PyTorch Tensors\n",
    "\n",
    "print(f'The batch features dimensions: {tX.shape}')\n",
    "print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping\n",
    "for ii, (tX, vY) in zip(range(1), dlTest): #<! https://stackoverflow.com/questions/36106712\n",
    "    print(f'The batch features dimensions: {tX.shape}')\n",
    "    print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "\n",
    "The model is defined as a sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# Defining a sequential model.\n",
    "\n",
    "numFeatures = np.prod(tX.shape[1:])\n",
    "\n",
    "def BuildModel( activationLyrType: ActivationLayerCls = ActivationLayerCls.RELU, poolLayerType: PoolLayerCls = PoolLayerCls.MAX ) -> nn.Module:\n",
    "\n",
    "    if activationLyrType is ActivationLayerCls.ELU:\n",
    "        ActivationLayer = nn.ELU\n",
    "    elif activationLyrType is ActivationLayerCls.GELU:\n",
    "        ActivationLayer = nn.GELU\n",
    "    elif activationLyrType is ActivationLayerCls.LEAKY_RELU:\n",
    "        ActivationLayer = nn.LeakyReLU\n",
    "    elif activationLyrType is ActivationLayerCls.RELU:\n",
    "        ActivationLayer = nn.ReLU\n",
    "    elif activationLyrType is ActivationLayerCls.SILU:\n",
    "        ActivationLayer = nn.SiLU\n",
    "    else:\n",
    "        raise ValueError(f'The value of `activationLyrType` {activationLyrType} is not supported')\n",
    "    \n",
    "    if poolLayerType is PoolLayerCls.AVERAGE:\n",
    "        PoolLayer = nn.AvgPool2d\n",
    "    elif poolLayerType is PoolLayerCls.MAX:\n",
    "        PoolLayer = nn.MaxPool2d\n",
    "    else:\n",
    "        raise ValueError(f'The value of `poolLayerType` {activationLyrType} is not supported')\n",
    "    \n",
    "    oModel = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        \n",
    "        nn.Conv2d(3,    16, 3, bias = False), nn.BatchNorm2d(16),                ActivationLayer(),\n",
    "        nn.Conv2d(16,   32, 3, bias = False), nn.BatchNorm2d(32),  PoolLayer(2), ActivationLayer(),\n",
    "        nn.Conv2d(32,   64, 3, bias = False), nn.BatchNorm2d(64),  PoolLayer(2), ActivationLayer(),\n",
    "        nn.Conv2d(64,  128, 3, bias = False), nn.BatchNorm2d(128),               ActivationLayer(),\n",
    "        nn.Conv2d(128, 256, 3, bias = False), nn.BatchNorm2d(256),               ActivationLayer(),\n",
    "        \n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256, len(lClass)),\n",
    "    )\n",
    "\n",
    "    return oModel\n",
    "\n",
    "oModel = BuildModel()\n",
    "\n",
    "torchinfo.summary(oModel, tX.shape, col_names = ['kernel_size', 'output_size', 'num_params'], device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why is `bias = False` used above?\n",
    "* <font color='brown'>(**#**)</font> Using a multiplication by 8 number of channels accelerate the run time (In most cases).\n",
    "* <font color='brown'>(**#**)</font> Pay attention to model size and the RAM fo the GPU. Rule of thumb, up to ~40%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "This section trains the model using different schedulers:\n",
    "\n",
    " - Updates the training function to use more features of _TensorBoard_.\n",
    " - Trains the model with different _hyper parameters_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Device\n",
    "\n",
    "runDevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #<! The 1st CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Score Function\n",
    "\n",
    "hL = nn.CrossEntropyLoss()\n",
    "hS = MulticlassAccuracy(num_classes = len(lClass))\n",
    "hL = hL.to(runDevice) #<! Not required!\n",
    "hS = hS.to(runDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "def TrainModel( oModel: nn.Module, dlTrain: DataLoader, dlVal: DataLoader, oOpt: Optimizer, numEpoch: int, hL: Callable, hS: Callable, oSch: Optional[LRScheduler] = None, oTBWriter: Optional[SummaryWriter] = None) -> Tuple[nn.Module, List, List, List, List]:\n",
    "\n",
    "    lTrainLoss  = []\n",
    "    lTrainScore = []\n",
    "    lValLoss    = []\n",
    "    lValScore   = []\n",
    "    lLearnRate  = []\n",
    "\n",
    "    # Support R2\n",
    "    bestScore = -1e9 #<! Assuming higher is better\n",
    "\n",
    "    learnRate = oOpt.param_groups[0]['lr']\n",
    "\n",
    "    for ii in range(numEpoch):\n",
    "        startTime           = time.time()\n",
    "        trainLoss, trainScr = RunEpoch(oModel, dlTrain, hL, hS, oOpt, opMode = NNMode.TRAIN) #<! Train\n",
    "        valLoss,   valScr   = RunEpoch(oModel, dlVal, hL, hS, oOpt, opMode = NNMode.INFERENCE) #<! Score Validation\n",
    "        if oSch is not None:\n",
    "            # Adjusting the scheduler on Epoch level\n",
    "            learnRate = oSch.get_last_lr()[0]\n",
    "            oSch.step()\n",
    "        epochTime           = time.time() - startTime\n",
    "\n",
    "        # Aggregate Results\n",
    "        lTrainLoss.append(trainLoss)\n",
    "        lTrainScore.append(trainScr)\n",
    "        lValLoss.append(valLoss)\n",
    "        lValScore.append(valScr)\n",
    "        lLearnRate.append(learnRate)\n",
    "\n",
    "        if oTBWriter is not None:\n",
    "            oTBWriter.add_scalars('Loss (Epoch)', {'Train': trainLoss, 'Validation': valLoss}, ii)\n",
    "            oTBWriter.add_scalars('Score (Epoch)', {'Train': trainScr, 'Validation': valScr}, ii)\n",
    "            oTBWriter.add_scalar('Learning Rate (Epoch)', learnRate, ii)\n",
    "\n",
    "            runDevice = next(oModel.parameters()).device\n",
    "            oModel.eval()\n",
    "            lYHat   = []\n",
    "            lY      = []\n",
    "            for jj, (mX, vY) in enumerate(dlVal):\n",
    "                mX = mX.to(runDevice) #<! Lazy\n",
    "\n",
    "                with torch.inference_mode():\n",
    "                    mZ = oModel(mX)\n",
    "                    vYHat = torch.argmax(mZ, dim = 1)\n",
    "                \n",
    "                lYHat.extend(vYHat.cpu().numpy())\n",
    "                lY.extend(vY.numpy())\n",
    "            \n",
    "            vYHat   = np.array(lYHat)\n",
    "            vY      = np.array(lY)\n",
    "\n",
    "            hF, hA = plt.subplots(figsize = (9, 5)) #<! Complex axes, hence `cla()` won't do it\n",
    "            hA, _ = PlotConfusionMatrix(vY, vYHat, hA)\n",
    "            oTBWriter.add_figure('Confusion Matrix (Epoch)', hF, ii, close = True)\n",
    "        \n",
    "        # Display (Babysitting)\n",
    "        print('Epoch '              f'{(ii + 1):4d} / ' f'{numEpoch}:', end = '')\n",
    "        print(' | Train Loss: '     f'{trainLoss          :6.3f}', end = '')\n",
    "        print(' | Val Loss: '       f'{valLoss            :6.3f}', end = '')\n",
    "        print(' | Train Score: '    f'{trainScr           :6.3f}', end = '')\n",
    "        print(' | Val Score: '      f'{valScr             :6.3f}', end = '')\n",
    "        print(' | Epoch Time: '     f'{epochTime          :5.2f}', end = '')\n",
    "\n",
    "        # Save best model (\"Early Stopping\")\n",
    "        if valScr > bestScore:\n",
    "            bestScore = valScr\n",
    "            print(' | <-- Checkpoint!', end = '')\n",
    "            try:\n",
    "                dCheckpoint = {'Model' : oModel.state_dict(), 'Optimizer' : oOpt.state_dict()}\n",
    "                if oSch is not None:\n",
    "                    dCheckpoint['Scheduler': oSch.state_dict()]\n",
    "                torch.save(dCheckpoint, 'BestModel.pt')\n",
    "            except:\n",
    "                pass\n",
    "        print(' |')\n",
    "    \n",
    "    # Load best model (\"Early Stopping\")\n",
    "    # dCheckpoint = torch.load('BestModel.pt')\n",
    "    # oModel.load_state_dict(dCheckpoint['Model'])\n",
    "\n",
    "    return oModel, lTrainLoss, lTrainScore, lValLoss, lValScore, lLearnRate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Some schedulers (For instance `OneCycleLR`) do not allow iterations beyond what is defined.\n",
    "* <font color='brown'>(**#**)</font> Some schedulers are score / loss event driven. See `torch.optim.ReduceLROnPlateau`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Grid\n",
    "\n",
    "dParamGrid = ParameterGrid({'activationLyrType': [ActivationLayerCls.ELU, ActivationLayerCls.GELU, ActivationLayerCls.LEAKY_RELU, ActivationLayerCls.RELU, ActivationLayerCls.SILU], \n",
    "                            'poolLayerType': [PoolLayerCls.AVERAGE, PoolLayerCls.MAX]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "learnRate = 4e-3\n",
    "\n",
    "dModelHist = {}\n",
    "\n",
    "for ii, dModelParams in enumerate(dParamGrid):\n",
    "    print(f'Training with the {(ii + 1): 02d} model parameters combination')\n",
    "    oTBWriter = SummaryWriter(log_dir = os.path.join(TENSOR_BOARD_BASE, f'Model{(ii + 1):03d}'))\n",
    "    oModel = BuildModel(**dModelParams) #<! Just for graphing\n",
    "    oTBWriter.add_graph(oModel, tX) #<! Model Graph\n",
    "    oModel = BuildModel(**dModelParams)\n",
    "    oModel = oModel.to(runDevice) #<! Transfer model to device\n",
    "    oOpt = torch.optim.AdamW(oModel.parameters(), lr = learnRate, betas = (0.9, 0.99), weight_decay = 1e-4) #<! Define optimizer\n",
    "    oScd = torch.optim.lr_scheduler.OneCycleLR(oOpt, max_lr = learnRate, total_steps = nEpochs)\n",
    "    _, lTrainLoss, lTrainScore, lValLoss, lValScore, lLearnRate = TrainModel(oModel, dlTrain, dlTest, oOpt, nEpochs, hL, hS, oScd, oTBWriter)\n",
    "    oTBWriter.add_hparams({'Activation Layer': dModelParams['activationLyrType'].name, 'Pool Layer': dModelParams['poolLayerType'].name}, \n",
    "                          {'Loss (Train)': min(lTrainLoss), 'Score (Train)': max(lTrainScore), 'Loss (Validation)': min(lValLoss), 'Score (Validation)': max(lValScore)})\n",
    "    dModelHist[ii] = lTrainLoss, lTrainScore, lValLoss, lValScore, lLearnRate\n",
    "    oTBWriter.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='blue'>(**!**)</font> Plot the data (`dModelHist`) using _MatPlotLib_.\n",
    "* <font color='blue'>(**!**)</font> Add an image of some of mislabeled images. See [PyTorch TensorBoard Tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html).\n",
    "* <font color='blue'>(**!**)</font> Add a PR Curve for the TB result. See [PyTorch TensorBoard Tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
