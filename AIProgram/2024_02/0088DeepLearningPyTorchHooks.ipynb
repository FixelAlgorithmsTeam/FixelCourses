{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - Deep Learning - PyTorch Hooks\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 07/05/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0088DeepLearningPyTorchHooks.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torchinfo\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "import torchvision\n",
    "\n",
    "# Miscellaneous\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, Generator, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    "```python\n",
    "# You need to start writing\n",
    "?????\n",
    "```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# Improve performance by benchmarking\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Reproducibility (Per PyTorch Version on the same device)\n",
    "# torch.manual_seed(seedNum)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark     = False #<! Makes things slower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "DATA_FOLDER_PATH = 'Data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Auxiliary Modules for Google Colab\n",
    "if runInGoogleColab:\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataManipulation.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataVisualization.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DeepLearningPyTorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotLabelsHistogram, PlotMnistImages\n",
    "from DeepLearningPyTorch import TrainModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Hooks\n",
    "\n",
    "PyTorch _Hooks_ / _Callbacks_ are _event driven functions_.  \n",
    "They are integrated into objects (Tensors / `nn.Module`) and are executed when the event hooked happens.\n",
    "\n",
    "Conceptually, one can think of the model as a `while` loop with `if` to execute if some condition holds.    \n",
    "Specifically in the context of PyTorch, the even is updating or executing the Tensor / Module.\n",
    "\n",
    "Object which supports hooks:\n",
    " - Tensors (`torch.Tensor`).\n",
    " - Modules (`nn.Module`).\n",
    "\n",
    "Events:\n",
    " - Forward Pre Hook - Before forward pass.\n",
    " - Forward Hook - After forward pass.\n",
    " - Backward Hook - After backward pass (Gradient is available).\n",
    "\n",
    "\n",
    "Some use cases:\n",
    " - Tracking the distribution of values of a certain layer during training.\n",
    " - Tracking the distribution of the values of the gradient of a certain layer during training.\n",
    " - How many neurons have \"died\"?\n",
    "\n",
    "The notebook presents:\n",
    "\n",
    " * The concept of _Hooks_ for `nn.Module` in PyTorch.\n",
    " * An implementation of use case: Analysis of activations using hooks.\n",
    " * Using _Normal Kaiming Initialization_ instead of the default _Uniform Kaiming Initialization_.\n",
    " * Using model's `apply()` method for initialization.\n",
    " * Comparing the effect of the initialization on the data distribution using _Hooks_.\n",
    "\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> [YouTube - Elliot Waite - PyTorch Hooks Explained](https://www.youtube.com/watch?v=syLFCVYua6Q).\n",
    "* <font color='brown'>(**#**)</font> [How to Use PyTorch Hooks](https://scribe.rip/5041d777f904).\n",
    "* <font color='brown'>(**#**)</font> [PyTorch Hooks](https://scribe.rip/5909c7636fb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "%% Nodes\n",
    "    X(fa:fa-image X)\n",
    "    Y((Y))\n",
    "    H{\"f()\"} \n",
    "\n",
    "subgraph Model\n",
    "  C1[fa:fa-layer-group Conv2D]\n",
    "  C2[fa:fa-layer-group Conv2D]\n",
    "end\n",
    "\n",
    "%% Edge connections between nodes\n",
    "    X  --> C1\n",
    "    C1 --> C2\n",
    "    C2 --> Y\n",
    "    C1 <-. Hook .-> H\n",
    "\n",
    "%% Individual node styling. Try the visual editor toolbar for easier styling!\n",
    "    style X  color:#FFFFFF, stroke:#AA00FF, fill:#AA00FF\n",
    "    style Y  color:#FFFFFF, stroke:#00C853, fill:#00C853\n",
    "    style C1 color:#FFFFFF, stroke:#2962FF, fill:#2962FF\n",
    "    style C2 color:#FFFFFF, stroke:#2962FF, fill:#2962FF\n",
    "    style H  color:#FFFFFF, stroke:#296255, fill:#88AA00\n",
    "    \n",
    "%% You can add notes with two \"%\" signs in a row!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case\n",
    "\n",
    "If most of the neurons of a net at some layer have vanished, it means the net only uses a small part of its capacity.  \n",
    "This should be diagnosed form multiple motivations:\n",
    "\n",
    " - Adjust the net model: Smaller / Different.\n",
    " - Prune the model to make inference faster.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> This notebook focuses on the _Hook_ as a tool to diagnose such cases yet not on how to prevent them or handle them.\n",
    "* <font color='brown'>(**#**)</font> [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635).  \n",
    "  Shows most known model can be heavily pruned with no performance hit.  \n",
    "  Though it seems the model have over capacity, it does not mean we know how to make them more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "\n",
    "# Model\n",
    "dropP = 0.5 #<! Dropout Layer\n",
    "\n",
    "# Training\n",
    "batchSize   = 256\n",
    "numWork     = 2 #<! Number of workers\n",
    "nEpochs     = 5\n",
    "\n",
    "# Visualization\n",
    "numImg = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "This section loads the [MNIST Data set](https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n",
    "The data is split to 60,000 train samples and 10,000 test samples.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The dataset is retrieved using [Torch Vision](https://pytorch.org/vision/stable/index.html)'s built in datasets.  \n",
    "* <font color='brown'>(**#**)</font> In PyTorch `Dataset` object defines how to access a dataset on hard drive.  \n",
    "  It abstracts the data on an HD as an array like object.\n",
    "* <font color='brown'>(**#**)</font> In PyTorch a `Dataloader` object handled the actual loading at scale during the training: Fetching the data from a dataset and pushing into the net.\n",
    "* <font color='brown'>(**#**)</font> For custom data one should sub class the [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class.  \n",
    "  See [Writing Custom Datasets, DataLoaders and Transforms](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "# PyTorch \n",
    "dsTrain = torchvision.datasets.MNIST(root = DATA_FOLDER_PATH, train = True,  download = True, transform = torchvision.transforms.ToTensor())\n",
    "dsTest  = torchvision.datasets.MNIST(root = DATA_FOLDER_PATH, train = False, download = True, transform = torchvision.transforms.ToTensor())\n",
    "lClass  = dsTrain.classes\n",
    "\n",
    "\n",
    "print(f'The training data set data shape: {dsTrain.data.shape}')\n",
    "print(f'The test data set data shape: {dsTest.data.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(lClass)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The dataset is indexible (Subscriptable). It returns a tuple of the features and the label.\n",
    "* <font color='brown'>(**#**)</font> While data is arranged as `H x W x C` the transformer, when accessing the data, will convert it into `C x H x W`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element of the Data Set\n",
    "\n",
    "mX, valY = dsTrain[0]\n",
    "\n",
    "print(f'The features shape: {mX.shape}')\n",
    "print(f'The label value: {valY}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "\n",
    "tX = dsTrain.data #<! NumPy Tensor (NDarray)\n",
    "mX = np.reshape(tX, (tX.shape[0], -1))\n",
    "vY = dsTrain.targets #<! NumPy Vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF = PlotMnistImages(mX, vY, numImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY, lClass = list(range(10)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Process Data\n",
    "\n",
    "This section normalizes the data to have zero mean and unit variance per **channel**.  \n",
    "It is required to calculate:\n",
    "\n",
    " * The average pixel value per channel.\n",
    " * The standard deviation per channel.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The values calculated on the train set and applied to both sets.\n",
    "* <font color='brown'>(**#**)</font> The the data will be used to pre process the image on loading by the `transformer`.\n",
    "* <font color='brown'>(**#**)</font> There packages which specializes in transforms: [`Kornia`](https://github.com/kornia/kornia), [`Albumentations`](https://github.com/albumentations-team/albumentations).  \n",
    "  They are commonly used for _Data Augmentation_ at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What do you expect the mean value to be?\n",
    "* <font color='red'>(**?**)</font> What do you expect the standard deviation value to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Standardization Parameters\n",
    "valMean = torch.mean(dsTrain.data / 255.0)\n",
    "valStd  = torch.std(dsTest.data / 255.0)\n",
    "\n",
    "print('µ =', valMean)\n",
    "print('σ =', valStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Transformer\n",
    "\n",
    "oDataTrns = torchvision.transforms.Compose([           #<! Chaining transformations\n",
    "    torchvision.transforms.ToTensor(),                 #<! Convert to Tensor (C x H x W), Normalizes into [0, 1] (https://pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html)\n",
    "    torchvision.transforms.Normalize(valMean, valStd), #<! Normalizes the Data (https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html)\n",
    "    ])\n",
    "\n",
    "# Update the DS transformer\n",
    "dsTrain.transform = oDataTrns\n",
    "dsTest.transform  = oDataTrns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Normalized\" Image\n",
    "\n",
    "mX, valY = dsTrain[5]\n",
    "\n",
    "hF, hA = plt.subplots()\n",
    "hImg = hA.imshow(np.transpose(mX, (1, 2, 0)))\n",
    "hF.colorbar(hImg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> How come the values are not centered around $0$? Thing about the data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders\n",
    "\n",
    "The dataloader is the functionality which loads the data into memory in batches.  \n",
    "Its challenge is to bring data fast enough so the Hard Disk is not the training bottleneck.  \n",
    "In order to achieve that, Multi Threading / Multi Process is used.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The multi process, by the `num_workers` parameter is not working well _out of the box_ on Windows.  \n",
    "  See [Errors When Using `num_workers > 0` in `DataLoader`](https://discuss.pytorch.org/t/97564), [On Windows `DataLoader` with `num_workers > 0` Is Slow](https://github.com/pytorch/pytorch/issues/12831).  \n",
    "  A way to overcome it is to define the training loop as a function in a different module (File) and import it (https://discuss.pytorch.org/t/97564/4, https://discuss.pytorch.org/t/121588/21). \n",
    "* <font color='brown'>(**#**)</font> The `num_workers` should be set to the lowest number which feeds the GPU fast enough.  \n",
    "  The idea is preserve as much as CPU resources to other tasks.\n",
    "* <font color='brown'>(**#**)</font> On Windows keep the `persistent_workers` parameter to `True` (_Windows_ is slower on forking processes / threads).\n",
    "* <font color='brown'>(**#**)</font> The Dataloader is a generator which can be looped on.\n",
    "* <font color='brown'>(**#**)</font> In order to make it iterable it has to be wrapped with `iter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "\n",
    "dlTrain  = torch.utils.data.DataLoader(dsTrain, shuffle = True, batch_size = 1 * batchSize, num_workers = numWork, drop_last = True, persistent_workers = True)\n",
    "dlTest   = torch.utils.data.DataLoader(dsTest, shuffle = False, batch_size = 2 * batchSize, num_workers = numWork, persistent_workers = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why is the size of the batch twice as big for the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate on the Loader\n",
    "# The first batch.\n",
    "tX, vY = next(iter(dlTrain)) #<! PyTorch Tensors\n",
    "\n",
    "print(f'The batch features dimensions: {tX.shape}')\n",
    "print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping\n",
    "for ii, (tX, vY) in zip(range(1), dlTest): #<! https://stackoverflow.com/questions/36106712\n",
    "    print(f'The batch features dimensions: {tX.shape}')\n",
    "    print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "\n",
    "The model is defined as a sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# Defining a sequential model.\n",
    "\n",
    "numFeatures = np.prod(tX.shape[1:])\n",
    "\n",
    "oModel = nn.Sequential(\n",
    "    nn.Identity(),\n",
    "        \n",
    "    nn.Conv2d(1,  8,  5, stride = 1), nn.ReLU(),\n",
    "    nn.Conv2d(8,  16, 5, stride = 1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 5, stride = 1), nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 5, stride = 1), nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 5, stride = 1), nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 5, stride = 1), nn.ReLU(),\n",
    "    \n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32, len(lClass)),\n",
    ")\n",
    "\n",
    "torchinfo.summary(oModel, tX.shape, device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What will be the effect of a bigger stride for `Conv2d`?\n",
    "* <font color='brown'>(**#**)</font> Pay attention to model size and the RAM fo the GPU. Rule of thumb, up to ~40%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization Function\n",
    "\n",
    "By default, PyTorch initializes the weights of the linear layers using the _Kaiming_ method to \"control\" the output variance.  \n",
    "Yet by default it initializes the weights using a _Uniform Distribution_.  \n",
    "\n",
    "PyTorch has several initialization methods as described in the [`torch.nn.init`](https://pytorch.org/docs/stable/nn.init.html) module.\n",
    "\n",
    "This section implement a function to initialize weights using the Kaiming method with _Gaussian Distribution_.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The implementation assumes to be used using [`apply()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.apply) method of a model.\n",
    "* <font color='brown'>(**#**)</font> The variance of a Uniform Distribution over `[a, b]`, $\\mathcal{U}_{\\left[ a, b \\right]}$ is given by $\\frac{1}{12} {\\left( b - a \\right)}^{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightInit( oModule: nn.Module ) -> None:\n",
    "    if isinstance(oModule, nn.Conv2d) or isinstance(oModule, nn.Conv1d) or isinstance(oModule, nn.Linear):\n",
    "        nn.init.kaiming_normal_(oModule.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The function alters only a sub set of the matching classes.\n",
    "* <font color='brown'>(**#**)</font> Convention in PyTorch: Functions ending with `_` are in place.  \n",
    "  See [`torch.nn.functional.relu_()`](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu_.html#torch.nn.functional.relu_) vs. [`torch.nn.functional.relu()`](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu_.html#torch.nn.functional.relu).  \n",
    "  It is accessible using `torch.relu()` and `torch.relu_()`.\n",
    "* <font color='red'>(**?**)</font> In the case of Linear Layers (_Fully Connected_ / _Dense) with input of dimensions $d$ and a _ReLU_ layer.  \n",
    "  What would be the value of $a$ in order to have weights uniformly distributed over $\\left[ -a, a \\right]$ matching the Kaiming initialization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "This section trains the model twice:\n",
    "\n",
    " 1. Using the default initialization (Kaiming, Uniform Distribution).\n",
    " 2. Using the implemented initialization (Kaiming, Gaussian Distribution).\n",
    "\n",
    "Both methods will be compared in their performance and analyzed using Hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Device\n",
    "\n",
    "runDevice   = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #<! The 1st CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Score Function\n",
    "\n",
    "hL = nn.CrossEntropyLoss()\n",
    "hS = MulticlassAccuracy(num_classes = len(lClass), average = 'micro')\n",
    "hL = hL.to(runDevice) #<! Not required!\n",
    "hS = hS.to(runDevice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> For binary problems one should use Binary Cross Entropy instead of Cross Entropy.  \n",
    "  Yet the number of outputs is only 1 and not 2. Why? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model - Default Initialization\n",
    "\n",
    "oRunModel = copy.deepcopy(oModel)\n",
    "oRunModel = oRunModel.to(runDevice) #<! Transfer model to device\n",
    "oOpt = torch.optim.SGD(oRunModel.parameters(), lr = 2e-2) #<! Define optimizer\n",
    "_, lTrainLossU, lTrainScoreU, lValLossU, lValScoreU, _ = TrainModel(oRunModel, dlTrain, dlTest, oOpt, nEpochs, hL, hS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model - Implemented Initialization\n",
    "\n",
    "oRunModel = copy.deepcopy(oModel)\n",
    "oRunModel = oRunModel.to(runDevice) #<! Transfer model to device\n",
    "oRunModel = oRunModel.apply(WeightInit)\n",
    "oOpt = torch.optim.SGD(oRunModel.parameters(), lr = 2e-2) #<! Define optimizer\n",
    "_, lTrainLossG, lTrainScoreG, lValLossG, lValScoreG, _ = TrainModel(oRunModel, dlTrain, dlTest, oOpt, nEpochs, hL, hS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The method [`apply()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.apply) applies a given function on any element of the model.  \n",
    "  The elements of the model are given by the result of the [`children()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.children) method (Iterator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 6))\n",
    "vHa = vHa.flat\n",
    "\n",
    "hA = vHa[0]\n",
    "hA.plot(lTrainLossU, lw = 2, ls = ':', label = 'Train Uniform')\n",
    "hA.plot(lValLossU, lw = 2, label = 'Validation Uniform')\n",
    "hA.plot(lTrainLossG, lw = 2, ls = ':', label = 'Train Gaussian')\n",
    "hA.plot(lValLossG, lw = 2, label = 'Validation Gaussian')\n",
    "hA.grid()\n",
    "hA.set_title('Cross Entropy Loss')\n",
    "hA.set_xlabel('Epoch Index')\n",
    "hA.set_ylabel('Loss')\n",
    "hA.legend();\n",
    "\n",
    "\n",
    "hA = vHa[1]\n",
    "hA.plot(lTrainScoreU, lw = 2, ls = ':', label = 'Train Uniform')\n",
    "hA.plot(lValScoreU, lw = 2, label = 'Validation Uniform')\n",
    "hA.plot(lTrainScoreG, lw = 2, ls = ':', label = 'Train Gaussian')\n",
    "hA.plot(lValScoreG, lw = 2, label = 'Validation Gaussian')\n",
    "hA.grid()\n",
    "hA.set_title('Accuracy Score')\n",
    "hA.set_xlabel('Epoch Index')\n",
    "hA.set_ylabel('Score')\n",
    "hA.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The results can not answer globally which initialization is superior. This is a specific limited case.\n",
    "* <font color='brown'>(**#**)</font> The motivation is to create a simple case to analyze using _Hook_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook\n",
    "\n",
    "This section implements a _Forward Hook_ to analyze the distribution of the values at the output of a layer in the model.\n",
    "\n",
    "The signature of an `nn.Module` hook is: `def ModuleHook(module: nn.Module, tIn: Tensor, tOut: Tensor):`.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The definition of the hook is given in [`torch.nn.Module.register_forward_hook()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_forward_hook).\n",
    "* <font color='brown'>(**#**)</font> If the hood returns a tensor it will override the output of the layer.\n",
    "* <font color='brown'>(**#**)</font> Hooks are nto part of the _computational graph_. Hence won't effect the backward pass.\n",
    "* <font color='brown'>(**#**)</font> There is a global model variation in [`torch.nn.modules.module.register_module_forward_hook()`](https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_hook.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer Statistics Container\n",
    "\n",
    "class LayerStats():\n",
    "    def __init__( self, numIter: int, numBins: int, tuRange: Tuple ) -> None:\n",
    "        \n",
    "        self.vMean  = np.full(numIter, np.nan)\n",
    "        self.vStd   = np.full(numIter, np.nan)\n",
    "        self.mHist  = np.full((numBins, numIter), np.nan)\n",
    "        self.mEdges = np.full((numBins + 1, numIter), np.nan)\n",
    "        \n",
    "        self.numIter    = numIter\n",
    "        self.ii         = 0 #<! Iteration index\n",
    "        self.numBins    = numBins #<! Number of bins for the histogram\n",
    "        self.tuRange    = tuRange #<! Range of the histogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook Function \n",
    "\n",
    "def ForwardHook( oLayer: nn.Module, mX: torch.Tensor, mZ: torch.Tensor, oLyrStats: LayerStats ) -> None:\n",
    "    # mX : Input Tensor.\n",
    "    # mZ : Output Tensor.\n",
    "    # No Return: No override of mZ\n",
    "    \n",
    "    if oLayer.training == False: #<! skip validation\n",
    "        return\n",
    "    \n",
    "    ii      = oLyrStats.ii\n",
    "    numBins = oLyrStats.numBins\n",
    "    tuRange = oLyrStats.tuRange\n",
    "\n",
    "    oLyrStats.vMean[ii] = mZ.data.mean().cpu()\n",
    "    oLyrStats.vStd[ii]  = mZ.data.std().cpu()\n",
    "    \n",
    "    oLyrStats.mHist[:, ii], oLyrStats.mEdges[:, ii] = np.histogram(mZ.data.view(-1).cpu(), bins = numBins, range = tuRange)\n",
    "    \n",
    "    oLyrStats.ii += 1   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation for Analysis\n",
    "\n",
    "nEpochs = 1 #<! Single Epoch\n",
    "numIter = nEpochs * len(dlTrain) #<! Number of Epochs x Number of Batches\n",
    "numBins = 101\n",
    "tuRange = (-1.0, 7.0)\n",
    "\n",
    "oLyrStat        = LayerStats(numIter, numBins, tuRange)\n",
    "hForwardHook    = lambda oLayer, mX, mZ: ForwardHook(oLayer, mX, mZ, oLyrStat) #<! Matching signature of the hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Hook - Default Initialization\n",
    "\n",
    "oRunModel = copy.deepcopy(oModel)\n",
    "oRunModel = oRunModel.to(runDevice) #<! Transfer model to device\n",
    "oLayer    = oRunModel[6] #<! The activation after the 3rd conv layer\n",
    "hHook     = oLayer.register_forward_hook(hForwardHook)\n",
    "oOpt      = torch.optim.SGD(oRunModel.parameters(), lr = 2e-2) #<! Define optimizer\n",
    "\n",
    "_, lTrainLossU, lTrainScoreU, lValLossU, lValScoreU, _ = TrainModel(oRunModel, dlTrain, dlTest, oOpt, nEpochs, hL, hS)\n",
    "\n",
    "\n",
    "hHook.remove() #<! Remove hook\n",
    "oLyrStatU = oLyrStat #<! Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of the Object\n",
    "oLyrStat        = LayerStats(numIter, numBins, tuRange)\n",
    "hForwardHook    = lambda oLayer, mX, mZ: ForwardHook(oLayer, mX, mZ, oLyrStat) #<! Matching signature of the hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Hook - Implemented Initialization\n",
    "\n",
    "oRunModel = copy.deepcopy(oModel)\n",
    "oRunModel = oRunModel.to(runDevice) #<! Transfer model to device\n",
    "oRunModel = oRunModel.apply(WeightInit)\n",
    "oLayer    = oRunModel[6] #<! The activation after the 3rd conv layer\n",
    "hHook     = oLayer.register_forward_hook(hForwardHook)\n",
    "oOpt      = torch.optim.SGD(oRunModel.parameters(), lr = 2e-2) #<! Define optimizer\n",
    "\n",
    "_, lTrainLossU, lTrainScoreU, lValLossU, lValScoreU, _ = TrainModel(oRunModel, dlTrain, dlTest, oOpt, nEpochs, hL, hS)\n",
    "\n",
    "hHook.remove() #<! Remove hook\n",
    "oLyrStatG = oLyrStat #<! Copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What happened to the run time? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Statistics Function\n",
    "\n",
    "def PlotStatistics( oLyrStats: LayerStats, hF: plt.Figure ) -> plt.Figure:\n",
    "    \n",
    "    vMean = oLyrStats.vMean\n",
    "    vStd  = oLyrStats.vStd\n",
    "    mHist = oLyrStats.mHist\n",
    "\n",
    "    tuRange = oLyrStats.tuRange\n",
    "\n",
    "    vAx = hF.axes\n",
    "\n",
    "    vAx[0].plot(oLyrStats.vMean, lw = 2)\n",
    "    vAx[1].plot(oLyrStats.vStd, lw = 2)\n",
    "    vAx[2].imshow(np.log(oLyrStats.mHist + 0.1), origin = 'lower', extent = [0, oLyrStats.ii, tuRange[0], tuRange[1]], aspect = 'auto')\n",
    "    vAx[0].set_title ('Activation Output - Mean')\n",
    "    vAx[1].set_title ('Activation Output - Standard Deviation')\n",
    "    vAx[2].set_title ('Activation Output - Histogram')\n",
    "    vAx[0].set_xlabel('Iteration')\n",
    "    vAx[1].set_xlabel('Iteration')\n",
    "    vAx[2].set_xlabel('Iteration')\n",
    "    vAx[0].grid()\n",
    "    vAx[1].grid()\n",
    "    \n",
    "    # hF.tight_layout()\n",
    "\n",
    "    return hF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results\n",
    "\n",
    "hF, _ = plt.subplots(nrows = 1, ncols = 3, figsize = (15, 6))\n",
    "PlotStatistics(oLyrStatU, hF)\n",
    "hF.suptitle('Activation Output Analysis - Uniform')\n",
    "\n",
    "hF, _ = plt.subplots(nrows = 1, ncols = 3, figsize = (15, 6))\n",
    "PlotStatistics(oLyrStatG, hF)\n",
    "hF.suptitle('Activation Output Analysis - Gaussian')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The more the variation in values, the better (Up to s limit) as the net is taking better advantage of its capacity.\n",
    "* <font color='red'>(**?**)</font> What would be the results of running more epochs?\n",
    "* <font color='green'>(**@**)</font> Increase the number of epochs and rerun the analysis.\n",
    "* <font color='brown'>(**#**)</font> The concept of activation of a neuron is \"firing\" (Positive value) when the feature the neuron was specialized on is detected.  \n",
    "  Hence vanishing neurons means no features were detected.   \n",
    "  This is a crude analogy, yet its intuition works in many cases.\n",
    "* <font color='brown'>(**#**)</font> **Don't generalize** (Which initialization is superior) the results to other models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
