{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io/)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - Supervised Learning - Regression - Least Squares with ${L}^{1}$ / ${L}^{2}$ Regularization\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 24/03/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0047RegressorL1L2Regularization.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.linear_model import lars_path, lasso_path\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Miscellaneous\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    " ```python\n",
    " vallToFill = ???\n",
    " ```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "???\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotRegressionData, PlotRegressionResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "def PlotPolyFit( vX: np.ndarray, vY: np.ndarray, vP: Optional[np.ndarray] = None, P: int = 1, numGridPts: int = 1001, \n",
    "                hA: Optional[plt.Axes] = None, figSize: Tuple[int, int] = FIG_SIZE_DEF, markerSize: int = MARKER_SIZE_DEF, \n",
    "                lineWidth: int = LINE_WIDTH_DEF, axisTitle: str = None ) -> None:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(1, 2, figsize = figSize)\n",
    "    else:\n",
    "        hF = hA[0].get_figure()\n",
    "\n",
    "    numSamples = len(vY)\n",
    "\n",
    "    # Polyfit\n",
    "    vW    = np.polyfit(vX, vY, P)\n",
    "    \n",
    "    # MSE\n",
    "    vHatY = np.polyval(vW, vX)\n",
    "    MSE   = (np.linalg.norm(vY - vHatY) ** 2) / numSamples\n",
    "    \n",
    "    # Plot\n",
    "    xx  = np.linspace(np.floor(np.min(vX)), np.ceil(np.max(vX)), numGridPts)\n",
    "    yy  = np.polyval(vW, xx)\n",
    "\n",
    "    hA[0].plot(vX, vY, '.r', ms = 10, label = '$y_i$')\n",
    "    hA[0].plot(xx, yy, 'b',  lw = 2,  label = '$\\hat{f}(x)$')\n",
    "    hA[0].set_title (f'$P = {P}$\\nMSE = {MSE}')\n",
    "    hA[0].set_xlabel('$x$')\n",
    "    # hA[0].axis(lAxis)\n",
    "    hA[0].grid()\n",
    "    hA[0].legend()\n",
    "    \n",
    "    hA[1].stem(vW[::-1], label = 'Estimated')\n",
    "    if vP is not None:\n",
    "        hA[1].stem(vP[::-1], linefmt = 'C1:', markerfmt = 'D', label = 'Ground Truth')\n",
    "    numTicks = len(vW) if vP is None else max(len(vW), len(vP))\n",
    "    hA[1].set_xticks(range(numTicks))\n",
    "    hA[1].set_title('Coefficients')\n",
    "    hA[1].set_xlabel('$w$')\n",
    "    hA[1].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with LASSO (${L}_{1}$) / Ridge (${L}_{2}$) Regularization\n",
    "\n",
    "Regularization is a simple and effective way to balance the adaptation of the model to the data.  \n",
    "It allows us to use complex model yet to tune it to prevent overfit.\n",
    "\n",
    "The models of optimization:\n",
    "\n",
    " - LASSO: $\\arg \\min_{\\boldsymbol{w}} \\frac{1}{2} {\\left\\| X \\boldsymbol{w} - \\boldsymbol{y} \\right\\|}_{2}^{2} + \\lambda {\\left\\| \\boldsymbol{w} \\right\\|}_{1}$.  \n",
    "   Promotes sparsity, modeled by a Laplace prior of the coefficients of $\\boldsymbol{w}$.\n",
    " - Ridge: $\\arg \\min_{\\boldsymbol{w}} \\frac{1}{2} {\\left\\| X \\boldsymbol{w} - \\boldsymbol{y} \\right\\|}_{2}^{2} + \\lambda {\\left\\| \\boldsymbol{w} \\right\\|}_{2}^{2}$.  \n",
    "   Promotes damped coefficients, modeled by a Gaussian prior of the coefficients of $\\boldsymbol{w}$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The LASSO model is implemented by the `Lasso` class in SciKit Learn.\n",
    "* <font color='brown'>(**#**)</font> The Ridge model is implemented by the `Ridge` class in SciKit Learn.\n",
    "* <font color='brown'>(**#**)</font> Both `Lasso` and `Ridge` (As well as `LinearRegression`) have the `positive` parameter to enforce non negative values for $\\boldsymbol{w}$.\n",
    "* <font color='brown'>(**#**)</font> The SciKit Learn classes use $\\alpha$ instead of $\\lambda$ in their optimization function.\n",
    "\n",
    "In this notebook we'll show the effect of the regularization on the fitness level of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data Generation\n",
    "numSamples  = 30\n",
    "noiseStd    = 17.5\n",
    "\n",
    "vP = np.array([0.5, 0.25, 2, 5])\n",
    "\n",
    "# Model\n",
    "lPolyDeg = [3, 5, 7, 9]\n",
    "lλ       = list(np.linspace(0, 200, 1001)) #<! Pay attention that for λ = 0 it is better to use LinearRegression model (Numerical reasons)\n",
    "lλ       = lλ[1:] #<! Prevent issues with λ = 0\n",
    "numSamplesTrain = 20\n",
    "numSamplesTest  = numSamples - numSamplesTrain\n",
    "\n",
    "maximumIter = 500_000\n",
    "\n",
    "# Data Visualization\n",
    "gridNoiseStd = 0.05\n",
    "numGridPts   = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "In the following we'll generate data according to the following model:\n",
    "\n",
    "$$ y_{i} = f \\left( x_{i} \\right) + \\epsilon_{i} $$\n",
    "\n",
    "Where\n",
    "\n",
    "$$ f \\left( x \\right) = \\frac{1}{2} {x}^{3} + \\frac{1}{4} {x}^{2} + 2 x + 5 $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Data Generating Function\n",
    "\n",
    "def f( vX: np.ndarray, vP: np.ndarray ):\n",
    "    \n",
    "    return np.polyval(vP, vX)\n",
    "\n",
    "\n",
    "hF = lambda vX: f(vX, vP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "\n",
    "vX = np.linspace(-5, 5, numSamples, endpoint = True) + (gridNoiseStd * np.random.randn(numSamples))\n",
    "vN = noiseStd * np.random.randn(numSamples)\n",
    "vY = hF(vX) + vN\n",
    "\n",
    "print(f'The features data shape: {vX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "PlotRegressionData(vX, vY)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "In order to show the importance of the regularization, we'll apply a split on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "mX = np.reshape(vX, (-1, 1))\n",
    "mXTrain, mXTest, vYTrain, vYTest = train_test_split(mX, vY, test_size = numSamplesTest, train_size = numSamplesTrain, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What does `stratify` mean in the context of splitting data for regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Regularized Polyfit Regressor\n",
    "\n",
    "The regularized PolyFit optimization problem is given by:\n",
    "\n",
    "$$ \\arg \\min_{\\boldsymbol{w}} {\\left\\| \\boldsymbol{X} \\boldsymbol{w} - \\boldsymbol{y} \\right|}_{2}^{2} + \\lambda R \\left( \\boldsymbol{w} \\right) $$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X} = \\begin{bmatrix} 1 & x_{1} & x_{1}^{2} & \\cdots & x_{1}^{p} \\\\\n",
    "1 & x_{2} & x_{2}^{2} & \\cdots & x_{2}^{p} \\\\\n",
    "\\vdots & \\vdots & \\vdots &  & \\vdots \\\\\n",
    "1 & x_{N} & x_{N}^{2} & \\cdots & x_{N}^{p}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And $R \\left( \\boldsymbol{w} \\right)$ is the regularization function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "\n",
    "# We could use the same instance of polynomial features object for both\n",
    "pPolyFitL1 = Pipeline([('PolyFeatures', PolynomialFeatures(include_bias = False)), ('Regressor', Lasso(fit_intercept = True, max_iter = maximumIter))])\n",
    "pPolyFitL2 = Pipeline([('PolyFeatures', PolynomialFeatures(include_bias = False)), ('Regressor', Ridge(fit_intercept = True))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score Data Frame\n",
    "\n",
    "numComb = len(lPolyDeg) * len(lλ)\n",
    "dData   = {'Poly Degree': [], 'λ': [], 'Train R2 L1 Regularization': [0.0] * numComb, 'Test R2 L1 Regularization': [0.0] * numComb, 'Train R2 L2 Regularization': [0.0] * numComb, 'Test R2 L2 Regularization': [0.0] * numComb}\n",
    "\n",
    "for ii, polyDeg in enumerate(lPolyDeg):\n",
    "    for jj, paramλ in enumerate(lλ):\n",
    "        dData['Poly Degree'].append(polyDeg)\n",
    "        dData['λ'].append(paramλ)\n",
    "#===============================================================#\n",
    "\n",
    "dfModelScore = pd.DataFrame(data = dData)\n",
    "dfModelScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring the Models\n",
    "\n",
    "for ii in range(numComb):\n",
    "    polyDeg  = dfModelScore.loc[ii, 'Poly Degree']\n",
    "    paramλ   = dfModelScore.loc[ii, 'λ']\n",
    "\n",
    "    print(f'Processing model {ii + 1:03d} out of {numComb} with `degree` = {polyDeg} and `λ` = {paramλ}.')\n",
    "\n",
    "    # The `__` Trick for Pipelines\n",
    "    pPolyFitL1.set_params(PolyFeatures__degree = polyDeg)\n",
    "    pPolyFitL1.set_params(Regressor__alpha = paramλ)\n",
    "    pPolyFitL2.set_params(PolyFeatures__degree = polyDeg)\n",
    "    pPolyFitL2.set_params(Regressor__alpha = paramλ)\n",
    "\n",
    "    pPolyFitL1.fit(mXTrain, vYTrain)\n",
    "    pPolyFitL2.fit(mXTrain, vYTrain)\n",
    "\n",
    "    dfModelScore.loc[ii, 'Train R2 L1 Regularization'] = pPolyFitL1.score(mXTrain, vYTrain)\n",
    "    dfModelScore.loc[ii, 'Test R2 L1 Regularization'] = pPolyFitL1.score(mXTest, vYTest)\n",
    "    dfModelScore.loc[ii, 'Train R2 L2 Regularization'] = pPolyFitL2.score(mXTrain, vYTrain)\n",
    "    dfModelScore.loc[ii, 'Test R2 L2 Regularization'] = pPolyFitL2.score(mXTest, vYTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Score DF\n",
    "\n",
    "dfModelScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results\n",
    "\n",
    "numFigures = len(lPolyDeg)\n",
    "numRows    = 2\n",
    "numCols    = int(np.ceil(numFigures / numRows))\n",
    "\n",
    "hF, hA = plt.subplots(nrows = numRows, ncols = numCols, figsize = (18, 8))\n",
    "hA = hA.flat\n",
    "\n",
    "for ii, ax in enumerate(hA):\n",
    "    if ii >= len(lPolyDeg):\n",
    "        continue\n",
    "    dsIdx = dfModelScore['Poly Degree'] == lPolyDeg[ii]\n",
    "    ax.plot(lλ, dfModelScore.loc[dsIdx, 'Train R2 L1 Regularization'], color = 'C0', ls = ':', label = 'Train L1')\n",
    "    ax.plot(lλ, dfModelScore.loc[dsIdx, 'Test R2 L1 Regularization'], color = 'C0', ls = '-', label = 'Test L1')\n",
    "    ax.plot(lλ, dfModelScore.loc[dsIdx, 'Train R2 L2 Regularization'], color = 'C1', ls = ':', label = 'Train L2')\n",
    "    ax.plot(lλ, dfModelScore.loc[dsIdx, 'Test R2 L2 Regularization'], color = 'C1', ls = '-', label = 'Test L2')\n",
    "\n",
    "    ax.set_ylim((0.50, 1.00))\n",
    "\n",
    "    ax.set_title(f'Regression with Polynomial of Degree {lPolyDeg[ii]}')\n",
    "    ax.set_xlabel('$\\lambda$')\n",
    "    ax.set_ylabel('${R}^{2}$')\n",
    "\n",
    "    ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
