{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - Supervised Learning - Classification - Kernel SVM - Exercise\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.1.000 | 05/10/2025 | Royi Avital | Added guidelines to use SVM / Kernel SVM                           |\n",
    "| 1.0.000 | 17/03/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0040ClassifierKernelSVM.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Image Processing\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    "```python\n",
    "# You need to start writing\n",
    "?????\n",
    "```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "# Fashion MNIST\n",
    "TRAIN_DATA_SET_IMG_URL = r'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz'\n",
    "TRAIN_DATA_SET_LBL_URL = r'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz'\n",
    "TEST_DATA_SET_IMG_URL  = r'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'\n",
    "TEST_DATA_SET_LBL_URL  = r'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "TRAIN_DATA_IMG_FILE_NAME = 'TrainImgFile'\n",
    "TRAIN_DATA_LBL_FILE_NAME = 'TrainLblFile'\n",
    "TEST_DATA_IMG_FILE_NAME  = 'TestImgFile'\n",
    "TEST_DATA_LBL_FILE_NAME  = 'TestLblFile'\n",
    "\n",
    "TRAIN_DATA_SET_FILE_NAME = 'FashionMnistTrainDataSet.npz'\n",
    "TEST_DATA_SET_FILE_NAME  = 'FashionMnistTestDataSet.npz'\n",
    "\n",
    "TRAIN_DATA_NUM_IMG  = 60_000\n",
    "TEST_DATA_NUM_IMG   = 10_000\n",
    "\n",
    "D_CLASSES = {0: 'T-Shirt', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Boots'}\n",
    "L_CLASSES = ['T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataManipulation import DownloadDecompressGzip, ConvertMnistDataDf\n",
    "from DataVisualization import PlotConfusionMatrix, PlotLabelsHistogram, PlotMnistImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "def IsStrFloat(inStr: any) -> bool:\n",
    "    #Support None input\n",
    "    if inStr is None: \n",
    "        return False\n",
    "    try:\n",
    "        float(inStr)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameter Optimization with Kernel SVM\n",
    "\n",
    "In this exercise we'll apply the Cross Validation automatically to find the optimal hyper parameters for the Kernel SVM Model.  \n",
    "In order to achieve this we'll do a [Grid Search for Hyper Parameters Optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization).\n",
    "\n",
    "1. Load the [Fashion MNIST Data Set](https://github.com/zalandoresearch/fashion-mnist) manually (Done by the notebook).\n",
    "2. Train a baseline Linear SVM model.\n",
    "3. Find the optimal Kernel SVM model using Grid Search.\n",
    "4. Extract the optimal model.\n",
    "5. Plot the Confusion Matrix of the best model on the training data.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may and should use the functions in the `Auxiliary Functions` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVM / Kernel SVM\n",
    "\n",
    "Assuming $n$ features ($\\boldsymbol{x} \\in \\mathbb{R}^{n}$) and $m$ training samples:\n",
    "\n",
    " - $n \\gg m$ - Use Linear Kernel SVM (Classic SVM) as first choice.\n",
    " - $n$ is small, $m$ is intermediate - Use RBF (Gaussian) Kernel SVM.\n",
    " - $n$ is small, $m$ is large - Generate more features and use Classic SVM as first choice.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The complexity of **Kernel SVM** is mostly determined by the number of samples.\n",
    "* <font color='brown'>(**#**)</font> Linear SVM are effective in cases where $n \\gg m$.  \n",
    "  Kernel SVM requires tuning of _Hyper Parameters_ to avoid **overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "numSamplesTrain = 4_000\n",
    "numSamplesTest  = 1_000\n",
    "numImg = 3\n",
    "\n",
    "# Linear SVM (Baseline Model)\n",
    "paramC      = 1\n",
    "kernelType  = 'linear'\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Think of the parameters to optimize.\n",
    "# 2. Select the set to optimize over.\n",
    "# 3. Set the number of folds in the cross validation.\n",
    "lC      = [0.1, 1, 3]\n",
    "lKernel = ['poly', 'rbf']\n",
    "lγ      = ['scale', 'auto', 0.1, 1, 10]\n",
    "numFold = 5\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "Load the [Fashion MNIST Data Set](https://github.com/zalandoresearch/fashion-mnist).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data \n",
    "\n",
    "if os.path.isfile(TRAIN_DATA_SET_FILE_NAME):\n",
    "    dData = np.load(TRAIN_DATA_SET_FILE_NAME)\n",
    "    mXTrain, vYTrain = dData['mXTrain'], dData['vYTrain']\n",
    "else:\n",
    "    if not os.path.isfile(TRAIN_DATA_IMG_FILE_NAME):\n",
    "        DownloadDecompressGzip(TRAIN_DATA_SET_IMG_URL, TRAIN_DATA_IMG_FILE_NAME) #<! Download Data (GZip File)\n",
    "    if not os.path.isfile(TRAIN_DATA_LBL_FILE_NAME):\n",
    "        DownloadDecompressGzip(TRAIN_DATA_SET_LBL_URL, TRAIN_DATA_LBL_FILE_NAME) #<! Download Data (GZip File)\n",
    "    mXTrain, vYTrain = ConvertMnistDataDf(TRAIN_DATA_IMG_FILE_NAME, TRAIN_DATA_LBL_FILE_NAME)\n",
    "    np.savez_compressed(TRAIN_DATA_SET_FILE_NAME, mXTrain  = mXTrain, vYTrain = vYTrain)\n",
    "    if os.path.isfile(TRAIN_DATA_IMG_FILE_NAME):\n",
    "        os.remove(TRAIN_DATA_IMG_FILE_NAME)\n",
    "    if os.path.isfile(TRAIN_DATA_LBL_FILE_NAME):\n",
    "        os.remove(TRAIN_DATA_LBL_FILE_NAME)\n",
    "\n",
    "if os.path.isfile(TEST_DATA_SET_FILE_NAME):\n",
    "    dData = np.load(TEST_DATA_SET_FILE_NAME)\n",
    "    mXTest, vYTest = dData['mXTest'], dData['vYTest']\n",
    "else:\n",
    "    if not os.path.isfile(TEST_DATA_IMG_FILE_NAME):\n",
    "        DownloadDecompressGzip(TEST_DATA_SET_IMG_URL, TEST_DATA_IMG_FILE_NAME) #<! Download Data (GZip File)\n",
    "    if not os.path.isfile(TEST_DATA_LBL_FILE_NAME):\n",
    "        DownloadDecompressGzip(TEST_DATA_SET_LBL_URL, TEST_DATA_LBL_FILE_NAME) #<! Download Data (GZip File)\n",
    "    mXTest, vYTest = ConvertMnistDataDf(TEST_DATA_IMG_FILE_NAME, TEST_DATA_LBL_FILE_NAME)\n",
    "    np.savez_compressed(TEST_DATA_SET_FILE_NAME, mXTest = mXTest, vYTest = vYTest)\n",
    "    if os.path.isfile(TEST_DATA_IMG_FILE_NAME):\n",
    "        os.remove(TEST_DATA_IMG_FILE_NAME)\n",
    "    if os.path.isfile(TEST_DATA_LBL_FILE_NAME):\n",
    "        os.remove(TEST_DATA_LBL_FILE_NAME)\n",
    "\n",
    "\n",
    "vSampleIdx = np.random.choice(mXTrain.shape[0], numSamplesTrain)\n",
    "mXTrain = mXTrain[vSampleIdx, :]\n",
    "vYTrain = vYTrain[vSampleIdx]\n",
    "\n",
    "vSampleIdx = np.random.choice(mXTest.shape[0], numSamplesTest)\n",
    "mXTest = mXTest[vSampleIdx, :]\n",
    "vYTest = vYTest[vSampleIdx]\n",
    "\n",
    "\n",
    "print(f'The number of train data samples: {mXTrain.shape[0]}')\n",
    "print(f'The number of train features per sample: {mXTrain.shape[1]}') \n",
    "print(f'The unique values of the train labels: {np.unique(vYTrain)}')\n",
    "print(f'The number of test data samples: {mXTest.shape[0]}')\n",
    "print(f'The number of test features per sample: {mXTest.shape[1]}') \n",
    "print(f'The unique values of the test labels: {np.unique(vYTest)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process Data\n",
    "\n",
    "The image data is in the `UInt8` data form with values in `{0, 1, 2, ..., 255}`.   \n",
    "The _pre process_ step scales it into `[0, 1]` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Data\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Scale data into [0, 1] range.\n",
    "mXTrain = mXTrain / 255\n",
    "mXTest  = mXTest / 255\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF = PlotMnistImages(mXTrain, vYTrain, numImg, lClasses = L_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Histogram of Classes\n",
    "\n",
    "hA = PlotLabelsHistogram(vYTrain)\n",
    "hA.set_xticks(range(len(L_CLASSES)))\n",
    "hA.set_xticklabels(L_CLASSES)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear SVM Classifier\n",
    "\n",
    "The _Linear SVM_ will function as the baseline classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear Model\n",
    "#===========================Fill This===========================#\n",
    "# 1. Construct a baseline model (Linear SVM).\n",
    "# 2. Train the model.\n",
    "# 3. Score the model (Accuracy). Keep result in a variable named `modelScore`.\n",
    "oSVM  = SVC(C = paramC, kernel = kernelType).fit(mXTrain, vYTrain)\n",
    "modelScore = oSVM.score(mXTest, vYTest)\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The model score (Accuracy) on the data: {modelScore:0.2%}') #<! Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Kernel SVM\n",
    "\n",
    "In this section we'll train a Kernel SVM. We'll find the optimal kernel and other hyper parameters by cross validation.  \n",
    "In order to optimize on the following parameters: `C`, `kernel` and `gamma` we'll use [`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).  \n",
    "The idea is iterating over the grid of parameters of the model to find the optimal one.  \n",
    "Each parameterized model is evaluated by a Cross Validation.\n",
    "\n",
    "In order to use it we need to define:\n",
    " - The Model (`estimator`) - Which model is used.\n",
    " - The Parameters Grid (`param_grid`) - The set of parameter to try.\n",
    " - The Scoring (`scoring`) - The score used to define the best model.\n",
    " - The Cross Validation Iterator (`cv`) - The iteration to validate the model.\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Pay attention to the expected run time. Using `verbose` is useful.\n",
    "* <font color='brown'>(**#**)</font> This is a classic grid search which is not the most efficient policy. There are more advanced policies.\n",
    "* <font color='brown'>(**#**)</font> The `GridSearchCV()` is limited to one instance of an estimator.  \n",
    "  Yet using Pipelines we may test different types of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Grid Search object \n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Set the parameters to iterate over and their values.\n",
    "dParams = {'C': lC, 'kernel': lKernel, 'gamma': lγ}\n",
    "#===============================================================#\n",
    "\n",
    "oGsSvc = GridSearchCV(estimator = SVC(), param_grid = dParams, scoring = None, cv = numFold, verbose = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Are there non effective combinations? If so, how can one solve them?  \n",
    "  Look at the option for _list of dictionaries_ in [`ParameterGrid`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html).\n",
    "* <font color='brown'>(**#**)</font> You may want to have a look at the `n_jobs` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter Optimization\n",
    "# Training the model with each combination of hyper parameters.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. The model trains on the train data using Stratified K Fold cross validation.\n",
    "oGsSvc = oGsSvc.fit(mXTrain, vYTrain) #<! It may take few minutes\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "# Extract the attributes of the best model.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Extract the best score.\n",
    "# 2. Extract a dictionary of the parameters.\n",
    "# !! Use the attributes of the `oGsSvc` object.\n",
    "bestScore   = oGsSvc.best_score_\n",
    "dBestParams = oGsSvc.best_params_\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The best model had the following parameters: {dBestParams} with the CV score: {bestScore:0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> In production one would visualize the effect of each parameter on the model result. Then use it to fine tune farther the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Best Model\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Extract the best model.\n",
    "# 2. Score the best model on the test data set.\n",
    "bestModel = oGsSvc.best_estimator_\n",
    "modelScore = bestModel.score(mXTest, vYTest)\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The model score (Accuracy) on the data: {modelScore:0.2%}') #<! Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> With proper tuning one can improve the baseline model by `~5%`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Best Model on the Train Data Set\n",
    "\n",
    "In production we take the optimal Hyper Parameters and then retrain the model on the whole training data set.  \n",
    "This is the model we'll use in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Model with Optimal Parameters\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Construct the model.\n",
    "# 2. Train the model.\n",
    "oSvmCls = SVC(**dBestParams)\n",
    "oSvmCls = oSvmCls.fit(mXTrain, vYTrain)\n",
    "#===============================================================#\n",
    "\n",
    "modelScore = oSvmCls.score(mXTest, vYTest)\n",
    "\n",
    "print(f'The model score (Accuracy) on the data: {modelScore:0.2%}') #<! Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Is the value above exactly as the value from the best model of the grid search? If so, look at the `refit` parameter of `GridSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics / Scores\n",
    "\n",
    "In this section we'll analyze the model using the _confusion matrix_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "hF, hA = plt.subplots(figsize = (10, 10))\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Plot the confusion matrix for the best model.\n",
    "# 2. Use the data labels (`L_CLASSES`).\n",
    "hA, mConfMat = PlotConfusionMatrix(vYTest, bestModel.predict(mXTest), lLabels = L_CLASSES, hA = hA)\n",
    "#===============================================================#\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Which class has the best accuracy?\n",
    "* <font color='red'>(**?**)</font> Which class has a dominant false prediction? Does it make sense?\n",
    "* <font color='red'>(**?**)</font> What's the difference between $p \\left( \\hat{y}_{i} = \\text{coat} \\mid {y}_{i} = \\text{coat} \\right)$ to $p \\left( {y}_{i} = \\text{coat} \\mid \\hat{y}_{i} = \\text{coat} \\right)$?\n",
    "* <font color='blue'>(**!**)</font> Make the proper calculations on `mConfMat` or the function `PlotConfusionMatrix` to answer the questions above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
