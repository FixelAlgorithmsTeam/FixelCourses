{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io/)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - Deep Learning - Regularized Training\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 04/07/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0097DeepLearningRegularizedTraining.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchinfo\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as TorchVisionTrns\n",
    "\n",
    "# Miscellaneous\n",
    "import copy\n",
    "from enum import auto, Enum, unique\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, Generator, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    " ```python\n",
    " vallToFill = ???\n",
    " ```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "???\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# Improve performance by benchmarking\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Reproducibility (Per PyTorch Version on the same device)\n",
    "# torch.manual_seed(seedNum)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark     = False #<! Makes things slower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "DATA_SET_FILE_NAME      = 'archive.zip'\n",
    "DATA_SET_FOLDER_NAME    = 'IntelImgCls'\n",
    "\n",
    "D_CLASSES  = {0: 'Airplane', 1: 'Automobile', 2: 'Bird', 3: 'Cat', 4: 'Deer', 5: 'Dog', 6: 'Frog', 7: 'Horse', 8: 'Ship', 9: 'Truck'}\n",
    "L_CLASSES  = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "T_IMG_SIZE = (32, 32, 3)\n",
    "\n",
    "DATA_FOLDER_PATH    = 'Data'\n",
    "TENSOR_BOARD_BASE   = 'TB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Auxiliary Modules for Google Colab\n",
    "if runInGoogleColab:\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataManipulation.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataVisualization.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DeepLearningPyTorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotLabelsHistogram, PlotMnistImages\n",
    "from DeepLearningPyTorch import ResidualBlock, TBLogger, TestDataSet\n",
    "from DeepLearningPyTorch import GenDataLoaders, InitWeightsKaiNorm, TrainModel, TrainModelSch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "def GenResNetModel( trainedModel: bool, numCls: int, resNetDepth: int = 18 ) -> nn.Module:\n",
    "    # Read on the API change at: How to Train State of the Art Models Using TorchVisionâ€™s Latest Primitives\n",
    "    # https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives\n",
    "\n",
    "    if (resNetDepth == 18):\n",
    "        modelFun = torchvision.models.resnet18\n",
    "        modelWeights = torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
    "    elif (resNetDepth == 34):\n",
    "        modelFun = torchvision.models.resnet34\n",
    "        modelWeights = torchvision.models.ResNet34_Weights.IMAGENET1K_V1\n",
    "    else:\n",
    "        raise ValueError(f'The `resNetDepth`: {resNetDepth} is invalid!')\n",
    "\n",
    "    if trainedModel:\n",
    "        oModel = modelFun(weights = modelWeights)\n",
    "        numFeaturesIn   = oModel.fc.in_features\n",
    "        # Assuming numCls << 100\n",
    "        oModel.fc       = nn.Sequential(\n",
    "            nn.Linear(numFeaturesIn, 128), nn.ReLU(),\n",
    "            nn.Linear(128, numCls),\n",
    "        )\n",
    "    else:\n",
    "        oModel = modelFun(weights = None, num_classes = numCls)\n",
    "\n",
    "    return oModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Training\n",
    "\n",
    "This notebook combines several regularization methods in order to maximize the **validation score**.\n",
    "\n",
    "\n",
    "This notebook demonstrate:\n",
    " - Using data augmentation using _CutMix_.\n",
    " - Using _Label Smoothing_.\n",
    "\n",
    "</br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "\n",
    "# Model\n",
    "dropP = 0.5 #<! Dropout Layer\n",
    "\n",
    "# Training\n",
    "batchSize   = 256\n",
    "numWorkers  = 4 #<! Number of workers\n",
    "numEpochs   = 35\n",
    "Ïµ = 0.1 #<! Label Smoothing\n",
    "\n",
    "# Visualization\n",
    "numImg = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "Load the [CIFAR 10 Data Set](https://en.wikipedia.org/wiki/CIFAR-10).  \n",
    "It is composed of 60,000 RGB images of size `32x32` with 10 classes uniformly spread.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The dataset is retrieved using [Torch Vision](https://pytorch.org/vision/stable/index.html)'s built in datasets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "dsTrain = torchvision.datasets.CIFAR10(root = DATA_FOLDER_PATH, train = True,  download = True, transform = torchvision.transforms.ToTensor())\n",
    "dsVal   = torchvision.datasets.CIFAR10(root = DATA_FOLDER_PATH, train = False, download = True, transform = torchvision.transforms.ToTensor())\n",
    "lClass  = dsTrain.classes\n",
    "\n",
    "\n",
    "print(f'The training data set data shape: {dsTrain.data.shape}')\n",
    "print(f'The test data set data shape: {dsVal.data.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(lClass)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The dataset is indexible (Subscriptable). It returns a tuple of the features and the label.\n",
    "* <font color='brown'>(**#**)</font> While data is arranged as `H x W x C` the transformer, when accessing the data, will convert it into `C x H x W`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element of the Data Set\n",
    "\n",
    "mX, valY = dsTrain[0]\n",
    "\n",
    "print(f'The features shape: {mX.shape}')\n",
    "print(f'The label value: {valY}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "\n",
    "tX = dsTrain.data #<! NumPy Tensor (NDarray)\n",
    "mX = np.reshape(tX, (tX.shape[0], -1))\n",
    "vY = dsTrain.targets #<! NumPy Vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF = PlotMnistImages(mX, vY, numImg, tuImgSize = T_IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY, lClass = L_CLASSES)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> If data is converted into _grayscale_, how would it effect the performance of the classifier? Explain.  \n",
    "  You may assume the conversion is done using the mean value of the RGB pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Process Data\n",
    "\n",
    "This section normalizes the data to have zero mean and unit variance per **channel**.  \n",
    "It is required to calculate:\n",
    "\n",
    " * The average pixel value per channel.\n",
    " * The standard deviation per channel.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The values calculated on the train set and applied to both sets.\n",
    "* <font color='brown'>(**#**)</font> The the data will be used to pre process the image on loading by the `transformer`.\n",
    "* <font color='brown'>(**#**)</font> There packages which specializes in transforms: [`Kornia`](https://github.com/kornia/kornia), [`Albumentations`](https://github.com/albumentations-team/albumentations).  \n",
    "  They are commonly used for _Data Augmentation_ at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Standardization Parameters\n",
    "vMean = np.mean(dsTrain.data / 255.0, axis = (0, 1, 2))\n",
    "vStd  = np.std(dsVal.data / 255.0, axis = (0, 1, 2))\n",
    "\n",
    "print('Âµ =', vMean)\n",
    "print('Ïƒ =', vStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Transformer\n",
    "\n",
    "oTrnsTrain = TorchVisionTrns.Compose([\n",
    "    TorchVisionTrns.RandomHorizontalFlip(), #<! Can be done in UINT8 for faster performance\n",
    "    TorchVisionTrns.AutoAugment(policy = TorchVisionTrns.AutoAugmentPolicy.CIFAR10), #<! Requires `UINT8`\n",
    "    TorchVisionTrns.ToImage(),\n",
    "    TorchVisionTrns.ToDtype(torch.float32, scale = True),\n",
    "    TorchVisionTrns.Normalize(vMean, vStd)\n",
    "])\n",
    "\n",
    "oTrnsInfer = TorchVisionTrns.Compose([\n",
    "    TorchVisionTrns.ToImage(),\n",
    "    TorchVisionTrns.ToDtype(torch.float32, scale = True),\n",
    "    TorchVisionTrns.Normalize(vMean, vStd)\n",
    "])\n",
    "\n",
    "# Update the DS transformer\n",
    "dsTrain.transform   = oTrnsTrain\n",
    "dsVal.transform     = oTrnsInfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Normalized\" Image\n",
    "\n",
    "imgIdx = 5\n",
    "\n",
    "\n",
    "N, H, W, C = dsTrain.data.shape\n",
    "hF, vHA = plt.subplots(2, 3, figsize = (8, 4))\n",
    "vHA = vHA.flat\n",
    "for hA in vHA:\n",
    "    mX, valY = dsTrain[imgIdx] #<! Random\n",
    "    mX = torch.permute(mX, (1, 2, 0))\n",
    "    hA.imshow(torch.clip(mX * vStd[None, None, :] + vMean[None, None, :], min = 0.0, max = 1.0))\n",
    "    hA.set_title(f'True label: {L_CLASSES[valY]}')\n",
    "    \n",
    "hF.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders\n",
    "\n",
    "This section defines the data loaded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "\n",
    "dlTrain = torch.utils.data.DataLoader(dsTrain, shuffle = True, batch_size = 1 * batchSize, num_workers = 2, drop_last = True, persistent_workers = True)\n",
    "dlVal   = torch.utils.data.DataLoader(dsVal, shuffle = False, batch_size = 2 * batchSize, num_workers = 2, persistent_workers = True)\n",
    "\n",
    "# dlTrain = torch.utils.data.DataLoader(dsTrain, shuffle = True, batch_size = 1 * batchSize, num_workers = 0, drop_last = True)\n",
    "# dlVal   = torch.utils.data.DataLoader(dsVal, shuffle = False, batch_size = 2 * batchSize, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate on the Loader\n",
    "# The first batch.\n",
    "tX, vY = next(iter(dlTrain)) #<! PyTorch Tensors\n",
    "\n",
    "print(f'The batch features dimensions: {tX.shape}')\n",
    "print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping\n",
    "# for ii, (tX, vY) in zip(range(1), dlVal): #<! https://stackoverflow.com/questions/36106712\n",
    "#     print(f'The batch features dimensions: {tX.shape}')\n",
    "#     print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "This section loads the model.  \n",
    "The number of outputs is adjusted to match the number of classes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a Pre Defined Model\n",
    "oModel = GenResNetModel(trainedModel = False, numCls = len(L_CLASSES))\n",
    "# oModel.apply(InitWeightsKaiNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Information - Pre Defined\n",
    "# Pay attention to the layers name.\n",
    "torchinfo.summary(oModel, (batchSize, *(T_IMG_SIZE[::-1])), col_names = ['kernel_size', 'output_size', 'num_params'], device = 'cpu', row_settings = ['depth', 'var_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Does the last (_Head_) dense layer includes a bias? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "This section trains the model.  \n",
    "It compares results with and without _Label Smoothing_.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The objective is to show how to apply _Label Smoothing_.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CutMix\n",
    "\n",
    "There are 2 options to incorporate the `CutMix` (Or `MixUp`):\n",
    "\n",
    "1. The Training Loop.\n",
    "2. The Data Loader.\n",
    "\n",
    "The (1) option requires adapting the training loop after fetching the batch.  \n",
    "The (2) option works with no change of the training loop.\n",
    "\n",
    "This section implements the (2) option.  \n",
    "This requires altering the `collate_fn` of the data loader.  \n",
    "The `collate_fn` takes a list of items where each item is a single output of `DataSet` object.\n",
    "For example, in image classification the output of the `DataSet` is usually a tuple of `(imge, label)`.  \n",
    "Hence the input to `collate_fn` is a list (Length of `batchSize`) of such tuples and the output is a tuple of 2 tensors.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The `CutMix` / `MixUp` can't be incorporated into the `DataSet` transform as they require multiple images at once.\n",
    "* <font color='brown'>(**#**)</font> PyTorch [`CutMix`](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.CutMix.html).\n",
    "* <font color='brown'>(**#**)</font> PyTorch [How to use CutMix and MixUp](https://pytorch.org/vision/main/auto_examples/transforms/plot_cutmix_mixup.html).\n",
    "* <font color='brown'>(**#**)</font> PyTorch [Working with `collate_fn`](https://pytorch.org/docs/stable/data.html#dataloader-collate-fn).\n",
    "* <font color='brown'>(**#**)</font> [PyTorch Datasets, DataLoader, Samplers and the `collat_fn`](https://scribe.rip/bbfc7c527cf1).\n",
    "* <font color='brown'>(**#**)</font> [StackOverflow - Use `collate_fn` with `DataLoader`](https://stackoverflow.com/questions/65279115)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the Collate Function\n",
    "\n",
    "from torch.utils.data import default_collate\n",
    "Î± = 0.5\n",
    "numCls = len(L_CLASSES)\n",
    "\n",
    "oCutMix = TorchVisionTrns.CutMix(alpha = Î±, num_classes = numCls) #<! `num_classes` must be defined for integer label\n",
    "\n",
    "def CutMixColateFun( lBatch: List[Tuple] ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    return oCutMix(*default_collate(lBatch))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Data Loaders\n",
    "# Custom collate function seems to not work with `numWorkers > 0` on Windows.\n",
    "dlTrain, dlVal = GenDataLoaders(dsTrain, dsVal, batchSize, numWorkers = 0, CollateFn = CutMixColateFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate on the Loader\n",
    "# The first batch.\n",
    "tX, mY = next(iter(dlTrain)) #<! PyTorch Tensors\n",
    "\n",
    "print(f'The batch features dimensions: {tX.shape}')\n",
    "print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from Data Loader\n",
    "\n",
    "hF, vHA = plt.subplots(2, 3, figsize = (8, 4))\n",
    "vHA = vHA.flat\n",
    "for hA, mXX, vYY in zip(vHA, tX, mY):\n",
    "    valY = torch.argmax(vYY)\n",
    "    mX = torch.permute(mXX, (1, 2, 0))\n",
    "    hA.imshow(torch.clip(mX * vStd[None, None, :] + vMean[None, None, :], min = 0.0, max = 1.0))\n",
    "    hA.set_title(f'True label: {L_CLASSES[valY]}')\n",
    "    \n",
    "hF.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Device\n",
    "\n",
    "runDevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #<! The 1st CUDA device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Score Function\n",
    "\n",
    "hL = nn.CrossEntropyLoss(label_smoothing = Ïµ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Score\n",
    "# Adjusting the score to support the labels in a form od discrete distribution\n",
    "\n",
    "def hS( mZ: torch.Tensor, mY: torch.Tensor ):\n",
    "\n",
    "    numDim = mY.ndim\n",
    "\n",
    "    vZ = torch.argmax(mZ, dim = 1)\n",
    "    if numDim > 1: #<! Discrete Distribution\n",
    "        vY = torch.argmax(mY, dim = 1)\n",
    "    else: #<! Label as an integer\n",
    "        vY = mY\n",
    "\n",
    "    return torch.sum(torch.eq(vZ, vY)) / vZ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "oModel = oModel.to(runDevice)\n",
    "oOpt = torch.optim.AdamW(oModel.parameters(), lr = 1e-3, betas = (0.9, 0.99), weight_decay = 1e-2) #<! Define optimizer\n",
    "oSch = torch.optim.lr_scheduler.OneCycleLR(oOpt, max_lr = 5e-2, total_steps = numEpochs)\n",
    "_, lTrainLoss, lTrainScore, lValLoss, lValScore, lLearnRate = TrainModel(oModel, dlTrain, dlVal, oOpt, numEpochs, hL, hS, oSch = oSch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training Phase\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = 3, figsize = (12, 5))\n",
    "vHa = np.ravel(vHa)\n",
    "\n",
    "hA = vHa[0]\n",
    "hA.plot(lTrainLoss, lw = 2, label = 'Train')\n",
    "hA.plot(lValLoss, lw = 2, label = 'Validation')\n",
    "hA.set_title('Binary Cross Entropy Loss')\n",
    "hA.set_xlabel('Epoch')\n",
    "hA.set_ylabel('Loss')\n",
    "hA.legend()\n",
    "\n",
    "hA = vHa[1]\n",
    "hA.plot(lTrainScore, lw = 2, label = 'Train')\n",
    "hA.plot(lValScore, lw = 2, label = 'Validation')\n",
    "hA.set_title('Accuracy Score')\n",
    "hA.set_xlabel('Epoch')\n",
    "hA.set_ylabel('Score')\n",
    "hA.legend()\n",
    "\n",
    "hA = vHa[2]\n",
    "hA.plot(lLearnRate, lw = 2)\n",
    "hA.set_title('Learn Rate Scheduler')\n",
    "hA.set_xlabel('Epoch')\n",
    "hA.set_ylabel('Learn Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Explain the training loss vs. the validation loss.\n",
    "* <font color='blue'>(**!**)</font> Replace the augmentation with `MixUp`.\n",
    "* <font color='green'>(**@**)</font> Train a model based on self implementation of ResNet / ResNeXt (Use `ResidualBlock`).\n",
    "* <font color='green'>(**@**)</font> Implement \"Test Time\" augmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
