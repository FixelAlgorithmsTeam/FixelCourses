{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io/)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - UnSupervised Learning - Dimensionality Reduction - Principal Component Analysis (PCA)\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 13/04/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0063DimensionalityReductionPCA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Miscellaneous\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    " ```python\n",
    " vallToFill = ???\n",
    " ```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "???\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotMnistImages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "hOrdinalNum = lambda n: '%d%s' % (n, 'tsnrhtdd'[(((math.floor(n / 10) %10) != 1) * ((n % 10) < 4) * (n % 10))::4])\n",
    "\n",
    "def PlotPcaReconstruction( mX: np.ndarray, dataIdx: int, mU: np.ndarray, vMean: np.ndarray, numComp:int, vSize: np.ndarray, hA: Optional[plt.Axes] = None, figSize: Tuple[int, int] = FIG_SIZE_DEF ) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(nrows = 1, ncols = 3, figsize = figSize)\n",
    "    else:\n",
    "        hF = hA.get_figure()\n",
    "\n",
    "    vX = mX[dataIdx, :]\n",
    "\n",
    "    if numComp == 0:\n",
    "        vZ    = [0]\n",
    "        vHatX = vMean\n",
    "    else:\n",
    "        vZ    = mU[:numComp]   @ (vX - vMean) #<! Encode\n",
    "        vHatX = (mU[:numComp].T @  vZ) + vMean  #<! Decode\n",
    "        \n",
    "    mI   = np.clip(np.reshape(vX, vSize), 0, 1)\n",
    "    mRec = np.clip(np.reshape(vHatX, vSize), 0, 1)\n",
    "\n",
    "    hA[0].imshow(mI, cmap = 'gray');\n",
    "    hA[0].set_title('Original Image')\n",
    "\n",
    "    hA[1].imshow(mRec, cmap = 'gray');\n",
    "    hA[1].set_title(f'Reconstructed Image, # Components: {numComp}')\n",
    "\n",
    "    hA[2].stem(vZ, markerfmt = 'b.', label = 'Coefficients')\n",
    "    hA[2].set_xlabel('Principal Component')\n",
    "    hA[2].set_ylabel('Coefficient Value')\n",
    "\n",
    "    return hA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction by PCA\n",
    "\n",
    "In this note book we'll use the PCA approach for dimensionality reduction.\n",
    "\n",
    "This notebook introduces:\n",
    "\n",
    "1. The [Olivetti Faces Data Set from AT&T](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html).\n",
    "2. Showing the PCA spectrum.\n",
    "3. Showing the PCA reconstruction (Eigen Faces).\n",
    "\n",
    "### Eigen Faces\n",
    "\n",
    "One of the first successful approaches to face recognition is the concept of [_Eigenface_](https://en.wikipedia.org/wiki/Eigenface).   \n",
    "Given enough data (Images) of the subject we build the PCA of the face of each subject.  \n",
    "We use those as a mean to recognize the person.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> PCA is the most basic dimensionality reduction operator.\n",
    "* <font color='brown'>(**#**)</font> The PCA output is a linear combination of the input.\n",
    "* <font color='brown'>(**#**)</font> Conceptually we may think of Dimensionality Reduction as a _soft_ feature selection / mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "tImgSize = (64, 64)\n",
    "numRows = 3\n",
    "numCols = 3\n",
    "\n",
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "In this notebook we'll use the [Olivetti Faces Data Set from AT&T](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html).  \n",
    "The data set is available on SciKit Learn using [`fetch_olivetti_faces()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html). \n",
    "\n",
    "The data set itself is built like the MNIST, each row is an image.  \n",
    "The size of the images is `(64, 64)` and there are 40 classes.\n",
    "\n",
    "There are ten different images of each of 40 distinct subjects.  \n",
    "For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses).  \n",
    "All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "mX, vY   = fetch_olivetti_faces(return_X_y = True)\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The features data type: {mX.dtype}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Do we need to scale the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF = PlotMnistImages(mX, vY, numRows, numCols, tuImgSize = tImgSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Dimensionality Reduction - PCA \n",
    "\n",
    "The PCA method basically treats the data as a Gaussian Distribution.   \n",
    "Hence, it basically decomposes the ellipsoid into its radius components, each in its own orthogonal to the others, direction.  \n",
    "Those are sorted by the variance along each direction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the PCA Model\n",
    "numComp    = min(mX.shape)\n",
    "numSamples = mX.shape[0]\n",
    "\n",
    "oPCA = PCA(n_components = numComp) #<! Calculate all the components of the data (The default)\n",
    "oPCA = oPCA.fit(mX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Mean Image  \n",
    "\n",
    "The PCA works on a centered data.  \n",
    "Hence the mean image is kept a side for the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Mean Image\n",
    "\n",
    "hF = PlotMnistImages(np.atleast_2d(oPCA.mean_), np.array(['Mean Image']), 1, 1, tuImgSize = tImgSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PCA Spectrum\n",
    "\n",
    "vλ = oPCA.explained_variance_ratio_\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (12, 6))\n",
    "hA.stem(np.sqrt(vλ[:200]), markerfmt = 'b.', label = '$\\\\sqrt{\\lambda_i}$')\n",
    "hA.set_title('Eigen Values')\n",
    "hA.set_xlabel('$i$')\n",
    "hA.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Energy Ratio\n",
    "\n",
    "vλ = oPCA.explained_variance_ratio_\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (12, 6))\n",
    "hA.stem(vλ, markerfmt = 'b.', label = '$Ratio$')\n",
    "hA.set_title('Variance Ratio')\n",
    "hA.set_xlabel('$Component Index$')\n",
    "hA.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Look at the rate the accumulated explained energy is accumulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Components\n",
    "\n",
    "mU = oPCA.components_ #<! mU.shape = (n_components, n_features)\n",
    "\n",
    "hF, hAs = plt.subplots(nrows = 2, ncols = 5, figsize = (12, 6))\n",
    "vIdx    = list(range(5)) + list(range(numComp - 5, numComp))\n",
    "for kk, hA in zip(range(10), hAs.flat):\n",
    "    idx = vIdx[kk]\n",
    "    mI  = np.reshape(mU[idx], tImgSize)\n",
    "    hA.imshow(mI)\n",
    "    hA.set_title(f'{hOrdinalNum(idx + 1)} Principal Component')\n",
    "    \n",
    "hF.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Reconstruction\n",
    "\n",
    "* Encode:\n",
    "$$\\boldsymbol{z}_{i}=\\boldsymbol{U}_{d}^{T}\\left(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{x}\\right)$$  \n",
    "\n",
    "* Decode:\n",
    "$$\\hat{\\boldsymbol{x}}_{i}=\\boldsymbol{U}_{d}\\boldsymbol{z}_{i}+\\boldsymbol{\\mu}_{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Function Wrapper\n",
    "hPlotPcaReconstruction = lambda dataIdx, numComponents: PlotPcaReconstruction(mX, dataIdx, mU, oPCA.mean_, numComponents, tImgSize, figSize = (14, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Visualization \n",
    "dataIdxSlider = IntSlider(min = 0, max = numSamples - 1, step = 1, value = 0, layout = Layout(width = '30%'))\n",
    "numComponentsSlider = IntSlider(min = 0, max = numComp, step = 1, value = 0, layout = Layout(width = '30%'))\n",
    "\n",
    "interact(hPlotPcaReconstruction, dataIdx = dataIdxSlider, numComponents = numComponentsSlider)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Describe how the actual recognition of a given face is done.\n",
    "* <font color='green'>(**@**)</font> Remove one image from each class. Then build a recognition system based on all other images. Show the success rate.\n",
    "\n",
    "<!-- Given the data base, each image in the data base has its own finger print on the data base: $\\boldsymbol{z}_{i}$.  \n",
    "Then, for a new image:\n",
    "\n",
    "1. Calculate its encoding using the components: $\\boldsymbol{z}_{new} = \\boldsymbol{U}_{d}^{T} \\left( \\boldsymbol{x}_{new} - \\boldsymbol{\\mu}_{x} \\right)$.\n",
    "2. Calculate the distance to the closest existing finger printing: $j = \\arg \\min_{i} {d}_{i} = \\left\\| \\boldsymbol{z}_{new} - \\boldsymbol{z}_{i}$.\n",
    "3. If ${d}_{j} \\leq {\\vareps}_{1}$ for a given threshold ${\\vareps}_{1}$ then the face is recognized as the $j$ -th face in the data base.\n",
    "4. If ${\\vareps}_{1} < {d}_{j} \\leq {\\vareps}_{2}$ for a given threshold ${\\vareps}_{2}$ then the image is not in the data base yet can be added.\n",
    "5. If ${\\vareps}_{2} < {d}_{j}$ for a given threshold ${\\vareps}_{2}$ then the image is not considered a face image. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
