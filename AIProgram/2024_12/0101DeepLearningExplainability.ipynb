{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Deep Learning - Computer Vision - Shapely Values for Deep Learning\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 21/03/2025 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0099DeepLearningObjectDetection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "import shap\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchinfo\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as TorchVisionTrns\n",
    "\n",
    "# Miscellaneous\n",
    "from enum import auto, Enum, unique\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, Generator, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    "```python\n",
    "# You need to start writing\n",
    "?????\n",
    "```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# Improve performance by benchmarking\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Reproducibility (Per PyTorch Version on the same device)\n",
    "# torch.manual_seed(seedNum)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark     = False #<! Makes things slower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "DATA_SET_FILE_NAME      = 'archive.zip'\n",
    "DATA_SET_FOLDER_NAME    = 'IntelImgCls'\n",
    "\n",
    "D_CLASSES   = {ii: str(ii) for ii in range(10)}\n",
    "L_CLASSES   = [str(ii) for ii in range(10)]\n",
    "TU_IMG_SIZE = (28, 28, 1)\n",
    "\n",
    "PROJECT_NAME     = 'FixelCourses'\n",
    "DATA_FOLDER_PATH = 'DataSets'\n",
    "BASE_FOLDER      = os.getcwd()[:len(os.getcwd()) - (os.getcwd()[::-1].lower().find(PROJECT_NAME.lower()[::-1]))]\n",
    "\n",
    "TENSOR_BOARD_BASE   = 'TB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Auxiliary Modules for Google Colab\n",
    "if runInGoogleColab:\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataManipulation.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataVisualization.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DeepLearningPyTorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotLabelsHistogram, PlotMnistImages\n",
    "from DeepLearningPyTorch import TrainModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "def TensorImageNumpy( tZ: torch.Tensor ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a PyTorch Tensor to a Numpy Array.\n",
    "    \"\"\"\n",
    "    mZ = tZ.squeeze()\n",
    "    mX = mZ.detach().cpu().numpy()\n",
    "\n",
    "    return mX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapely Values\n",
    "\n",
    "![](https://i.postimg.cc/BbkcrzRM/shap-headeraa.png)\n",
    "<!-- ![](https://i.imgur.com/oCqTLBk.png) -->\n",
    "\n",
    "The [SHAP](https://github.com/shap/shap) (SHapley Additive exPlanations) package allows to create explanation per **processed sample**.  \n",
    "It is based on a game theoretic approach to explain the output of **any** _Machine Learning Model_.\n",
    "\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The concept of the Shapely Values is to measure the marginal contribution of each feature.   \n",
    "  The concept is to look at any combination of the features \n",
    "* <font color='brown'>(**#**)</font> The values can be used for _Feature Importance_ for _Feature Engineering_ during the training process.\n",
    "* <font color='brown'>(**#**)</font> Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue.\n",
    "* <font color='brown'>(**#**)</font> Resources on Shapely Values:\n",
    "  - [Understanding SHAP Values: A Panoramic Guide](https://scribe.rip/132e817c01f0).\n",
    "  - [Aidan Cooper - Explaining Machine Learning Models: A Non Technical Guide to Interpreting SHAP Analyses](https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses).\n",
    "  - [Problems with Shapley Value Based Explanations as Feature Importance Measures](https://hdc.cs.arizona.edu/papers/html/icml_2020_shapley.html).\n",
    "  - [Interpretable Machine Learning - Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html).\n",
    "  - [Reddit - Shapely Values Discussion](https://www.reddit.com/r/datascience/comments/w5d3zg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "numSamplesTrain = 30_000\n",
    "numSamplesVal   = 10_000\n",
    "numCls          = len(L_CLASSES) #<! Number of classes\n",
    "maxObj          = 3\n",
    "\n",
    "dataFolder = os.path.join(BASE_FOLDER, DATA_FOLDER_PATH)\n",
    "\n",
    "# Model\n",
    "latDim     = 2\n",
    "latDimFctr = 8 #<! Linear Layer\n",
    "\n",
    "# Training\n",
    "batchSize   = 512\n",
    "numWorkers  = 2 #<! Number of workers\n",
    "numEpochs   = 5\n",
    "\n",
    "# Visualization\n",
    "numImg = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "The examples uses the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader Transform\n",
    "\n",
    "oTrns = TorchVisionTrns.Compose([\n",
    "    TorchVisionTrns.ToImage(),\n",
    "    TorchVisionTrns.ToDtype(torch.float, scale = True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set\n",
    "\n",
    "dsTrain = torchvision.datasets.MNIST(root = dataFolder, train = True,  transform = oTrns, download = True)\n",
    "dsVal   = torchvision.datasets.MNIST(root = dataFolder, train = False, transform = oTrns, download = True)\n",
    "\n",
    "print(f'The training data set RAW data shape: {dsTrain.data.shape}')\n",
    "print(f'The validation data set RAW data shape: {dsVal.data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element of the Data Set / Data Sample\n",
    "\n",
    "tX, valY = dsTrain[0]\n",
    "\n",
    "print(f'The features shape: {tX.shape}')\n",
    "print(f'The label         : {valY}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "mX = np.reshape(dsTrain.data.numpy(), (dsTrain.data.shape[0], -1))\n",
    "vY = dsTrain.targets.numpy()\n",
    "\n",
    "hF = PlotMnistImages(mX, vY, 3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY, lClass = L_CLASSES)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier\n",
    "\n",
    "A simple CNN model.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The SHAP package does not support all operations of PyTorch.  \n",
    "  See [supported operations of SHAP Deep Explainer](https://github.com/shap/shap/blob/0d1ae5a62c9e0cafc2368fddd1b76e670cf44cb5/shap/explainers/_deep/deep_pytorch.py#L375) (As of `2025_03`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oClsModel = nn.Sequential(\n",
    "    nn.Identity(),\n",
    "    \n",
    "    nn.Conv2d(in_channels = 1, out_channels = 30, kernel_size = 7, bias = False),\n",
    "    nn.MaxPool2d(kernel_size = 2),\n",
    "    nn.BatchNorm2d(num_features = 30),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Conv2d(in_channels = 30, out_channels = 60, kernel_size = 5, bias = False),\n",
    "    nn.MaxPool2d(kernel_size = 2),\n",
    "    nn.BatchNorm2d(num_features = 60),\n",
    "    nn.ReLU(),\n",
    "            \n",
    "    nn.Conv2d(in_channels = 60,  out_channels = 120, kernel_size = 3, bias = False),\n",
    "    nn.BatchNorm2d(num_features = 120),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(120, 10),\n",
    ")\n",
    "\n",
    "torchinfo.summary(oClsModel, (256, *(TU_IMG_SIZE[::-1])), col_names = ['kernel_size', 'output_size', 'num_params'], device = 'cpu', row_settings = ['depth', 'var_names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "\n",
    "dlTrain = torch.utils.data.DataLoader(dsTrain, shuffle = True, batch_size = 1 * batchSize, num_workers = numWorkers, drop_last = True, persistent_workers = True)\n",
    "dlVal   = torch.utils.data.DataLoader(dsVal, shuffle = False, batch_size = 2 * batchSize, num_workers = numWorkers, persistent_workers = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU Availability\n",
    "\n",
    "runDevice   = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #<! The 1st CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Score\n",
    "hL = nn.CrossEntropyLoss()\n",
    "hS = MulticlassAccuracy(num_classes = 10, average = 'micro')\n",
    "hL = hL.to(runDevice) #<! Not required!\n",
    "hS = hS.to(runDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oClsModel = oClsModel.to(runDevice) #<! Transfer model to device\n",
    "oOpt = torch.optim.AdamW(oClsModel.parameters(), lr = 6e-4, betas = (0.9, 0.99), weight_decay = 1e-3) #<! Define optimizer\n",
    "oRunModel, lTrainLoss, lTrainScore, lValLoss, lValScore, lLearnRate = TrainModel(oClsModel, dlTrain, dlVal, oOpt, numEpochs, hL, hS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training Phase\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = 3, figsize = (15, 5))\n",
    "vHa = np.ravel(vHa)\n",
    "\n",
    "hA = vHa[0]\n",
    "hA.plot(lTrainLoss, lw = 2, label = 'Train')\n",
    "hA.plot(lValLoss, lw = 2, label = 'Validation')\n",
    "hA.set_title(f'Classification Loss')\n",
    "hA.set_xlabel('Epoch')\n",
    "hA.set_ylabel('Loss')\n",
    "hA.legend()\n",
    "\n",
    "hA = vHa[1]\n",
    "hA.plot(lTrainScore, lw = 2, label = 'Train')\n",
    "hA.plot(lValScore, lw = 2, label = 'Validation')\n",
    "hA.set_title('Classification Score')\n",
    "hA.set_xlabel('Epoch')\n",
    "hA.set_ylabel('Score')\n",
    "hA.legend()\n",
    "\n",
    "hA = vHa[2]\n",
    "hA.plot(lLearnRate, lw = 2)\n",
    "hA.set_title('Learn Rate Scheduler')\n",
    "hA.set_xlabel('Epoch')\n",
    "hA.set_ylabel('Learn Rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expandability of Predictions\n",
    "\n",
    "This section use the [SHAP](https://github.com/shap/shap) package for expandability of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to CPU\n",
    "# The SHAP analyzer requires the model to be on the CPU.\n",
    "\n",
    "oClsModel = oClsModel.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Baseline\n",
    "\n",
    "tX, vY = next(iter(dlVal))\n",
    "\n",
    "tB = tX[:1000] #<! Baseline\n",
    "tP = tX[1000:1009] #<! Predictions\n",
    "\n",
    "oShapExp = shap.DeepExplainer(oClsModel, tB)\n",
    "tShapVal = oShapExp.shap_values(tP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Numpy\n",
    "lShapVal = list(np.transpose(tShapVal, (4, 0, 2, 3, 1)))\n",
    "tPShow   = np.swapaxes(np.swapaxes(tP.numpy(), 1, -1), 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Values\n",
    "The DL Explainer shows the contribution of each average feature to the current decision.  \n",
    "Hence each column is class and the values are contributions to the class values (The classifier takes the max over each row).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> See [Partition Explainer example](https://shap.readthedocs.io/en/latest/example_notebooks/image_examples/image_classification/Explain%20MobilenetV2%20using%20the%20Partition%20explainer%20%28PyTorch%29.html). It uses \"blurring\" effect to see the contribution of each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Values per Class\n",
    "shap.image_plot(lShapVal, -tPShow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
