{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - Deep Learning - PyTorch Regression - Exercise\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.001 | 02/06/2024 | Royi Avital | Changed `Test` into `Validation`                                   |\n",
    "|         |            |             | Added `α` as a parameter to the `LeakyReLU` layer                  |\n",
    "| 1.0.000 | 27/04/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0083DeepLearningPyTorchCifar10.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.regression import R2Score\n",
    "import torchinfo\n",
    "\n",
    "# Miscellaneous\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Typing\n",
    "from typing import Any, Callable, Dict, Generator, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    " ```python\n",
    " vallToFill = ???\n",
    " ```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "???\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# Improve performance by benchmarking\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Reproducibility\n",
    "# torch.manual_seed(seedNum)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark     = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "D_CLASSES_CIFAR_10  = {0: 'Airplane', 1: 'Automobile', 2: 'Bird', 3: 'Cat', 4: 'Deer', 5: 'Dog', 6: 'Frog', 7: 'Horse', 8: 'Ship', 9: 'Truck'}\n",
    "L_CLASSES_CIFAR_10  = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "T_IMG_SIZE_CIFAR_10 = (32, 32, 3)\n",
    "\n",
    "DATA_FOLDER_PATH    = 'Data'\n",
    "TENSOR_BOARD_BASE   = 'TB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Auxiliary Modules for Google Colab\n",
    "if runInGoogleColab:\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataManipulation.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataVisualization.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DeepLearningPyTorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DeepLearningPyTorch import NNMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California House Pricing Regression with PyTorch\n",
    "\n",
    "This notebook applies regression (Single value per sample) on the [California Housing Dataset](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html).  \n",
    "\n",
    "The notebook presents:\n",
    "\n",
    " * Use PyTorch tools for splitting of data.\n",
    " * The use of the MSE loss in PyTorch.\n",
    " * The use of the ${R}^{2}$ score in PyTorch.\n",
    " * Use grid search for weight decay parameter (`λ`).\n",
    " * Using [TensorBoard](https://www.tensorflow.org/tensorboard) with PyTorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "numSamplesTrain = 15_000\n",
    "numSamplesVal   = 5_640\n",
    "\n",
    "# Model\n",
    "dropP = 0.1 #<! Dropout Layer\n",
    "α     = 0.1 #<! LeakyReLu\n",
    "\n",
    "# Training\n",
    "batchSize   = 256\n",
    "numWork     = 2 #<! Number of workers\n",
    "nEpochs     = 200\n",
    "\n",
    "lλ = [0.0, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "\n",
    "# Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "This section loads the [California Housing Dataset](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html):\n",
    "\n",
    " * The dataset is retrieved using [`fetch_california_housing()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html).  \n",
    " * It is wrapped into a `Dataset` using [`torch.utils.data.TensorDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset).\n",
    " * The data is split to 15,000 train samples and 5,640 test samples.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The `TensorDataset` suits for small data sets which fit memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "mX, vY  = fetch_california_housing(return_X_y = True)\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')\n",
    "print(f'The labels data shape: {vY.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Wrap the data using `torch.utils.data.TensorDataset`.\n",
    "# 2. Split the data using `torch.utils.data.random_split` (numSamplesTrain, numSamplesVal).\n",
    "# !! Data must be converted into Tensors before using `TensorDataset`.\n",
    "# !! Make sure to define the `dtype` properly.\n",
    "dsData          = ???\n",
    "dsTrain, dsVal  = ???\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The training data set data shape: {(len(dsTrain), dsTrain.dataset.tensors[0].shape[1])}')\n",
    "print(f'The test data set data shape: {(len(dsVal), dsTrain.dataset.tensors[0].shape[1])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Pay attention that `dsTrain` and `dsVal` are [`Subset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Process Data\n",
    "\n",
    "Make the data zero mean and unit variance.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The normalization is applied per feature.\n",
    "* <font color='brown'>(**#**)</font> Calculation be based on the train data and applied to both.\n",
    "* <font color='brown'>(**#**)</font> Since data fits memory, no need for `transform`. In case it is needed, one must create a [custom `Dataset` sub class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Standardization Parameters\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Calculate the mean per feature.\n",
    "# 2. Calculate the standard deviation per feature.\n",
    "# !! Calculation by train data only.\n",
    "vMean = ???\n",
    "vStd  = ???\n",
    "#===============================================================#\n",
    "\n",
    "print('µ =', vMean)\n",
    "print('σ =', vStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Standardization Parameters\n",
    "\n",
    "# Train\n",
    "dsTrain.dataset.tensors[0][dsTrain.indices, :] -= vMean\n",
    "dsTrain.dataset.tensors[0][dsTrain.indices, :] /= vStd\n",
    "\n",
    "# Train\n",
    "dsVal.dataset.tensors[0][dsVal.indices, :] -= vMean\n",
    "dsVal.dataset.tensors[0][dsVal.indices, :] /= vStd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders\n",
    "\n",
    "The dataloader is the functionality which loads the data into memory in batches.  \n",
    "Its challenge is to bring data fast enough so the Hard Disk is not the training bottleneck.  \n",
    "In order to achieve that, Multi Threading / Multi Process is used.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The multi process, by the `num_workers` parameter is not working well _out of the box_ on Windows.  \n",
    "  See [Errors When Using `num_workers > 0` in `DataLoader`](https://discuss.pytorch.org/t/97564), [On Windows `DataLoader` with `num_workers > 0` Is Slow](https://github.com/pytorch/pytorch/issues/12831).  \n",
    "  A way to overcome it is to define the training loop as a function in a different module (File) and import it (https://discuss.pytorch.org/t/97564/4, https://discuss.pytorch.org/t/121588/21). \n",
    "* <font color='brown'>(**#**)</font> The `num_workers` should be set to the lowest number which feeds the GPU fast enough.  \n",
    "  The idea is preserve as much as CPU resources to other tasks.\n",
    "* <font color='brown'>(**#**)</font> On Windows keep the `persistent_workers` parameter to `True` (_Windows_ is slower on forking processes / threads).\n",
    "* <font color='brown'>(**#**)</font> The Dataloader is a generator which can be looped on.\n",
    "* <font color='brown'>(**#**)</font> In order to make it iterable it has to be wrapped with `iter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "\n",
    "# The `drop_last` parameter has a default of False in PyTorch\n",
    "dlTrain = torch.utils.data.DataLoader(dsTrain, shuffle = True, batch_size = 1 * batchSize, num_workers = numWork, drop_last = True, persistent_workers = True)\n",
    "dlVal   = torch.utils.data.DataLoader(dsVal, shuffle = False, batch_size = 2 * batchSize, num_workers = numWork, persistent_workers = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why is the size of the batch twice as big for the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate on the Loader\n",
    "# The first batch.\n",
    "tX, vY = next(iter(dlTrain)) #<! PyTorch Tensors\n",
    "\n",
    "print(f'The batch features dimensions: {tX.shape}')\n",
    "print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "\n",
    "The model is defined as a sequential model.\n",
    "\n",
    "The model is given by:\n",
    "\n",
    "```python\n",
    "==========================================================================================\n",
    "Layer (type:depth-idx)                   Output Shape              Param #\n",
    "==========================================================================================\n",
    "Sequential                               --                        --\n",
    "├─Identity: 1-1                          [128, 8]                  --\n",
    "├─Linear: 1-2                            [128, 900]                8,100\n",
    "├─LeakyReLU: 1-3                         [128, 900]                --\n",
    "├─Dropout: 1-4                           [128, 900]                --\n",
    "├─Linear: 1-5                            [128, 700]                630,700\n",
    "├─LeakyReLU: 1-6                         [128, 700]                --\n",
    "├─Dropout: 1-7                           [128, 700]                --\n",
    "├─Linear: 1-8                            [128, 500]                350,500\n",
    "├─LeakyReLU: 1-9                         [128, 500]                --\n",
    "├─Dropout: 1-10                          [128, 500]                --\n",
    "├─Linear: 1-11                           [128, 300]                150,300\n",
    "├─LeakyReLU: 1-12                        [128, 300]                --\n",
    "├─Dropout: 1-13                          [128, 300]                --\n",
    "├─Linear: 1-14                           [128, 100]                30,100\n",
    "├─LeakyReLU: 1-15                        [128, 100]                --\n",
    "├─Dropout: 1-16                          [128, 100]                --\n",
    "├─Linear: 1-17                           [128, 1]                  101\n",
    "├─Flatten: 1-18                          [128]                     --\n",
    "==========================================================================================\n",
    "Total params: 1,169,801\n",
    "Trainable params: 1,169,801\n",
    "```\n",
    "\n",
    "* <font color='brown'>(**#**)</font> One may alter the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# Defining a sequential model.\n",
    "\n",
    "numFeatures = mX.shape[1]\n",
    "\n",
    "def GetModel( dropP: float, α: float = 0.1 ) -> nn.Module:\n",
    "    oModel = nn.Sequential(\n",
    "        nn.Identity(), #<! Allows seeing the dimensions of the input\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Define the model layers.\n",
    "        # !! Use `dropP` for the Dropout layers.\n",
    "        ?????\n",
    "        #===============================================================#\n",
    "        nn.Flatten(start_dim = 0)\n",
    "        )\n",
    "    \n",
    "    return oModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Dropout and _LeakyReLU_ / _ReLU_ are mathematically commutative.\n",
    "* <font color='red'>(**?**)</font> Why is there no Dropout on the last layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "\n",
    "oModel = GetModel(dropP, α)\n",
    "torchinfo.summary(oModel, tX.shape, device = 'cpu')\n",
    "# torchinfo.summary(oModel, tX.shape, col_names = ['input_size', 'output_size', 'num_params'], device = 'cpu') #<! See input, hence Identity is redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Pay attention the dropout parameter of PyTorch is about the probability to zero out the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization Function\n",
    "\n",
    "def InitWeights( oLayer: nn.Module ) -> None:\n",
    "        if isinstance(oLayer, nn.Linear):\n",
    "            nn.init.kaiming_normal_(oLayer.weight.data) #<! Only on weights, not biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Manual Initialization\n",
    "\n",
    "oModel.apply(InitWeights) #<! Applies the function on all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model\n",
    "# Apply a test run.\n",
    "\n",
    "mXX   = torch.randn(batchSize, numFeatures)\n",
    "vYHat = oModel(mXX)\n",
    "\n",
    "print(f'The input dimensions: {mXX.shape}')\n",
    "print(f'The output dimensions: {vYHat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "[TensorBoard](https://www.tensorflow.org/tensorboard) is a tool to analyze runs of models.  \n",
    "The concept is to save data to HD while running and display it using the server.\n",
    "\n",
    "Using _TensorBoard_ is based on:\n",
    "\n",
    " * Defining a `SummaryWriter` object which documents a session.\n",
    " * Using the `SummaryWriter`'s method to add data: Scalars, Images, etc...\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> While [TensorBoard](https://www.tensorflow.org/tensorboard) is common in the DL world, it might used to handle any ML analysis.\n",
    "* <font color='brown'>(**#**)</font> See [`torch.utils.tensorboard.writer.SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard) documentation.\n",
    "* <font color='brown'>(**#**)</font> Alternatives: [ClearML](https://clear.ml), [Weights & Biases](https://wandb.ai), [ML Flow](https://mlflow.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Writer\n",
    "oTBWriter = SummaryWriter(log_dir = os.path.join(TENSOR_BOARD_BASE, 'Test'))\n",
    "oTBWriter.add_graph(oModel, mXX) #<! Graph of the Model\n",
    "oTBWriter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Alternatives to visualize a net: [StackOverflow - Visualize a PyTorch Model](https://stackoverflow.com/questions/52468956), [Tools to Design or Visualize Architecture of Neural Network](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Epoch PyTorch\n",
    "\n",
    "def RunEpoch( oModel: nn.Module, dlData: DataLoader, hL: Callable, hS: Callable, oOpt: Optional[Optimizer] = None, opMode: NNMode = NNMode.TRAIN ) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Runs a single Epoch (Train / Test) of a model.  \n",
    "    Input:\n",
    "        oModel      - PyTorch `nn.Module` object.\n",
    "        dlData      - PyTorch `Dataloader` object.\n",
    "        hL          - Callable for the Loss function.\n",
    "        hS          - Callable for the Score function.\n",
    "        oOpt        - PyTorch `Optimizer` object.\n",
    "        opMode      - An `NNMode` to set the mode of operation.\n",
    "    Output:\n",
    "        valLoss     - Scalar of the loss.\n",
    "        valScore    - Scalar of the score.\n",
    "    Remarks:\n",
    "      - The `oDataSet` object returns a Tuple of (mX, vY) per batch.\n",
    "      - The `hL` function should accept the `vY` (Reference target) and `mZ` (Output of the NN).  \n",
    "        It should return a Tuple of `valLoss` (Scalar of the loss) and `mDz` (Gradient by the loss).\n",
    "      - The `hS` function should accept the `vY` (Reference target) and `mZ` (Output of the NN).  \n",
    "        It should return a scalar `valScore` of the score.\n",
    "      - The optimizer is required for training mode.\n",
    "    \"\"\"\n",
    "    \n",
    "    epochLoss   = 0.0\n",
    "    epochScore  = 0.0\n",
    "    numSamples  = 0\n",
    "    numBatches = len(dlData)\n",
    "\n",
    "    runDevice = next(oModel.parameters()).device #<! CPU \\ GPU\n",
    "\n",
    "    if opMode == NNMode.TRAIN:\n",
    "        oModel.train(True) #<! Equivalent of `oModel.train()`\n",
    "    elif opMode == NNMode.INFERENCE:\n",
    "        oModel.eval() #<! Equivalent of `oModel.train(False)`\n",
    "    else:\n",
    "        raise ValueError(f'The `opMode` value {opMode} is not supported!')\n",
    "    \n",
    "    for ii, (mX, vY) in enumerate(dlData):\n",
    "        # Move Data to Model's device\n",
    "        mX = mX.to(runDevice) #<! Lazy\n",
    "        vY = vY.to(runDevice) #<! Lazy\n",
    "\n",
    "\n",
    "        batchSize = mX.shape[0]\n",
    "        \n",
    "        if opMode == NNMode.TRAIN:\n",
    "            # Forward\n",
    "            mZ      = oModel(mX) #<! Model output\n",
    "            valLoss = hL(mZ, vY) #<! Loss\n",
    "            \n",
    "            # Backward\n",
    "            oOpt.zero_grad()    #<! Set gradients to zeros\n",
    "            valLoss.backward()  #<! Backward\n",
    "            oOpt.step()         #<! Update parameters\n",
    "            oModel.eval()       #<! Set layers for inference mode\n",
    "        else: #<! Value of `opMode` was already validated\n",
    "            with torch.no_grad():\n",
    "                # No computational \n",
    "                mZ      = oModel(mX) #<! Model output\n",
    "                valLoss = hL(mZ, vY) #<! Loss\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Score\n",
    "            valScore = hS(mZ, vY)\n",
    "            # Normalize so each sample has the same weight\n",
    "            epochLoss  += batchSize * valLoss.item()\n",
    "            epochScore += batchSize * valScore.item()\n",
    "            numSamples += batchSize\n",
    "\n",
    "        print(f'\\r{\"Train\" if opMode == NNMode.TRAIN else \"Val\"} - Iteration: {ii:3d} ({numBatches}): loss = {valLoss:.6f}', end = '')\n",
    "    \n",
    "    print('', end = '\\r')\n",
    "            \n",
    "    return epochLoss / numSamples, epochScore / numSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> One could `with torch.inference_mode():` for inference mode.  \n",
    "  See [Inference in PyTorch: What Do the Wrappers Mean](https://muellerzr.github.io/blog/PyTorchInference.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model Loop Function\n",
    "\n",
    "def TrainModel( oModel: nn.Module, dlTrain: DataLoader, dlVal: DataLoader, oOpt: Optimizer, numEpoch: int, hL: Callable, hS: Callable , oTBWriter: Optional[SummaryWriter] = None) -> Tuple[nn.Module, List, List, List, List]:\n",
    "\n",
    "    lTrainLoss  = []\n",
    "    lTrainScore = []\n",
    "    lValLoss    = []\n",
    "    lValScore   = []\n",
    "\n",
    "    #!!!\n",
    "    # Support R2\n",
    "    bestScore = -1e9 #<! Assuming higher is better\n",
    "    #!!!\n",
    "\n",
    "    for ii in range(numEpoch):\n",
    "        startTime           = time.time()\n",
    "        trainLoss, trainScr = RunEpoch(oModel, dlTrain, hL, hS, oOpt, opMode = NNMode.TRAIN) #<! Train\n",
    "        valLoss,   valScr   = RunEpoch(oModel, dlVal, hL, hS, oOpt, opMode = NNMode.INFERENCE)    #<! Score Validation\n",
    "        epochTime           = time.time() - startTime\n",
    "\n",
    "        # Aggregate Results\n",
    "        lTrainLoss.append(trainLoss)\n",
    "        lTrainScore.append(trainScr)\n",
    "        lValLoss.append(valLoss)\n",
    "        lValScore.append(valScr)\n",
    "\n",
    "        #!!!\n",
    "        if oTBWriter is not None:\n",
    "            oTBWriter.add_scalar('Train Loss', trainLoss, ii)\n",
    "            oTBWriter.add_scalar('Train Score', trainScr, ii)\n",
    "            oTBWriter.add_scalar('Validation Loss', valLoss, ii)\n",
    "            oTBWriter.add_scalar('Validation Score', valScr, ii)\n",
    "        #!!!\n",
    "        \n",
    "        # Display (Babysitting)\n",
    "        print('Epoch '              f'{(ii + 1):4d} / ' f'{numEpoch}:', end = '')\n",
    "        print(' | Train Loss: '     f'{trainLoss          :6.3f}', end = '')\n",
    "        print(' | Val Loss: '       f'{valLoss            :6.3f}', end = '')\n",
    "        print(' | Train Score: '    f'{trainScr           :6.3f}', end = '')\n",
    "        print(' | Val Score: '      f'{valScr             :6.3f}', end = '')\n",
    "        print(' | Epoch Time: '     f'{epochTime          :5.2f}', end = '')\n",
    "\n",
    "        # Save best model (\"Early Stopping\")\n",
    "        if valScr > bestScore:\n",
    "            bestScore = valScr\n",
    "            print(' | <-- Checkpoint!', end = '')\n",
    "            try:\n",
    "                dCheckpoint = {'Model' : oModel.state_dict(), 'Optimizer' : oOpt.state_dict()}\n",
    "                torch.save(dCheckpoint, 'BestModel.pt')\n",
    "            except:\n",
    "                pass\n",
    "        print(' |')\n",
    "    \n",
    "    # Load best model (\"Early Stopping\")\n",
    "    dCheckpoint = torch.load('BestModel.pt')\n",
    "    oModel.load_state_dict(dCheckpoint['Model'])\n",
    "\n",
    "    return oModel, lTrainLoss, lTrainScore, lValLoss, lValScore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why is the state of the optimizer saved as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU Availability\n",
    "\n",
    "runDevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #<! The 1st CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Loss & Score\n",
    "\n",
    "hL = nn.MSELoss()\n",
    "hS = R2Score(num_outputs = 1)\n",
    "hS = hS.to(runDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "for ii, λ in enumerate(lλ):\n",
    "    # Hyper Parameter Loop\n",
    "    oTBWriter = SummaryWriter(log_dir = os.path.join(TENSOR_BOARD_BASE, f'Cali{ii:03d}'))\n",
    "    # oRunModel = GetModel(dropP, α)\n",
    "    oRunModel = copy.deepcopy(oModel) #<! All models with the same initialization\n",
    "    oRunModel = oRunModel.to(runDevice) #<! Transfer model to device\n",
    "    oOpt = torch.optim.AdamW(oRunModel.parameters(), lr = 1e-4, betas = (0.9, 0.99), weight_decay = λ) #<! Define optimizer\n",
    "    oRunModel, lTrainLoss, lTrainScore, lValLoss, lValScore = TrainModel(oRunModel, dlTrain, dlVal, oOpt, nEpochs, hL, hS, oTBWriter)\n",
    "    oTBWriter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> If all `λ` were the same, will all `oRunModel` give the same output? Think about the Dropout layer.\n",
    "* <font color='green'>(**@**)</font> Optimize model / hyper parameters to get ${R}^{2} \\approx 0.82$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard Results\n",
    "\n",
    " 1. Open _Command Line_ (`cmd` on Windows).\n",
    " 2. Change the path to the notebook folder.\n",
    " 3. Run `tensorboard --logdir=TB`.\n",
    " 4. Open the browser at the given address."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
