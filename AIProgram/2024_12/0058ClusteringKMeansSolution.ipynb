{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io/)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - UnSupervised Learning - Clustering - K-Means - Exercise\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 12/04/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0058ClusteringKMeans.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Image Processing Computer Vision\n",
    "import skimage as ski\n",
    "\n",
    "# Machine Learning\n",
    "from kneed import KneeLocator #<! Elbow Method\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Miscellaneous\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout, SelectionSlider\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    " ```python\n",
    " vallToFill = ???\n",
    " ```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "???\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "def ConvertRgbToLab( mRgb: np.ndarray ) -> np.ndarray:\n",
    "    # Converts sets of RGB features into LAB features.\n",
    "    # Input (numPx x 3)\n",
    "    # Output: (numPx x 3)\n",
    "    mRgb3D = np.reshape(mRgb, (1, -1, 3))\n",
    "    mLab3D = ski.color.rgb2lab(mRgb3D)\n",
    "\n",
    "    return np.reshape(mLab3D, (-1, 3))\n",
    "    \n",
    "\n",
    "def PlotSuperPixels( mI: np.ndarray, mMask: np.ndarray, boundColor: Tuple[float, float, float] = (0.0, 1.0, 1.0), figSize: Tuple[int, int] = FIG_SIZE_DEF, hA: Optional[plt.Axes] = None ) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = figSize)\n",
    "    else:\n",
    "        hF = hA.get_figure()\n",
    "    \n",
    "    mO = ski.segmentation.mark_boundaries(mI, mMask, boundColor)\n",
    "    \n",
    "    hA.imshow(mO)\n",
    "\n",
    "    return hA\n",
    "\n",
    "def PlotFeaturesHist( mX: np.ndarray, figSize: Tuple[int, int] = FIG_SIZE_DEF, hF: Optional[plt.Figure] = None ) -> plt.Figure:\n",
    "\n",
    "    numFeatures = mX.shape[1]\n",
    "    \n",
    "    if hF is None:\n",
    "        hF, hA = plt.subplots(nrows = 1, ncols = numFeatures, figsize = figSize)\n",
    "    else:\n",
    "        hA = np.array(hF.axes)\n",
    "    \n",
    "    hA = hA.flat\n",
    "\n",
    "    if len(hA) != numFeatures:\n",
    "        raise ValueError(f'The number of axes in the figure: {len(hA)} does not match the number of features: {numFeatures} in the data')\n",
    "    \n",
    "    for ii in range(numFeatures):\n",
    "        hA[ii].hist(mX[:, ii])\n",
    "    \n",
    "    return hF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering by K-Means\n",
    "\n",
    "In this notebook we'll do the following things:\n",
    "\n",
    "1. Implement K-Means manually.\n",
    "2. Use the K-Means to extract Super Pixels (A model for image segmentation).\n",
    "\n",
    "The Super Pixel is a simple clustering method which says s Super Pixel is a cluster f pixels which are localized and have similar colors.  \n",
    "Hence it fits to be applied using a clustering method with the features being the values of the pixels and its coordinates.\n",
    "\n",
    "The steps are as following:\n",
    "\n",
    "1. Load the `Fruits.jpeg` image and covert it to NumPy array `mI` using the [SciKit Image](https://github.com/scikit-image/scikit-image) library.  \n",
    "   See [`imread()`](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread).\n",
    "2. The image is given by $ I \\in \\mathbb{R}^{m \\times n \\times c}$ where $ c =  $ is the number of channels (`RGB`).   \n",
    "   We need to convert it into $ X \\in \\mathbb{R}^{mn \\times 3}$.  \n",
    "   Namely, a 2D array where each row is the RGB values triplets.\n",
    "3. Feature Engineering:  \n",
    "   - Convert data into a color space with approximately euclidean metric -> [LAB Color Space](https://en.wikipedia.org/wiki/CIELAB_color_space).\n",
    "   - Add the Row / Column indices of each pixel as one the features.\n",
    "   - Scale features to have the same range.\n",
    "4. Apply K-Means clustering on the features.\n",
    "5. Use the label of each pixel (The cluster it belongs to) to segment the image (Create Super Pixels).\n",
    "6. Plot the segmentation (Super Pixels) map.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may try different color spaces.\n",
    "* <font color='brown'>(**#**)</font> You may try different scaling of the features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/1HAq02c.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "imgUrl = r'https://github.com/FixelAlgorithmsTeam/FixelCourses/raw/master/MachineLearningMethod/16_ParametricClustering/Fruits.jpeg'\n",
    "\n",
    "# Model\n",
    "numClusters = 50\n",
    "numIter     = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "Load the fruits image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "mI = ski.io.imread(imgUrl)\n",
    "\n",
    "\n",
    "print(f'The image shape: {mI.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (8, 8))\n",
    "\n",
    "# Display the image\n",
    "hA.imshow(mI)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing\n",
    "\n",
    "We need to convert the image from `(numRows, numCols, numChannels)` to `(numRows * numCols, numChannels)`.  \n",
    "In our case, `numChannels = 3` as we work with `RGB` image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Image into Features Matrix\n",
    "\n",
    "numRows, numCols, numChannel = mI.shape\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "mX = np.reshape(mI, (numRows * numCols, numChannel))\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "In this section we'll apply the feature engineering:\n",
    "\n",
    "1. Convert data into a meaningful color space (LAB).\n",
    "2. Add the location (Row / Column indices) information as a feature to segment the image.\n",
    "3. Scale features to have similar dynamic range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Features into LAB Color Space\n",
    "mX = ConvertRgbToLab(mX) #<! Have a look on the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Indices as Features\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Create a vector of the row index of each pixel.\n",
    "# 2. Create a vector of the column index of each pixel.\n",
    "# 3. Stack them as additional columns to `mX`.\n",
    "# !! Python is column major.\n",
    "# !! The number of elements in the vectors should match the number of pixels.\n",
    "# !! You may find `repeat()` and `tile()` functions (NumPy) useful.\n",
    "vR = np.repeat(np.arange(numRows), repeats = numCols) #<! Row indices\n",
    "vC = np.tile(np.arange(numCols), reps = numRows) #<! Column indices\n",
    "mX = np.column_stack((mX, vR, vC))\n",
    "#===============================================================#\n",
    "\n",
    "numFeat = mX.shape[1]\n",
    "\n",
    "print(f'The features data shape: {mX.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Features Histogram \n",
    "hF, hA = plt.subplots(nrows = 1, ncols = numFeat, figsize = (15, 8))\n",
    "hF = PlotFeaturesHist(mX, hF = hF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Features\n",
    "# Scale each feature into the [0, 1] range.\n",
    "# Having similar scaling means have similar contribution when calculating the distance.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Construct the `MinMaxScaler` object.\n",
    "# 2. Use it to transform the data.\n",
    "oMinMaxScaler = MinMaxScaler()\n",
    "mX = oMinMaxScaler.fit_transform(mX)\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What would happen if we didn't scale the row and columns indices features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Features Histogram \n",
    "hF, hA = plt.subplots(nrows = 1, ncols = numFeat, figsize = (15, 8))\n",
    "hF = PlotFeaturesHist(mX, hF = hF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Data by K-Means\n",
    "\n",
    "1. Step I:  \n",
    "Assume fixed centroids $\\left\\{ \\boldsymbol{\\mu}_{k}\\right\\} $, find the optimal clusters $\\left\\{ \\mathcal{D}_{k}\\right\\} $:  \n",
    "$$\\arg\\min_{\\left\\{ \\mathcal{D}_{k}\\right\\} }\\sum_{k = 1}^{K}\\sum_{\\boldsymbol{x}_{i}\\in\\mathcal{D}_{k}}\\left\\Vert \\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{k}\\right\\Vert _{2}^{2}$$\n",
    "$$\\implies \\boldsymbol{x}_{i}\\in\\mathcal{D}_{s\\left(\\boldsymbol{x}_{i}\\right)} \\; \\text{where} \\; s\\left(\\boldsymbol{x}_{i}\\right)=\\arg\\min_{k}\\left\\Vert \\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{k}\\right\\Vert _{2}^{2}$$\n",
    "\n",
    "2. Step II:  \n",
    "Assume fixed clusters $\\left\\{ \\mathcal{D}_{k}\\right\\} $, find the optimal centroids $\\left\\{ \\boldsymbol{\\mu}_{k}\\right\\} $:\n",
    "$$\\arg\\min_{\\left\\{ \\boldsymbol{\\mu}_{k}\\right\\} }\\sum_{k=1}^{K}\\sum_{\\boldsymbol{x}_{i}\\in\\mathcal{D}_{k}}\\left\\Vert \\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{k}\\right\\Vert _{2}^{2}$$\n",
    "$$\\implies\\boldsymbol{\\mu}_{k}=\\frac{1}{\\left|\\mathcal{D}_{k}\\right|}\\sum_{\\boldsymbol{x}_{i}\\in\\mathcal{D}_{k}}\\boldsymbol{x}_{i}$$\n",
    "\n",
    "3. Step III:  \n",
    "Check for convergence (Change in assignments / location of the center). If not, go to _Step I_.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The K-Means is implemented in [`KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "* <font color='brown'>(**#**)</font> Some implementations of the algorithm supports different metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> With regard to the `RGB` features, is the metric used is the `Squared Euclidean`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The K-Means Algorithm\n",
    "\n",
    "Implement the K-Means algorithm as a SciKit Learn compatible class.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The implementation will allow different metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the K-Means as an Estimator\n",
    "\n",
    "class KMeansCluster(ClusterMixin, BaseEstimator):\n",
    "    def __init__(self, numClusters: int, numIter: int = 1000, metricType: str = 'sqeuclidean'):\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Add `numClusters` as an attribute of the object.\n",
    "        # 2. Add `numIter` as an attribute of the object.\n",
    "        # 3. Add `metricType` as an attribute of the object.\n",
    "        # !! The `metricType` must match the values of SciPy's `cdist()`: 'euclidean', 'cityblock', 'seuclidean', 'sqeuclidean', 'cosine', 'correlation'.\n",
    "        self.numClusters = numClusters\n",
    "        self.numIter     = numIter\n",
    "        self.metricType  = metricType\n",
    "        #===============================================================#\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def fit(self, mX: np.ndarray, vY: Optional[np.ndarray] = None) -> Self:\n",
    "\n",
    "        numSamples  = mX.shape[0]\n",
    "        featuresDim = mX.shape[1]\n",
    "\n",
    "        if (numSamples < self.numClusters):\n",
    "            raise ValueError(f'The number of samples: {numSamples} should not be smaller than the number of clusters: {self.numClusters}.')\n",
    "\n",
    "        mC = mX[np.random.choice(numSamples, self.numClusters, replace = False)] #<! Centroids (Random initialization)\n",
    "        vL = np.zeros(numSamples, dtype = np.int64) #<! Labels\n",
    "        vF = np.zeros(numSamples, dtype = np.bool_) #<! Flags for each label\n",
    "        \n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Create a loop of the number of samples.\n",
    "        # 2. Create the distance matrix between each sample to the centroids (Use the appropriate metrics).\n",
    "        # 3. Extract the labels.\n",
    "        # 4. Iterate on each label group to update the centroids.\n",
    "        # !! You may find `cdist()` from SciPy useful.\n",
    "        # !! Use `mean()` to calculate the centroids.\n",
    "        for ii in range(self.numIter):\n",
    "            mD = sp.spatial.distance.cdist(mX, mC, self.metricType) #<! Distance Matrix (numSamples, numClusters)\n",
    "            vL = np.argmin(mD, axis = 1, out = vL)\n",
    "            for kk in range(numClusters):\n",
    "                # Update `mC`\n",
    "                vF = np.equal(vL, kk, out = vF)\n",
    "                if np.any(vF):\n",
    "                    mC[kk, :] = np.mean(mX[vL == kk, :], axis = 0)\n",
    "        #===============================================================#\n",
    "\n",
    "        # SciKit Learn's `KMeans` compatibility\n",
    "        self.cluster_centers_   = mC\n",
    "        self.labels_            = vL\n",
    "        self.inertia_           = np.sum(np.amin(mD, axis = 1))\n",
    "        self.n_iter_            = self.numIter\n",
    "        self.n_features_in      = featuresDim\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, mX):\n",
    "\n",
    "        return sp.spatial.distance.cdist(mX, self.cluster_centers_, self.metricType)\n",
    "    \n",
    "    def predict(self, mX):\n",
    "\n",
    "        vL = np.argmin(self.transform(mX), axis = 1)\n",
    "\n",
    "        return vL\n",
    "    \n",
    "    def score(self, mX: np.ndarray, vY: Optional[np.ndarray] = None):\n",
    "        # Return the opposite of inertia as the score\n",
    "\n",
    "        mD = self.transform(mX)\n",
    "        inertiaVal = np.sum(np.amin(mD, axis = 1))\n",
    "\n",
    "        return -inertiaVal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why do the `fit()` and `predict()` method have the `vY` input?\n",
    "* <font color='red'>(**?**)</font> If one selects `'cosine'` as the distance metric, does the centroid match the metric?\n",
    "* <font color='green'>(**@**)</font> Add an option for `K-Means++` initialization.\n",
    "* <font color='red'>(**?**)</font> How can one use K-Means in an online fashion? Think of a static and dynamic case.\n",
    "* <font color='red'>(**?**)</font> Is the above implementation static or dynamic?\n",
    "* <font color='green'>(**@**)</font> Add a stopping criteria: The maximum movement of a centroid is below a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Pixel Clustering by K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Model & Fit to Data\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Construct the `KMeansCluster` object.\n",
    "# 2. Fit it to data.\n",
    "oKMeans = KMeansCluster(numClusters = numClusters, numIter = numIter)\n",
    "oKMeans = oKMeans.fit(mX)\n",
    "#===============================================================#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What's the difference between `fit()` and `predict()` in the context of K-Means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Labels and Form a Segmentation Mask\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Extract the labels of the pixels (Cluster index).\n",
    "# 2. Reshape them into a mask which matches the image.\n",
    "mSuperPixel = np.reshape(oKMeans.labels_, (numRows, numCols))\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (12, 8))\n",
    "PlotSuperPixels(mI, mSuperPixel, hA = hA)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> How do we set the hyper parameter `K` for `K-Means`?\n",
    "* <font color='red'>(**?**)</font> Why are the separating lines not straight?\n",
    "* <font color='green'>(**@**)</font> Run the notebook again yet using SciKit Learn `KMeans` class. Compare speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Hyper Parameter `K`\n",
    "\n",
    "One common method to find the optimal `K` is the [Knee / Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)).    \n",
    "In this method a score (Inertia) is plotted vs. the `K` parameter.  \n",
    "One way to define the _elbow point_ is by the point maximizing the [curvature](https://en.wikipedia.org/wiki/Curvature).  \n",
    "This point can be easily calculated by the [`kneed`](https://github.com/arvkevi/kneed) package.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> An alternative to the _elbow method_ is using [Silhouette](https://en.wikipedia.org/wiki/Silhouette_(clustering)). See [Stop Using the Elbow Method](https://scribe.rip/96bcfbbbe9fd), [Selecting the Number of Clusters with Silhouette Analysis on KMeans Clustering](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html).\n",
    "* <font color='brown'>(**#**)</font> [Method to Analyze K in K-Means](https://datascience.stackexchange.com/questions/6508)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score per K\n",
    "# Takes 4-6 minutes!\n",
    "lK = [10, 25, 50, 100, 150, 200, 500]\n",
    "numK = len(lK)\n",
    "vS = np.full(shape = numK, fill_value = np.nan)\n",
    "\n",
    "for ii, kVal in enumerate(lK):\n",
    "    oKMeans = KMeansCluster(numClusters = kVal, numIter = numIter)\n",
    "    oKMeans = oKMeans.fit(mX)\n",
    "    vS[ii]  = oKMeans.score(mX)\n",
    "    print(f'Finished processing the {ii + 1} / {numK} iteration with K = {kVal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Score\n",
    "hF, hA = plt.subplots(figsize = (12, 8))\n",
    "hA.plot(lK, vS, label = 'Score')\n",
    "hA.set_xlabel('Number of Clusters (K)')\n",
    "hA.set_ylabel('Score (Inertia)')\n",
    "hA.set_title('Score vs. Number of Clusters')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the Knee Point by Maximum Curvature\n",
    "\n",
    "oKneeLoc    = KneeLocator(lK, vS, curve = 'concave', direction = 'increasing')\n",
    "kneeK       = round(oKneeLoc.knee)\n",
    "kneeIdx     = lK.index(kneeK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Knee\n",
    "hF, hA = plt.subplots(figsize = (12, 8))\n",
    "hA.plot(lK, vS, lw = 2, label = 'Score')\n",
    "hA.scatter(lK[kneeIdx], vS[kneeIdx], s = 100, c = 'r', edgecolors = 'k', label = 'Knee')\n",
    "hA.set_xlabel('Number of Clusters (K)')\n",
    "hA.set_ylabel('Score (Inertia)')\n",
    "hA.set_title('Score vs. Number of Clusters')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
