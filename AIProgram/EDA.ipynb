{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 09/08/2025 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0002PointLine.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:52:07.921383Z",
     "start_time": "2022-02-02T17:52:07.649130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Scientific Python\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Miscellaneous\n",
    "import difflib #<! Fuzzy text search\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import re #<! Regular Expression\n",
    "\n",
    "import onedrivedownloader\n",
    "\n",
    "# Typing \n",
    "from typing import Callable\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ?????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "sns.set_theme() #>! Apply SeaBorn theme\n",
    "# sns.set_palette(\"tab10\")\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "The EDA part is a prior stage to the Machine Learning pipeline.  \n",
    "It is used as an introduction to the data in order to generate an intelligent path to process it in light of the objective.\n",
    "\n",
    "A common objective for the EDA phase:\n",
    " - Detection of outliers and invalid data.\n",
    " - Validation of assumption.\n",
    " - Preliminary selection of appropriate models.\n",
    " - Determining relationships among the features.\n",
    " - Determining relationships between features and the objective variable (Label).\n",
    "\n",
    "This notebook presents some visualization tools and concepts by an analysis of known data sets.  \n",
    "The visualization toolboxes, beyond [MatPlotlib](https://matplotlib.org/) used are:\n",
    "\n",
    " - [SeaBorn](https://github.com/mwaskom/seaborn) - Statistical data visualization in Python.\n",
    " - [PlotLy for Python](https://github.com/plotly/plotly.py) - The interactive graphing library for Python.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> While the EDA is prior to the ML pipeline, the work is iteratively and bi directional.\n",
    "* <font color='brown'>(**#**)</font> EDA is crucial in _Classic Machine Learning_ as it is the step to experiment with **Feature Engineering**.\n",
    "* <font color='brown'>(**#**)</font> EDA does not require labels, though it should utilize them if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Data\n",
    "\n",
    "```mermaid\n",
    "mindmap\n",
    "  root )Data Types in ML(\n",
    "    Structured Data\n",
    "        ((Tabular üìä))\n",
    "          (Customer Data)\n",
    "          (Employee Data)\n",
    "        ((Structured File üìÑ))\n",
    "          (Jupyter Notebook)\n",
    "          (HTML File)\n",
    "    Unstructured Data\n",
    "        ((Text üìù))\n",
    "          (Product Reviews)\n",
    "          (Twitter Posts)\n",
    "        ((Image üñºÔ∏è))\n",
    "          (Chest X-Ray)\n",
    "          (Satelite Multi Spectral Image)\n",
    "          (Smartphone Image)\n",
    "        ((Audio üîä))\n",
    "          (Speech Command)\n",
    "          (Podcast Recording)\n",
    "        ((Time Series ‚è±Ô∏è))\n",
    "          (Hourly Energy Usage)\n",
    "          (Stock Value)\n",
    "        ((Geospatial üó∫Ô∏è))\n",
    "          (GPS Tracks)\n",
    "          (Electric Poles Coordinates)\n",
    "        ((Graph üï∏Ô∏è))\n",
    "          (Social Network)\n",
    "          (Family Tree)\n",
    "        ((Event / Log üßæ))\n",
    "          (Clickstream)\n",
    "          (Machine Log)\n",
    "```\n",
    "\n",
    "![](https://i.imgur.com/mknxPtI.png)\n",
    "<!-- ![](https://i.postimg.cc/q7f6vMQd/mknxPtI.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Data Element\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "A[Data Element Type in Machine Learning]\n",
    "\n",
    "A --> B[Numeric]\n",
    "B --> C[\"`Continuous<br/>(e.g., Daily temperature ¬∞C)`\"]\n",
    "B --> D[\"`Discrete<br/>(e.g., Number of patients)`\"]\n",
    "\n",
    "A --> F[Categorical]\n",
    "F --> G[\"`Nominal<br/>(e.g., Color = {red, green, blue})`\"]\n",
    "F --> E[\"`Binary<br/>(e.g., Fraud: 0/1)`\"]\n",
    "F --> H[\"`Ordinal<br/>(e.g., Satisfaction = {poor, fair, good, excellent})`\"]\n",
    "\n",
    "\n",
    "%% Styling\n",
    "classDef root fill:#7f7f7f,stroke:#404040,stroke-width:4px,color:#ffffff;\n",
    "classDef num fill:#e3f2fd,stroke:#1976d2,stroke-width:4px,color:#0d47a1;\n",
    "classDef cat fill:#fff3e0,stroke:#ef6c00,stroke-width:4px,color:#e65100;\n",
    "classDef catnom fill:#fff3e0,stroke:#ef6c00,stroke-width:4px,stroke-dasharray: 5 5,color:#e65100;\n",
    "\n",
    "class A root;\n",
    "class B,C,D num;\n",
    "class F,H cat;\n",
    "class E,G catnom;\n",
    "```\n",
    "\n",
    "![](https://i.imgur.com/oO1Q22n.png)\n",
    "<!-- ![](https://i.postimg.cc/432syK4L/oO1Q22n.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines per Data Type  \n",
    "\n",
    "There are guidelines related to the visualization of different data types:\n",
    "\n",
    " - Categorical: \n",
    "   - Single Variable: Bar Plot, Pie Plot, Word Cloud (Text).\n",
    "   - Two Independent: Venn Diagram, 2D Bar Plot.\n",
    "   - Adjacency: Graph, Sankey.\n",
    "   - Sub Group (Data & Labels) / Nested: Scatter, Grouped / Stacked Bar Plot, Dendrogram.\n",
    " - Numeric\n",
    "   - Single Variable: Histogram / Density.\n",
    "   - Two Independent (Not Ordered): Box Plot, Violin Plot, Marginals Plot, Scatter Plot, 2D Histogram.\n",
    "   - Two Independent (Ordered): Line Plot, Area Plot.\n",
    "   - Several (Not Ordered): Box Plot, Violin Plot, Bubble Plot, Ridge Line, Dimensionality Reduction (PCA), Measure Heatmap (Correlation).\n",
    "   - Several (Ordered): Stacked Line Plot, Stacked Area Plot.\n",
    "\n",
    "Some of the concepts holds for the mixed case.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> A detailed guide matching a visualization to a data type is given in [From Data to Viz](https://www.data-to-viz.com).\n",
    "* <font color='brown'>(**#**)</font> [Wikipedia - Box Plot](https://en.wikipedia.org/wiki/Box_plot).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - The Diamonds Data Set\n",
    "\n",
    "The dataset variables are:\n",
    "\n",
    " - _Carat_  \n",
    "   Carat is a metric that is used to measure the weight of a diamond. One carat is equivalent to 200mg. Diamond prices increase with diamond carat weight, which means bigger the diamond higher the price. If two diamonds weights are equal, then other features are used to determine the price. \n",
    " - _Cut_  \n",
    "   The goal is to cut a diamond within an appropriate size shape, and angle such that the light entering the diamond should reflect and leave from the top surface.  \n",
    "   The values are Ideal, Premium, Good, Very Good, Fair.  \n",
    "   This feature is an important thing to notice in a diamond as it measures three crucial things, such as:\n",
    "    - Brilliance: It means the brightness of a diamond by the reflection of white lights inside and outside of a diamond.\n",
    "    - Fire: It means Scattering of white light into all the colors of the rainbow.\n",
    "    - Scintillation: the amount of sparkle produced and the pattern of light and dark areas caused by reflection within a diamond.    \n",
    " - _Color_  \n",
    "   Color measurement in diamond measures lacks color. If the diamond color is like a drop of water that is colorless, it will have a high value. As then only it can scatter the light without observing. However, there are some diamonds that are in different colors will have higher prices.  \n",
    "   The color scale is categorized from D to Z letters and ordered in ascending by the amount of presence of color in a diamond. From the K onwards to till Z, we can see a yellowish color present.  \n",
    "   D ,E,F - Colorless G,H,I,J - Near colorlessness K, L, M - Faint color N-R: Very Light Color S-Z: light color.\n",
    " - _Clarity_   \n",
    "   Diamonds are generated from sheer pressure and heat below the ground. Therefore, there will be some inclusion inside a diamond i.e., a mark or line pattern inside a diamond. Also, there will be a mark or line in the outer layer of a diamond, which is called blemishes. Based on the amount of inclusion and blemishes, the clarity of a diamond is categorized such as FL, IF, VSS1, VSS2, VS1, VS2, SI1, SI2, I1, I2, I3. The categories mentioned above are ordered in descending order by the amount of presence of inclusion and blemishes. \n",
    " - _Depth_ [%]  \n",
    "   Depth is the distance from a top surface i.e., table to a culet. The depth percentage is calculated by dividing the diamond depth by the overall width of a diamond. Lower the depth percentage the bigger the diamond looks from the below i.e., pavilion.\n",
    " - _Table_ [%]  \n",
    "   The table is the topmost surface of a diamond and also the most significant facet of the round diamond. An appropriate width of a table will allow the light to enter and reflect on the appropriate direction .if not most of the light will scatter off in different directions. The table percentage is calculated by dividing the table width by overall diamond width.\n",
    " - _x_ / _y_ / _z_ [Mili Meter]  \n",
    "   The dimension of a diamond is measured in millimeters. Moreover, the shape of a diamond is determined by the Length to width ratio. For instance, to determine the roundness of a diamond, we need to check the L/W ratio, If the ratio is between 1 and 1.05, it is a round diamond, and an oval shape diamond L/W ratio can be around 1.50 or less.  \n",
    "   `x` -> Length, `y` -> width, `z` -> depth.\n",
    "\n",
    "For more information look at [Diamonds Data Set](https://raw.githubusercontent.com/rithwiksarma/EDA-and-Classification---Diamonds-Dataset/main/updated-Diamonds-Project.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "# Data from CSV\n",
    "# Pandas can read CSV data from **URL**'s and local files\n",
    "\n",
    "diamondsCsvUrl  = r'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv'\n",
    "dfDiamonds      = pd.read_csv(diamondsCsvUrl)\n",
    "dfDiamonds #<! Shows the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Columns\n",
    "\n",
    "dColName = {'carat': 'Carat', 'cut': 'Cut', 'color': 'Color', 'clarity': 'Clarity', 'depth': 'Depth Ratio', 'table': 'Table Ratio', 'price': 'Price [$]', 'x': 'Length', 'y': 'Width', 'z': 'Depth'}\n",
    "\n",
    "dfDiamonds.rename(columns = dColName, inplace = True)\n",
    "\n",
    "print(f'The columns are given by: {dfDiamonds.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Info of the Data Frame\n",
    "\n",
    "print(f'The DF Shape is: {dfDiamonds.shape}')\n",
    "print(f'The DF variables info: {dfDiamonds.info()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Type of Data\n",
    "dVarType = {colName: 'Categorical' if dfDiamonds.dtypes[colName] == np.dtypes.ObjectDType else 'Continuous' for colName in dfDiamonds.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Values\n",
    "# Each column is a series with the given methods in: https://pandas.pydata.org/docs/reference/series.html\n",
    "\n",
    "for colName in dfDiamonds:\n",
    "    varType = dVarType[colName]\n",
    "    if varType == 'Categorical':\n",
    "        print(f'The {colName} variable is {varType} with values: {dfDiamonds[colName].unique()}')\n",
    "    else:\n",
    "        print(f'The {colName} variable is {varType} with values: [{dfDiamonds[colName].min()}, {dfDiamonds[colName].max()}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Describe\n",
    "\n",
    "dfDiamonds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Distribution\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (10, 6))\n",
    "sns.histplot(dfDiamonds, x = 'Price [$]', kde = True, ax = hA)\n",
    "hA.set_title('Price Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The price distribution is skewed and not \"Normal Like\".  \n",
    "In many cases the _Log Transform_ might generate a more \"Normal Data\" which is better suited for Linear Estimators.  \n",
    "\n",
    "* <font color='brown'>(**#**)</font> The _Log Transform_ assists with Skewing and applicable to Positive data.  \n",
    "  The underlying distribution assumption of the data is [Log Normal Distribution](https://en.wikipedia.org/wiki/Log-normal_distribution).\n",
    "* <font color='brown'>(**#**)</font> Other alternatives are the _Square Root_ and _Box-Cox_ transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Distribution\n",
    "# Use the Log Transform to make the data more \"Normal Like\".\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (10, 6))\n",
    "sns.histplot(dfDiamonds, x = np.log(dfDiamonds['Price [$]']), kde = True, ax = hA)\n",
    "# sns.histplot(dfDiamonds, x = 'Price [$]', kde = True, log_scale = True, ax = hA)\n",
    "# sns.histplot(dfDiamonds, x = sp.stats.boxcox(dfDiamonds['Price [$]'])[0], kde = True, ax = hA)\n",
    "hA.set_title('Log Price Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case above, the data is [BiModal distribution](https://en.wikipedia.org/wiki/Multimodal_distribution).  \n",
    "It might be useful to cluster data by the modality. For instance, see [Otsu's Method](https://en.wikipedia.org/wiki/Otsu%27s_method). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Distribution per Cut\n",
    "\n",
    "# Create SeaBorn Multi Plot\n",
    "# Display the Histogram per Cut of the Diamond\n",
    "\n",
    "oSnsGrid = sns.FacetGrid(dfDiamonds, col = 'Cut', hue = 'Cut', legend_out = False)\n",
    "oSnsGrid.map(sns.histplot, 'Price [$]', stat = 'probability', kde = True, alpha = 0.55)\n",
    "oSnsGrid.add_legend();\n",
    "\n",
    "# oSnsGrid = sns.displot(data = dfDiamonds, x = 'Price [$]', hue = 'Cut', col = 'Cut', **{'stat': 'probability', 'kde': True, 'log_scale': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important, in the above, when comparing histograms to normalize by the quantity. See the `stat` parameter in `sns.histplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Normalized by Carat per Cut\n",
    "\n",
    "dfDiamonds['Price per Carat [$]'] = dfDiamonds['Price [$]'] / dfDiamonds['Carat']\n",
    "\n",
    "oSnsGrid = sns.displot(data = dfDiamonds, x = 'Price per Carat [$]', hue = 'Cut', col = 'Cut', **{'stat': 'probability', 'kde': True, 'log_scale': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normalization by the Carat (Weight) with the Log Transform assisted in bringing the distribution closer to Normal Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Distribution per Clarity\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (10, 6))\n",
    "sns.violinplot(data = dfDiamonds, x = 'Clarity', y = 'Price per Carat [$]', inner = 'quartile', density_norm = 'area', ax = hA)\n",
    "hA.set_title('Price per Carat [$] Distribution per Clarity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Distribution per Clarity\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (10, 6))\n",
    "sns.boxplot(data = dfDiamonds, x = 'Color', y = 'Price per Carat [$]', log_scale = False, ax = hA)\n",
    "hA.set_title('Price per Carat [$] Distribution per Clarity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Price per Dimension\n",
    "dfPriceDimension = dfDiamonds.melt(id_vars = 'Price [$]', value_vars = ['Length', 'Width', 'Depth'], var_name = 'Dimension Type', value_name = 'Dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection of Price to Length, Width, and Depth\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (12, 6))\n",
    "sns.scatterplot(data = dfPriceDimension, x = 'Dimension', y = 'Price [$]', hue = 'Dimension Type', ax = hA, **{'alpha': 0.175})\n",
    "hA.set_xlim((2, 10))\n",
    "hA.set_title('Price per Carat [$] Distribution vs. Dimension');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection of Price to Length, Width, and Depth\n",
    "\n",
    "oSnsGrid = sns.FacetGrid(dfPriceDimension, col = 'Dimension Type', hue = 'Dimension Type', legend_out = False)\n",
    "oSnsGrid.map(sns.regplot, 'Dimension', 'Price [$]', fit_reg = True, lowess = True, line_kws = {'color': 'k', 'lw': 5}, scatter_kws = {'alpha': 0.175})\n",
    "oSnsGrid.set(xlim = (2, 10), ylim  = (0, 10_000))\n",
    "oSnsGrid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The connection looks like exponential which makes sense as the price is closely related to the volume which is the multiplication of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Volume\n",
    "dfDiamonds['Volume'] = dfDiamonds['Length'] * dfDiamonds['Width'] * dfDiamonds['Depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of the Data (Remove Outliers)\n",
    "\n",
    "# By Price\n",
    "quantileLow, quantilehigh = dfDiamonds['Price [$]'].quantile([0.03, 0.97])\n",
    "dfFiltered = dfDiamonds[dfDiamonds['Price [$]'].between(quantileLow, quantilehigh, inclusive = 'both')]\n",
    "\n",
    "# By Volume\n",
    "quantileLow, quantilehigh = dfDiamonds['Volume'].quantile([0.03, 0.97])\n",
    "dfFiltered = dfFiltered[dfFiltered['Volume'].between(quantileLow, quantilehigh, inclusive = 'both')]\n",
    "\n",
    "dfFiltered = dfFiltered[['Price [$]', 'Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "dfCorrelation = dfFiltered.corr()\n",
    "dfCorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Sub Sample (Run Time)\n",
    "\n",
    "dfFiltered = dfFiltered.sample(n = 10_000, random_state = seedNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price per Volume\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (12, 6))\n",
    "sns.regplot(data = dfFiltered, x = 'Volume', y = 'Price [$]', lowess = True, line_kws = {'color': 'k', 'lw': 5}, scatter_kws = {'alpha': 0.175}, ax = hA)\n",
    "hA.set_title('Price [$] vs. Volume');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of the Data (Remove Outliers)\n",
    "\n",
    "# By Price\n",
    "quantileLow, quantilehigh = dfDiamonds['Price [$]'].quantile([0.03, 0.97])\n",
    "dfFiltered = dfDiamonds[dfDiamonds['Price [$]'].between(quantileLow, quantilehigh, inclusive = 'both')]\n",
    "\n",
    "# By Volume\n",
    "quantileLow, quantilehigh = dfDiamonds['Volume'].quantile([0.03, 0.97])\n",
    "dfFiltered = dfFiltered[dfFiltered['Volume'].between(quantileLow, quantilehigh, inclusive = 'both')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information per Property\n",
    "# Using Group By\n",
    "\n",
    "dfFiltered.groupby('Cut').agg({'Price [$]': ['mean', 'std', 'median', 'min', 'max'], 'Carat': ['mean', 'std', 'median', 'min', 'max'], 'Volume': ['mean', 'std', 'median', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFiltered.groupby('Clarity').agg({'Price [$]': ['mean', 'std', 'median', 'min', 'max'], 'Carat': ['mean', 'std', 'median', 'min', 'max'], 'Volume': ['mean', 'std', 'median', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - The JSE OK Cupid Data Set\n",
    "\n",
    "Journal of Statistical Education Paper on Using OkCupid Data for Data Science Courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Data\n",
    "\n",
    "dataFileUrl  = 'https://technionmail-my.sharepoint.com/:x:/g/personal/royia_technion_ac_il/ESJTvS3m9-ZFnnxqFE2ah4QBWbE2Sn9cQHDnMhg3ntnvhg?e=XxhVsu'\n",
    "dataFileName = 'JSEOKCupidProfileData.csv'\n",
    "\n",
    "if not os.path.exists(dataFileName):\n",
    "    onedrivedownloader.download(dataFileUrl, dataFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "dfOkCupid = pd.read_csv('JSEOKCupidProfileData.csv') \n",
    "dfOkCupid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dColName = {\n",
    "    'age': 'Age', \n",
    "    'body_type': 'BodyType', \n",
    "    'diet': 'Diet', \n",
    "    'drinks': 'Drinks', \n",
    "    'drugs': 'Drugs', \n",
    "    'education': 'Education', \n",
    "    'ethnicity': 'Ethnicity', \n",
    "    'height': 'Height', \n",
    "    'income': 'Income', \n",
    "    'job': 'Job',\n",
    "    'offspring': 'Offspring',\n",
    "    'orientation': 'Orientation',\n",
    "    'pets': 'Pets',\n",
    "    'religion': 'Religion',\n",
    "    'sex': 'Sex', \n",
    "    'sign': 'Sign',\n",
    "    'smokes': 'Smokes',\n",
    "    'speaks': 'Speaks',\n",
    "    'status': 'Status',\n",
    "}\n",
    "\n",
    "dfOkCupid.rename(columns = dColName, inplace = True)\n",
    "\n",
    "print(f'The columns are given by: {dfOkCupid.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Units\n",
    "\n",
    "# Convert the Height form Inches to Centimeters\n",
    "dfOkCupid['Height'] = dfOkCupid['Height'].apply(lambda x: round(x * 2.54, ndigits = 2) if isinstance(x, (int, float)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Invalid Height Values\n",
    "\n",
    "dfOkCupid = dfOkCupid.dropna(axis = 0, subset = ['Height'])\n",
    "dfOkCupid = dfOkCupid[dfOkCupid['Height'].between(120, 220, inclusive = 'both')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute helpers\n",
    "lSign = ['Aries', 'Taurus', 'Gemini', 'Cancer', 'Leo', 'Virgo', 'Libra', 'Scorpio', 'Sagittarius', 'Capricorn', 'Aquarius', 'Pisces']\n",
    "\n",
    "lSignLower = [s.lower() for s in lSign]\n",
    "dSign      = {s.lower(): s for s in lSign} #<! Mapping of lower case sign to canonical name\n",
    "# Whole Word regex: prevents \"libraries\" -> \"Aries\"\n",
    "oWordRe = re.compile(r'\\b(' + '|'.join(lSignLower) + r')\\b', flags = re.IGNORECASE)\n",
    "\n",
    "def GuessSign( inStr: object, *, valThr: float = 0.80) -> object:\n",
    "    \"\"\"\n",
    "    Return the most probable zodiac sign from a free-text `text` string.\n",
    "    If no confident match is found, return NaN.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isna(inStr):\n",
    "        return np.nan\n",
    "\n",
    "    inStrLower = str(inStr).lower()\n",
    "\n",
    "    # 1) Exact whole-word match (fast, precise)\n",
    "    m = oWordRe.search(inStrLower)\n",
    "    if m:\n",
    "        return dSign[m.group(1).lower()]\n",
    "\n",
    "    # 2) Fuzzy fallback: compare each token to each sign; take best score\n",
    "    lToken = re.findall(r\"[a-z]+\", inStrLower)  # simple tokenization\n",
    "    if not lToken:\n",
    "        return np.nan\n",
    "\n",
    "    bestSign = None\n",
    "    bestScore = 0.0\n",
    "    for signCanon, signLower in zip(lSign, lSignLower):\n",
    "        # best token to sign similarity\n",
    "        for tok in lToken:\n",
    "            score = difflib.SequenceMatcher(None, tok, signLower).ratio()\n",
    "            if score > bestScore:\n",
    "                bestScore = score\n",
    "                bestSign = signCanon\n",
    "\n",
    "    return bestSign if bestScore >= valThr else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Sign Column\n",
    "\n",
    "dfOkCupid['Sign'] = dfOkCupid['Sign'].apply(GuessSign)\n",
    "dfOkCupid = dfOkCupid.dropna(axis = 0, subset = ['Sign'])\n",
    "dfOkCupid['Sign'].unique() #<! Show the unique values in the Sign column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body Type Mapping\n",
    "dBodyType = {\n",
    "    'a little extra': 'Curvy',\n",
    "    'average': 'Average',\n",
    "    'think': 'Thin',\n",
    "    'fit': 'Fit',\n",
    "    'athletic': 'Fit',\n",
    "    'curvy': 'Curvy',\n",
    "    'skinny': 'Thin',\n",
    "    'full figured': 'Curvy',\n",
    "    'jacked': 'Fit',\n",
    "    'overweight': 'Overweight',\n",
    "    'used up': 'Average',\n",
    "    'rather not say': None,\n",
    "}\n",
    "\n",
    "dfOkCupid['BodyType'] = dfOkCupid['BodyType'].map(dBodyType)\n",
    "dfOkCupid = dfOkCupid.dropna(axis = 0, subset = ['BodyType'])\n",
    "dfOkCupid['BodyType'].unique() #<! Show the unique values in the BodyType column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dSex = {\n",
    "    'm': 'Male',\n",
    "    'f': 'Female',\n",
    "}\n",
    "dfOkCupid['Sex'] = dfOkCupid['Sex'].map(dSex)\n",
    "dfOkCupid['Sex'].unique() #<! Show the unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dOrientation = {\n",
    "    'straight': 'Straight',\n",
    "    'gay': 'Gay',\n",
    "    'bisexual': 'Bisexual',\n",
    "}\n",
    "\n",
    "dfOkCupid['Orientation'] = dfOkCupid['Orientation'].map(dOrientation)\n",
    "dfOkCupid['Orientation'].unique() #<! Show the unique values in the Orientation column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Sex and Orientation\n",
    "dfCrossTab = pd.crosstab(dfOkCupid['Sex'], dfOkCupid['Orientation'])\n",
    "dfCrossTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Form Table\n",
    "dfCrossTab = dfCrossTab.unstack().reset_index().rename(columns = {0: 'Count'})\n",
    "dfCrossTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Sex and Orientation\n",
    "# Stacked Bar Plot (PlotLy)\n",
    "\n",
    "hF = px.bar(dfCrossTab, x = 'Sex', y = 'Count', color = 'Orientation')\n",
    "hF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "\n",
    "dsTotal = dfCrossTab.groupby('Sex')['Count'].transform('sum')\n",
    "dfCrossTab['Relative'] = (dfCrossTab['Count'] / dsTotal)\n",
    "dfCrossTab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> When working with `LLM` you may find `print(df.to_markdown())` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hF = px.bar(dfCrossTab, x = 'Sex', y = 'Relative', color = 'Orientation')\n",
    "hF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Jitter to Sex for Plotting\n",
    "dSex = {\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "}\n",
    "dfOkCupid['SexJitter'] = dfOkCupid['Sex'].map(dSex) + np.random.uniform(-0.2, 0.2, size = dfOkCupid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "oLogReg = LogisticRegression(solver = 'liblinear', random_state = seedNum)\n",
    "oLogReg.fit(dfOkCupid[['Height']].to_numpy(), dfOkCupid['Sex'].map(dSex))\n",
    "\n",
    "vHeight  = np.linspace(dfOkCupid['Height'].min(), dfOkCupid['Height'].max(), num = 1_000)\n",
    "vSexProb = oLogReg.predict_proba(vHeight.reshape(-1, 1))[:, 1] #<! Probability for 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression for Sex by Height\n",
    "hFig = px.scatter(dfOkCupid, x = 'Height', y = 'SexJitter', color = 'Sex', subtitle = 'Sex vs. Height', width = 850, height = 500)\n",
    "hFig.add_trace(go.Scatter(x = vHeight, y = vSexProb, mode = 'lines', name = 'Logistic Regression', line = dict(color = 'black', width = 2)))\n",
    "hFig.update_layout(\n",
    "    yaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = [0, 1],  #<! Ticks\n",
    "        ticktext = ['Male', 'Female'], #<! Tick labels\n",
    "        title = 'Sex',\n",
    "    )\n",
    ")\n",
    "hFig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of Distribution\n",
    "\n",
    "Many measures are related to the moments of the data.\n",
    "\n",
    "#### Skewness\n",
    "\n",
    "Calculated by the 3rd moment:\n",
    "\n",
    "$$ \\operatorname{skew} \\left( X \\right) = \\mathbb{E} \\left[ {\\left( \\frac{ X - \\mu }{\\sigma} \\right)}^{3} \\right] = \\frac{ \\mathbb{E} \\left[ {X}^{3} \\right] - 3 \\mu {\\sigma}^{2} - {\\mu}^{3} }{ {\\sigma}^{3} } $$\n",
    "\n",
    "Measures how asymmetric the distribution is.\n",
    "\n",
    "![](https://i.imgur.com/bKBT0sP.png)\n",
    "<!-- ![](https://i.postimg.cc/MK1mGYL6/Diagrams-Skewness.png) -->\n",
    "\n",
    "* <font color='brown'>(**#**)</font> For alternative measures of Skewness see [Wikipedia - Other Measures of Skewness](https://en.wikipedia.org/wiki/Skewness#Other_measures_of_skewness).\n",
    "\n",
    "#### Kurtosis\n",
    "\n",
    "Calculated by the 4th moment.\n",
    "\n",
    "$$ \\operatorname{kurt} \\left( X \\right) = \\mathbb{E} \\left[ {\\left( \\frac{ X - \\mu }{\\sigma} \\right)}^{4} \\right] = \\frac{ {\\mu}_{4} }{ {\\sigma}^{4} } $$\n",
    "\n",
    "Reflects either the presence of existing outliers (Sample kurtosis) or the tendency to produce outliers (Kurtosis of a probability distribution).  \n",
    "It is usually compared to a Normal Distribution which has a Kurtosis of 3. It is called _Excess Kurtosis_:\n",
    "\n",
    "$$ \\tilde{\\operatorname{kurt}} \\left( X \\right) = \\operatorname{kurt} \\left( X \\right) - 3 $$\n",
    "\n",
    "\n",
    "#### Transformations\n",
    "\n",
    "There are som transformations to make teh distribution closer to _Normal_:\n",
    "\n",
    " - [Power Transformation (Box Cox Transformation)](https://en.wikipedia.org/wiki/Power_transform).\n",
    " - Using $\\sqrt{\\cdot}$ and $\\log \\left( \\cdot \\right)$ (See [Variance Stabilizing Transformation](https://en.wikipedia.org/wiki/Variance-stabilizing_transformation)).\n",
    " - See [Advanced Normalizing Distribution Transformations](https://stats.stackexchange.com/questions/1601).\n",
    "\n",
    "\n",
    "</br>\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Kurtosis and Skewness can be used to check for the modality of the distribution. See [Measure Modality of a Distribution](https://stats.stackexchange.com/questions/395908)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Samples to Show the Different Distributions\n",
    "numSamples = 500\n",
    "\n",
    "dDist = {\n",
    "    'Normal': lambda: np.random.normal(0, 1, size = numSamples),\n",
    "    'Log Normal': lambda: np.random.lognormal(0, 1, size = numSamples),\n",
    "    'Beta (20, 2)': lambda: np.random.beta(20, 2, size = numSamples),\n",
    "    'Laplace': lambda: np.random.laplace(0, 1, size = numSamples),\n",
    "    'Student T (3)': lambda: np.random.standard_t(3, size = numSamples),\n",
    "    'Uniform': lambda: np.random.uniform(-2, 2, size = numSamples),\n",
    "    'Bimodal Symmetric': lambda: np.concatenate([np.random.normal(-2, 0.6, size = numSamples // 2), np.random.normal(2, 0.6, size = numSamples - numSamples // 2)]),\n",
    "    'Bimodal Skewed': lambda: np.concatenate([np.random.normal(0, 1, size = int(numSamples * 0.8)), np.random.normal(4, 0.7, size = numSamples - int(numSamples * 0.8))]),\n",
    "    'Trimodal': lambda: np.concatenate([np.random.normal(-3, 0.5, size = numSamples // 3), np.random.normal(0, 0.5, size = numSamples // 3), np.random.normal(3, 0.5, size = numSamples - 2 * (numSamples // 3))]),\n",
    "}\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 3, ncols = 3, figsize = (16, 11))\n",
    "vHa = vHa.flat\n",
    "\n",
    "for ii, (distName, distFunc) in enumerate(dDist.items()):\n",
    "    hA = vHa[ii]\n",
    "    vS = distFunc()\n",
    "    valMean = np.mean(vS)\n",
    "    valStd  = np.std(vS)\n",
    "    valMedian = np.median(vS)\n",
    "    valSkew = sp.stats.skew(vS)\n",
    "    valKurt = sp.stats.kurtosis(vS)\n",
    "    sns.histplot(vS, kde = True, stat = 'density', ax = hA)\n",
    "    hA.set_title(f'{distName} Distribution')\n",
    "\n",
    "    hA.axvline(valMean, color = 'red', linestyle = '--', label = f'Mean: {valMean:.2f}')\n",
    "    hA.axvline(valMedian, color = 'green', linestyle = '-.', label = f'Median: {valMedian:.2f}')\n",
    "    hA.axvline(valMean - valStd, color = 'orange', linestyle = ':', label = f'Std: {valStd:.2f}')\n",
    "    hA.axvline(valMean + valStd, color = 'orange', linestyle = ':')\n",
    "    # Test of the Skewness and Kurtosis\n",
    "    hA.text(0.30, 0.15, f'Skew: {valSkew:.2f}\\nKurtosis: {valKurt:.2f}', horizontalalignment = 'right', verticalalignment = 'top', transform = hA.transAxes, bbox = dict(facecolor = 'white', alpha = 0.5))\n",
    "    hA.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness Analysis\n",
    "vX = np.linspace(0, 1, 1_000)\n",
    "\n",
    "tuData = (\n",
    "    (2, 5),\n",
    "    (5, 5),\n",
    "    (5, 2),\n",
    ")\n",
    "\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = 3, figsize = (14, 5))\n",
    "vHa = vHa.flat\n",
    "\n",
    "for ii, (a, b) in enumerate(tuData):\n",
    "    oDistBeta = sp.stats.beta(a = a, b = b)\n",
    "    hA = vHa[ii]\n",
    "    hA.plot(vX, oDistBeta.pdf(vX), color = 'blue', lw = 2)\n",
    "    # Remove the top and right spines\n",
    "    hA.spines['top'].set_visible(False)\n",
    "    hA.spines['right'].set_visible(False)   \n",
    "    # Remove Ticks and Labels\n",
    "    hA.set_axis_off()\n",
    "\n",
    "# hF.savefig('TMP.svg', transparent = True, dpi = 100, bbox_inches = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis Analysis\n",
    "\n",
    "vX = np.linspace(-5, 5, 1_000)\n",
    "\n",
    "dDist = {\n",
    "    'Normal (0, 1)': sp.stats.norm(0, 1),\n",
    "    'T Student (3)': sp.stats.t(3),\n",
    "    'Laplace (0, 1)': sp.stats.laplace(0, 1),\n",
    "    'Beta (2, 2)': sp.stats.beta(2, 2, loc = -0.5),\n",
    "}\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (6, 4))\n",
    "\n",
    "for ii, (distName, oDist) in enumerate(dDist.items()):\n",
    "    valKurt = oDist.stats(moments = 'k')\n",
    "    hA.plot(vX, oDist.pdf(vX), lw = 2, label = distName + ', Kurtosis: ' + f'{valKurt:.2f}')\n",
    "\n",
    "\n",
    "hA.set_xticks([])\n",
    "hA.set_yticks([])\n",
    "\n",
    "\n",
    "hA.legend(loc = 'upper left', fontsize = 8)\n",
    "\n",
    "# hF.savefig('TMP.svg', transparent = True, dpi = 100, bbox_inches = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Samples to Show the Different Distributions\n",
    "numSamples = 5_000\n",
    "\n",
    "\n",
    "vS1  = np.random.beta(2, 3, size = numSamples)\n",
    "vS2  = np.random.lognormal(0.5, 0.5, size = numSamples)\n",
    "vS1T = np.sqrt(vS1)\n",
    "vS2T = np.log(vS2)\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (6, 4))\n",
    "sns.histplot(vS1, kde = True, stat = 'density', ax = hA)\n",
    "hA.set_xticks([])\n",
    "hA.set_yticks([])\n",
    "hA.set_ylabel(None)\n",
    "# hF.savefig('TMP.svg', transparent = True, dpi = 100, bbox_inches = None)\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (6, 4))\n",
    "sns.histplot(vS1T, kde = True, stat = 'density', ax = hA)\n",
    "hA.set_xticks([])\n",
    "hA.set_yticks([])\n",
    "hA.set_ylabel(None)\n",
    "# hF.savefig('TMP.svg', transparent = True, dpi = 100, bbox_inches = None)\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (6, 4))\n",
    "sns.histplot(vS2, kde = True, stat = 'density', ax = hA)\n",
    "hA.set_xticks([])\n",
    "hA.set_yticks([])\n",
    "hA.set_ylabel(None)\n",
    "# hF.savefig('TMP.svg', transparent = True, dpi = 100, bbox_inches = None)\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (6, 4))\n",
    "sns.histplot(vS2T, kde = True, stat = 'density', ax = hA)\n",
    "hA.set_xticks([])\n",
    "hA.set_yticks([])\n",
    "hA.set_ylabel(None)\n",
    "# hF.savefig('TMP.svg', transparent = True, dpi = 100, bbox_inches = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "4c555be6fa9458c8c75b4612c68315d9f1d74815b73d0e564fda29ad772cfcda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
