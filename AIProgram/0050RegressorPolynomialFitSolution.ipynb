{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://i.imgur.com/AqKHVZ0.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# AI Program\n",
    "\n",
    "## Machine Learning - Supervised Learning - Regression - Polynomial Fit - Exercise\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 23/12/2025 | Royi Avital | Added type annotations to the methods                              |\n",
    "| 1.0.000 | 23/03/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0046RegressorPolynomialFit.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Miscellaneous\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, List, Optional, Self, Set, Tuple, Union\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    "```python\n",
    "# You need to start writing\n",
    "?????\n",
    "```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "PEOPLE_CSV_URL = 'https://github.com/FixelAlgorithmsTeam/FixelCourses/raw/master/DataSets/People.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "# from DataVisualization import PlotRegressionData, PlotRegressionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "def PolyModelString( vW: np.ndarray, applyLatex: bool = True ) -> str:\n",
    "    \n",
    "    latexDelimiter = '$' if applyLatex else ''\n",
    "\n",
    "    modelTxt = latexDelimiter + 'y = '\n",
    "    for ii in range(len(vW)):\n",
    "        modelTxt += f'({vW[ii]:0.3f}) {{x}}^{{{ii}}} + '\n",
    "    \n",
    "    modelTxt = modelTxt[:-2]\n",
    "    modelTxt += latexDelimiter\n",
    "\n",
    "    return modelTxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Fit\n",
    "\n",
    "This notebooks compares the performance of a _Regression Decision Tree_ vs. a _Linear Regressor_.  \n",
    "\n",
    "The data is based on [`People.csv`](https://github.com/FixelAlgorithmsTeam/FixelCourses/blob/master/DataSets/People.csv) data set.  \n",
    "It includes 1000 samples of peoples: Sex, Age, Height (CM), Weight (KG).  \n",
    "\n",
    "The objective is to estimate the weight given the height and sex.  \n",
    "The Sex is a categorical feature which is to work with with Decision Tree while Linear Model sometimes struggle with.\n",
    "\n",
    "This notebook goes through:\n",
    "\n",
    "1. Load the [`People.csv`](https://github.com/FixelAlgorithmsTeam/FixelCourses/blob/master/DataSets/People.csv) data set using `pd.csv_read()`.\n",
    "2. Build a baseline regressor based on a _pipeline_ of _Polynomial Features_ and _Linear Regression_.\n",
    "3. Build a regressor based on (Ensemble) Decision Tree Regressor.\n",
    "4. Optimize the Hyper Parameters of both.\n",
    "4. Compare results.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> In order to let the classifier know the data is binary / categorical we'll use a **Data Frame** as the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Model\n",
    "polynomDeg = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "Loads the online `csv` file directly as a Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "dfPeople = pd.read_csv(PEOPLE_CSV_URL)\n",
    "\n",
    "dfPeople.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair Plot\n",
    "\n",
    "sns.pairplot(data = dfPeople, hue = 'Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> How would you model the data for the task of estimation of the weight of a person given his sex, age and height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Training Data \n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Extract the 'Height' column into a series `dsX`.\n",
    "# 2. Extract the 'Weight' column into a series `dsY`.\n",
    "dfX = dfPeople[['Sex', 'Height']].copy()\n",
    "dsY = dfPeople['Weight'].copy()\n",
    "#===============================================================#\n",
    "\n",
    "print(f'The features data shape: {dfX.shape}')\n",
    "print(f'The labels data shape: {dsY.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "sns.scatterplot(data = dfPeople, x = 'Height', y = 'Weight', hue = 'Sex', ax = hA);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert String to Numeric\n",
    "\n",
    "dfX['Sex'] = dfX['Sex'].map({'f': 0, 'm': 1})\n",
    "# Set 'Sex' as categorical variable\n",
    "dfX['Sex'] = dfX['Sex'].astype('category') #<! LightGBM can handle categorical variables directly\n",
    "\n",
    "dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame Info\n",
    "dfX.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Which polynomial order fits the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressors\n",
    "\n",
    "The PolyFit optimization problem is given by:\n",
    "\n",
    "$$ \\arg \\min_{\\boldsymbol{w}} {\\left\\| \\boldsymbol{\\Phi} \\boldsymbol{w} - \\boldsymbol{y} \\right\\|}_{2}^{2} $$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Phi} = \\begin{bmatrix} 1 & x_{1} & x_{1}^{2} & \\cdots & x_{1}^{p} \\\\\n",
    "1 & x_{2} & x_{2}^{2} & \\cdots & x_{2}^{p} \\\\\n",
    "\\vdots & \\vdots & \\vdots &  & \\vdots \\\\\n",
    "1 & x_{N} & x_{N}^{2} & \\cdots & x_{N}^{p}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is a _polyfit_ with hyper parameter $p$.\n",
    "\n",
    "The optimal weights are calculated by linear system solvers.  \n",
    "Yet it is better to use solvers optimized for this task, such as:\n",
    "\n",
    " * NumPy: [`polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html).\n",
    " * SciKit Learn: [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) combined with [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).\n",
    "\n",
    "In this notebook we'll implement our own class based on SciKit Learn's solutions.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> For arbitrary $\\Phi$ the above becomes a _linear regression_ problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polyfit Estimator\n",
    "\n",
    "We could create the linear polynomial fit estimator using a `Pipeline` of `PolynomialFeatures` and `LinearRegression`.  \n",
    "Yet since this is a simple task it is a good opportunity to exercise the creation of a _SciKit Estimator_.\n",
    "\n",
    "We need to provide 4 main methods:\n",
    "\n",
    "1. The `__init()__` Method: The constructor of the object. It should set the degree of the polynomial model used.\n",
    "2. The `fit()` Method: The training phase. It should calculate the matrix and solve the linear regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model with Polynomial Features\n",
    "\n",
    "oPolyFitReg = Pipeline([\n",
    "    ('PolyFeatures', PolynomialFeatures(include_bias = False)),\n",
    "    ('RidgeReg', Ridge(fit_intercept = True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression Model\n",
    "\n",
    "oDecTreeReg = LGBMRegressor(random_state = seedNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "In this section we'll train the model on the whole data using the class implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize Hyper Parameters with Grid Search and Cross Validation\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Construct the model using the `PolyFitRegressor` class and `polynomDeg`.\n",
    "oGridSearchCv = GridSearchCV(\n",
    "    estimator = oPolyFitReg,\n",
    "    param_grid = {\n",
    "        'PolyFeatures__degree': [1, 2, 3, 4],\n",
    "        'RidgeReg__alpha': np.linspace(0, 5, 21).tolist()\n",
    "    },\n",
    "    cv = 20,\n",
    "    n_jobs = -1,\n",
    "    verbose = 1\n",
    ")\n",
    "oGridSearchCv = oGridSearchCv.fit(dfX, dsY)\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Optimal Model\n",
    "oPolyFitReg = oGridSearchCv.best_estimator_\n",
    "print(f'Optimal Hyper Parameters: {oGridSearchCv.best_params_}')\n",
    "print(f'Model Score: {oPolyFitReg.score(dfX, dsY):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression Model Fitting\n",
    "# Though an Ensemble is used, this section will ignore that for simplicity.\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Convert `dsX` into a 2D matrix `mX` of shape `(numSamples, 1)`.\n",
    "# 2. Convert `dsY` into a vector `vY` of shape `(numSamples, )`.\n",
    "# 3. Fit the model using `mX` and `vY`.\n",
    "# !! SciKit Learn's model requires input data as 2D array (DF / Matrix).\n",
    "oGridSearchCv = GridSearchCV(\n",
    "    estimator = oDecTreeReg,\n",
    "    param_grid = {\n",
    "        'max_depth': [2, 3],\n",
    "        'reg_alpha': np.linspace(0, 0.75, 11).tolist(),\n",
    "        'reg_lambda': np.linspace(4.25, 5, 11).tolist()\n",
    "    },\n",
    "    cv = 20,\n",
    "    n_jobs = -1,\n",
    "    verbose = 1\n",
    ")\n",
    "oGridSearchCv = oGridSearchCv.fit(dfX, dsY)\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Optimal Model\n",
    "oDecTreeReg = oGridSearchCv.best_estimator_\n",
    "print(f'Optimal Hyper Parameters: {oGridSearchCv.best_params_}')\n",
    "print(f'Model Score: {oDecTreeReg.score(dfX, dsY):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "# Extract the Coefficients of the model.\n",
    "vW = oPolyFit.vW_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Model\n",
    "\n",
    "vWRef = np.polyfit(dfX.to_numpy(), dsY.to_numpy(), deg = polynomDeg)[::-1]\n",
    "\n",
    "for ii in range(polynomDeg + 1):\n",
    "    print(f'The model {ii} coefficient: {vW[ii]}, The reference coefficient: {vWRef[ii]}')\n",
    "\n",
    "maxAbsDev = np.max(np.abs(vW - vWRef))\n",
    "print(f'The maximum absolute deviation: {maxAbsDev}') #<! Should be smaller than 1e-8\n",
    "\n",
    "if (maxAbsDev > 1e-8):\n",
    "    print(f'Error: The implementation of the model is in correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Error and Score\n",
    "\n",
    "When dealing with regression there is a useful visualization which shows the predicted value vs the reference value.  \n",
    "This allows showing the results regardless of the features number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Prediction\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "\n",
    "PlotRegressionResults(vY, oPolyFit.predict(mX), hA = hA, axisTitle = f'Estimation vs. Ground Truth with RMSE = {oPolyFit.score(mX, vY):0.3f} [KG]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the features are 1D we can also show the prediction as a function of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs. Features\n",
    "\n",
    "vXX = np.linspace(120, 220, 2000)\n",
    "hF, hA = plt.subplots(figsize = FIG_SIZE_DEF)\n",
    "\n",
    "modelTxt = '$y = '\n",
    "for ii in range(polynomDeg + 1):\n",
    "    modelTxt += f'({vW[ii]:0.3f}) {{x}}^{{{ii}}} + '\n",
    "\n",
    "modelTxt = modelTxt[:-2]\n",
    "modelTxt += '$'\n",
    "\n",
    "hA.scatter(dfX.to_numpy(), dsY.to_numpy(), color = 'b', label = 'Train Data')\n",
    "hA.plot(vXX, oPolyFit.predict(np.reshape(vXX, (-1, 1))), color = 'r', label = 'Model Estimation')\n",
    "hA.set_title(f'The Linear Regression Model: {modelTxt}')\n",
    "hA.set_xlabel('$x$ - Height [CM]')\n",
    "hA.set_ylabel('$y$ - Weight [KG]')\n",
    "hA.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What did the model predict? What should be done?\n",
    "* <font color='blue'>(**!**)</font> Try the above with the model order fo 1 and 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
