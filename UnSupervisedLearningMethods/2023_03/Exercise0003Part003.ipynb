{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/qkg2E2D.png)\n",
    "\n",
    "# UnSupervised Learning Methods\n",
    "\n",
    "## Exercise 003 - Part III\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.001 | 11/06/2023 | Royi Avital | Fixed questions numbering                                          |\n",
    "| 0.1.000 | 23/05/2023 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/UnSupervisedLearningMethods/2023_03/Exercise0002Part002.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_openml, load_breast_cancer, load_digits, load_iris, load_wine, make_s_curve\n",
    "\n",
    "# Computer Vision\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import math\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "#%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FILE_URL   = r'None'\n",
    "DATA_FILE_NAME  = r'None'\n",
    "\n",
    "T_MNIST_IMG_SIZE = (28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def BalancedSubSample( dfX: pd.DataFrame, colName: str, numSamples: int ):\n",
    "    \n",
    "    # TODO: Validate the number of samples\n",
    "    # TODO: Validate the column name (Existence and categorical values)\n",
    "    return dfX.groupby(colName, as_index = False, group_keys = False).apply(lambda dfS: dfS.sample(numSamples, replace = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    " - Fill the full names and ID's of the team members in the `Team Members` section.\n",
    " - Answer all questions / tasks within the Jupyter Notebook.\n",
    " - Use MarkDown + MathJaX + Code to answer.\n",
    " - Verify the rendering on VS Code.\n",
    " - Submission in groups (Single submission per group).\n",
    " - You may and _should_ use the forums for questions.\n",
    " - Good Luck!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The `Import Packages` section above imports most needed tools to apply the work. Please use it.\n",
    "* <font color='brown'>(**#**)</font> You may replace the suggested functions to use with functions from other packages.\n",
    "* <font color='brown'>(**#**)</font> Whatever not said explicitly to implement maybe used by a 3rd party packages.\n",
    "* <font color='brown'>(**#**)</font> The total run time of this notebook must be **lower than 60 [Sec]**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    " - `<FULL>_<NAME>_<ID001>`.\n",
    " - `<FULL>_<NAME>_<ID002>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "# This section downloads data from the given URL if needed.\n",
    "\n",
    "if (DATA_FILE_NAME != 'None') and (not os.path.exists(DATA_FILE_NAME)):\n",
    "    urllib.request.urlretrieve(DATA_FILE_URL, DATA_FILE_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kernel PCA (K-PCA / KPCA)\n",
    "\n",
    "### 5.1. Kernel PCA Algorithm\n",
    "\n",
    "In this section we'll implement a SciKit Learn API compatible class for the Kernel PCA.  \n",
    "The class should implement the following methods:\n",
    "\n",
    "1. `__init____()` - The object constructor by the encoder dimension.  \n",
    "   The input will include the encoder dimension `d` and a callable function for the kernel.\n",
    "2. `fit()` - Given a data set builds the encoder.  \n",
    "3. `transform()` - Applies the encoding on the input data.   \n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may use the [SciKit Learn's Kernel PCA module](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html) as a reference.\n",
    "* <font color='brown'>(**#**)</font> Both encoding and decoding applied as out of sample encoding / decoding.\n",
    "* <font color='brown'>(**#**)</font> Pay attention to data structure (`N x D`).\n",
    "* <font color='brown'>(**#**)</font> You may assume the kernel function `k` ($ k : \\, \\mathbb{R}^{D} \\times \\mathbb{R}^{D} \\to \\mathbb{R} $) has the following signature:\n",
    "\n",
    "```python\n",
    "def k(mX1: np.ndarray, mX2: np.ndarray)\n",
    "    '''\n",
    "    Computes the kernel function between two sets of vectors.\n",
    "    Args:\n",
    "        mX1 - Input data with shape N1 x D.\n",
    "        mX2 - Input data with shape N2 x D.\n",
    "    Output:\n",
    "        mKx - Output kernel matrix with shape N1 x N2.\n",
    "    '''\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPCA:\n",
    "    def __init__(self, d: int = 2, k: Callable = lambda x: x):\n",
    "        '''\n",
    "        Constructing the object.\n",
    "        Args:\n",
    "            d - Number of dimensions of the encoder output.\n",
    "            k - A kernel function (Callable).\n",
    "        '''\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Keep the model parameters.\n",
    "\n",
    "        ?????\n",
    "        #===============================================================#\n",
    "        \n",
    "    def fit(self, mX: np.ndarray):\n",
    "        '''\n",
    "        Fitting model parameters to the input.\n",
    "        Args:\n",
    "            mX - Input data with shape N x D.\n",
    "        Output:\n",
    "            self\n",
    "        '''\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Build the model encoder.\n",
    "        # 2. Optimize calculation by the dimensions of `mX`.\n",
    "        # !! You may find `scipy.sparse.linalg.svds()` useful.\n",
    "        # !! You may find `scipy.sparse.linalg.eigsh()` useful.\n",
    "        # Do not use `J` explicitly as a matrix multiplication.\n",
    "\n",
    "        ?????\n",
    "        #===============================================================# \n",
    "        return self\n",
    "    \n",
    "    def transform(self, mX: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Applies (Out of sample) encoding\n",
    "        Args:\n",
    "            mX - Input data with shape N x D.\n",
    "        Output:\n",
    "            mZ - Low dimensional representation (embeddings) with shape N x d.\n",
    "        '''\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Encode data using the model encoder.\n",
    "        \n",
    "        ?????\n",
    "        #===============================================================#\n",
    "\n",
    "        return mZ\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why `inverse_transform()` is not implemented? You may read about SciKit Learn's `inverse_transform()`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. K-PCA Application\n",
    "\n",
    "In this section the K-PCA (Using the above class) will be applied on several data sets:\n",
    "\n",
    " * Breast Cancer Dataset - Loaded using `load_breast_cancer()`.\n",
    " * Digits Dataset - Loaded using `load_digits()`.\n",
    " * Iris Dataset - Loaded using `load_iris()`.\n",
    " * Wine Dataset - Loaded using `load_wine()`.\n",
    "\n",
    "For each data set:\n",
    "\n",
    "1. Make yourself familiar with the data set:\n",
    "    * How many features are there ($D$).\n",
    "    * How many samples are there ($N$).\n",
    "    * Do all features have the same unit?\n",
    "2. Apply a Pre Process Step  \n",
    "   In ML, usually, if the features do not have the same unit they are normalized.  \n",
    "   Namely, make each feature with zero mean and unit standard deviation.   \n",
    "   Write a function to normalize input data.\n",
    "3. Apply the K-PCA  \n",
    "   Set `d` to be visualization friendly and apply PCA from $D$ to $d$.  \n",
    "   The obtained the low dimensional data represents $\\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N}$.  \n",
    "   You should use the following kernels (Implemented by yourself):\n",
    "     * $k \\left( \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\right) = \\boldsymbol{x}_{i}^{T} \\boldsymbol{x}_{j}$.\n",
    "     * $k \\left( \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\right) = \\left(1 + \\boldsymbol{x}_{i}^{T} \\boldsymbol{x}_{j} \\right)^{p}$.  \n",
    "       You should set a reasonable $p$.\n",
    "     * $k \\left( \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\right) = \\exp \\left( - \\frac{\\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{x}_{j} \\right\\|_{2}^{2}}{2 {\\sigma}^{2}} \\right)$.  \n",
    "       You should set a reasonable $\\sigma$.\n",
    "4. Plot Low Dimensional Data  \n",
    "   Make a scatter plot of $\\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N}$ and color the data points according to the data labels.  \n",
    "   For each data set show result with the normalization step and without it.\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Pay attention to the difference in dimensions of the data to the derived Math formulations.\n",
    "* <font color='brown'>(**#**)</font> The output should be 2 figures for each data set and kernel. You may show them in a single plot using sub plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Implement the normalization function.\n",
    "# !! Make sure to address the remark.\n",
    "\n",
    "def NormalizeData(mX: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Normalize data so each feature has zero mean and unit standard deviation.\n",
    "    Args:\n",
    "        mX  - Input data with shape N x d.\n",
    "    Output:\n",
    "        mY  - Output data with shape N x d.\n",
    "    Remarks:\n",
    "        - Features with zero standard deviation are not scaled (Only centered).\n",
    "    '''\n",
    "\n",
    "    ?????\n",
    "\n",
    "    return mY\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Implement the 3 kernels.\n",
    "# !! Make sure to address the remarks.\n",
    "# !! Pay attention that `np.dot(mA.T, mA)` is faster (Symmetric aware) than `mA.T @ mA`.\n",
    "\n",
    "def KernelInnerProduct( mX1: np.ndarray, mX2: np.ndarray ) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the kernel matrix of the Inner Product kernel.\n",
    "    Args:\n",
    "        mX1 - Input data with shape N1 x D.\n",
    "        mX2 - Input data with shape N2 x D.\n",
    "    Output:\n",
    "        mKx - Output data with shape N1 x N2.\n",
    "    Remarks:\n",
    "        - The function is implemented without explicit loops.\n",
    "    '''\n",
    "\n",
    "    ?????\n",
    "    \n",
    "    return mKx\n",
    "\n",
    "def KernelPolynomial( mX1: np.ndarray, mX2: np.ndarray, p: int = 2 ) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the kernel matrix of the Polynomial kernel.\n",
    "    Args:\n",
    "        mX1 - Input data with shape N1 x D.\n",
    "        mX2 - Input data with shape N2 x D.\n",
    "        p   - The degree of the model.\n",
    "    Output:\n",
    "        mKx - Output data with shape N1 x N2.\n",
    "    Remarks:\n",
    "        - The function is implemented without explicit loops.\n",
    "    '''\n",
    "\n",
    "    ?????\n",
    "    \n",
    "    return mKx\n",
    "\n",
    "def KernelGaussian( mX1: np.ndarray, mX2: np.ndarray, σ2: float = None ) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the kernel matrix of the Gaussian kernel.\n",
    "    Args:\n",
    "        mX1 - Input data with shape N1 x D.\n",
    "        mX2 - Input data with shape N2 x D.\n",
    "        σ2  - The variance of the model.\n",
    "    Output:\n",
    "        mKx - Output data with shape N1 x N2.\n",
    "    Remarks:\n",
    "        - The function is implemented without explicit loops.\n",
    "    '''\n",
    "\n",
    "    ?????\n",
    "    \n",
    "    return mKx\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Set parameter `d`.\n",
    "# 2. Load each data set.\n",
    "# 3. Apply PCA to each data set with and without normalization.\n",
    "# 4. Display results as scatter data.\n",
    "\n",
    "?????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Question\n",
    "\n",
    "In the above, compare the results of the _Inner Product_ kernel to the PCA from the previous part.  \n",
    "Explain the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Kernel PCA with Geodesic Distance (Bonus 4 Points)\n",
    "\n",
    "In this question we'll build a pseudo _geodesic distance_ and apply the Kernel PCA.\n",
    "\n",
    "In this section:\n",
    "\n",
    " 1. Generate 750 samples of S Curve manifold (2D in 3D) using SciKit Learn's [`make_s_curve()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_s_curve.html).  \n",
    "    Make sure to read about its output, specifically `t`.    \n",
    "    This is already implemented.\n",
    " 2. Build a pair wise distance function utilizing both the data coordinates and the `vT` variable.  \n",
    "    Since the `vT` variable holds location data, this is a geodesic like distance.\n",
    " 3. Show the distance for 3 different points.  \n",
    "    This is already implemented.\n",
    " 4. Apply a Kernel PCA from 3D to 2D on the data utilizing the distance function.\n",
    " 5. Show the results in the 2D space.\n",
    " 6. Explain the results (In words).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Since in the case above we use a pre computed distance function, you may not use the K-PCA but the PCA. You may use SciKit's Learn PCA or your own implementation.\n",
    "* With some tweaking of parameters and the distance function one may get the following result:\n",
    "\n",
    "![](https://i.imgur.com/CYVzYnF.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Data\n",
    "\n",
    "N      = 750\n",
    "mX, vT = make_s_curve(N)\n",
    "\n",
    "numDispPts = 4\n",
    "\n",
    "print(f'The data has shape of {mX.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data\n",
    "\n",
    "hF = plt.figure(figsize = (8, 8))\n",
    "hA = hF.add_subplot(projection = '3d')\n",
    "hA.scatter(mX[:, 0], mX[:, 1], mX[:, 2], s = 50, c = vT, edgecolor = 'k', alpha = 1)\n",
    "hA.set_xlim([-2, 2])\n",
    "hA.set_ylim([-2, 2])\n",
    "hA.set_zlim([-2, 2])\n",
    "hA.set_xlabel('$x_1$')\n",
    "hA.set_ylabel('$x_2$')\n",
    "hA.set_zlabel('$x_3$')\n",
    "hA.set_title('The S Curve Colored by `vT`')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Generate a pair wise distance function.\n",
    "# !! You may and should utilize the parameter `vT`.\n",
    "# !! Since we use the location data `vT` this is a geodesic like distance.\n",
    "# !! You may add any parameters you need to the function.\n",
    "\n",
    "def DistanceFunction( mX: np.ndarray, vT: np.ndarray ) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the kernel matrix of the Polynomial kernel.\n",
    "    Args:\n",
    "        mX - Input data with shape N x D.\n",
    "        vT - Input data (Location)\n",
    "    Output:\n",
    "        mD - Pair wise distance matrix with shape N x N.\n",
    "    Remarks:\n",
    "        - You may use SciPy's `cdist()` and / or `pdist()`.\n",
    "    '''\n",
    "\n",
    "    ?????\n",
    "#===============================================================#\n",
    "    \n",
    "    return mD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Calculate the Distance Matrix `mD`.\n",
    "# !! You may add any parameters you need to the function.\n",
    "\n",
    "mD = DistanceFunction(???)\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Distance Function for few Points\n",
    "# The result should look like a local distance along the surface of the S curve.\n",
    "\n",
    "vIdx = np.random.choice(N, numDispPts, replace = False)\n",
    "\n",
    "hF = plt.figure(figsize = (20, 6))\n",
    "\n",
    "for ii, idx in enumerate(vIdx):\n",
    "    \n",
    "    hA  = hF.add_subplot(1, numDispPts, ii + 1, projection = '3d')\n",
    "    hA.scatter(*mX.T, s = 50, c = mD[idx, :], edgecolor = 'k', alpha = 0.8)\n",
    "    hA.scatter(*mX[idx], s = 500, c = 'r', edgecolor = 'k', alpha = 1)\n",
    "    hA.set_xlim([-2, 2])\n",
    "    hA.set_ylim([-2, 2])\n",
    "    hA.set_zlim([-2, 2])\n",
    "    hA.set_xlabel('$x_1$')\n",
    "    hA.set_ylabel('$x_2$')\n",
    "    hA.set_zlabel('$x_3$')\n",
    "    \n",
    "    hA.view_init(elev = 15, azim = 300)\n",
    "\n",
    "hF.suptitle('Geodesic Distance from the Red Point')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Create a Kernel Matrix from the distance matrix.\n",
    "# 2. Apply the K-PCA (Manually or using SciKit Learn).\n",
    "\n",
    "?????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Display the low dimension encoding of the data.\n",
    "\n",
    "?????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.6. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
