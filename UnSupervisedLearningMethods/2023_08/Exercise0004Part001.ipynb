{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/qkg2E2D.png)\n",
    "\n",
    "# UnSupervised Learning Methods\n",
    "\n",
    "## Exercise 004 - Part I\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 08/09/2023 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/UnSupervisedLearningMethods/2023_08/Exercise0004Part001.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    " - Fill the full names and ID's of the team members in the `Team Members` section.\n",
    " - Answer all questions / tasks within the Jupyter Notebook.\n",
    " - Use MarkDown + MathJaX + Code to answer.\n",
    " - Verify the rendering on VS Code.\n",
    " - Submission in groups (Single submission per group).\n",
    " - The submission files should have the format: `<fileName>_GRP_<#>`.  \n",
    "   For instance, `Exercise001Part002_GRP_A.ipynb` or `AuxFun_GRP_A.py`.\n",
    " - You may and _should_ use the forums for questions.\n",
    " - Good Luck!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    " - `<FULL>_<NAME>_<ID001>`.\n",
    " - `<FULL>_<NAME>_<ID002>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classic Multi Dimensional Scaling (MDS)\n",
    "\n",
    " * Given a function $ \\phi \\left( \\cdot \\right) : \\mathbb{R}^{D} \\to \\mathbb{R}^{M} $.\n",
    " * Consider the following inner product: ${\\left \\langle \\boldsymbol{x}, \\boldsymbol{y} \\right \\rangle}_{\\phi} = \\left \\langle \\phi \\left( \\boldsymbol{x} \\right), \\phi \\left( \\boldsymbol{y} \\right) \\right \\rangle$.\n",
    " * Yields the induced norm: $ {\\left\\| \\boldsymbol{x} \\right\\|}_{\\phi} = \\sqrt{ \\left \\langle \\phi \\left( \\boldsymbol{x} \\right), \\phi \\left( \\boldsymbol{x} \\right) \\right \\rangle } $.\n",
    " * Yields the induced metric: ${d}_{\\phi} \\left( \\boldsymbol{x}, \\boldsymbol{y} \\right) = {\\left\\| \\boldsymbol{x} - \\boldsymbol{y} \\right\\|}_{\\phi}$.\n",
    "\n",
    "### 1.1. Question\n",
    "\n",
    "Consider the data (Training set) $\\mathcal{X} = \\left\\{ \\boldsymbol{x}_{i} \\in \\mathcal{R}^{D} \\right\\}_{i = 1}^{N}$ and let $\\boldsymbol{D}_{\\phi} \\left[ i, j \\right] = {d}_{\\phi}^{2} \\left( \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\right)$.\n",
    "\n",
    "Show that $- \\frac{1}{2} \\boldsymbol{J} \\boldsymbol{D}_{\\phi} \\boldsymbol{J} = J \\boldsymbol{K}_{\\phi} \\boldsymbol{J}$ where:\n",
    "\n",
    " * $\\boldsymbol{J} = \\boldsymbol{I} - \\frac{1}{N} \\boldsymbol{1} \\boldsymbol{1}^{T}$ - The centering matrix.\n",
    " * $\\boldsymbol{K}_{\\phi} = \\boldsymbol{\\Phi}^{T} \\boldsymbol{\\Phi}$ where: $\\boldsymbol{\\Phi} = \\begin{bmatrix} \\mid & \\mid &  & \\mid \\\\ \\phi \\left( \\boldsymbol{x}_{1} \\right) & \\phi \\left( \\boldsymbol{x}_{2} \\right) & \\dots & \\phi \\left( \\boldsymbol{x}_{N} \\right) \\\\ \\mid & \\mid & & \\mid \\end{bmatrix} \\in \\mathbb{R}^{M \\times N} = \\boldsymbol{\\Phi} = \\begin{bmatrix} \\mid & \\mid &  & \\mid \\\\ \\boldsymbol{\\phi}_{1} & \\boldsymbol{\\phi}_{2} & \\dots & \\boldsymbol{\\phi}_{N} \\\\ \\mid & \\mid & & \\mid \\end{bmatrix} \\in \\mathbb{R}^{M \\times N}$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Hints:\n",
    "    * Show that the transformation $\\phi \\left( \\cdot \\right)$ must be linear: $\\phi \\left( \\alpha \\boldsymbol{x}, \\beta \\boldsymbol{y} \\right) = \\alpha \\phi \\left( \\boldsymbol{x} \\right) + \\beta \\phi \\left( \\boldsymbol{y} \\right)$.  \n",
    "      You may use $\\left \\langle \\alpha \\boldsymbol{x} + \\beta \\boldsymbol{y}, \\boldsymbol{z} \\right \\rangle$ as a starting point. \n",
    "    * Show that ${d}_{\\phi}^{2} \\left( \\boldsymbol{x}, \\boldsymbol{y} \\right) = {\\left\\| \\phi \\left( \\boldsymbol{x} \\right) - \\phi \\left( \\boldsymbol{y} \\right) \\right\\|}_{2}^{2} = {\\left\\| \\phi \\left( \\boldsymbol{x} \\right) \\right\\|}_{2}^{2} - 2 \\left \\langle \\phi \\left( \\boldsymbol{x} \\right), \\phi \\left( \\boldsymbol{y} \\right) \\right \\rangle + {\\left\\| \\phi \\left( \\boldsymbol{y} \\right) \\right\\|}_{2}^{2}$\n",
    "    * Use the lecture notes to conclude $- \\frac{1}{2} \\boldsymbol{J} \\boldsymbol{D}_{\\phi} \\boldsymbol{J} = J \\boldsymbol{K}_{\\phi} \\boldsymbol{J}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the data (Training set) $\\mathcal{X} = \\left\\{ \\boldsymbol{x}_{i} \\in \\mathcal{R}^{D} \\right\\}_{i = 1}^{N}$ and let $\\boldsymbol{D} \\left[ i, j \\right] = {\\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{x}_{j} \\right\\|}_{2}^{2}$.\n",
    "\n",
    "### 1.2. Question\n",
    "\n",
    "Show that $\\boldsymbol{v}^{T} \\boldsymbol{D} \\boldsymbol{v} \\leq 0$ for any $\\boldsymbol{v}$ such that $\\left \\langle \\boldsymbol{v}, \\boldsymbol{1} \\right \\rangle = 0$.  \n",
    "What does it imply on _distance matrices_?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Majorization Minimization / Maximization\n",
    "\n",
    "Consider the matrix:\n",
    "\n",
    "$$ \\boldsymbol{Y} \\left[ i, j \\right] = \\begin{cases} \\boldsymbol{X} \\left[ i, j \\right] & \\text{ if } \\boldsymbol{M} \\left[ i, j \\right] = 1 \\\\ 0 & \\text{ if } \\boldsymbol{M} \\left[ i, j \\right] = 0 \\end{cases} $$\n",
    "\n",
    "Namely $\\boldsymbol{Y} = \\boldsymbol{M} \\circ \\boldsymbol{X}$ where $\\circ$ is the Hadamard Product and $\\boldsymbol{M} \\in {\\left\\{ 0, 1 \\right\\}}^{M \\times N}$ is a _binary mask matrix_.\n",
    "\n",
    "Given $\\boldsymbol{Y} \\in \\mathbb{R}^{M \\times N}$, the low rank matrix completion objective is given by:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\arg \\min_{\\boldsymbol{X} \\in \\mathbb{R}^{M \\times N}} \\quad & {\\left\\| \\boldsymbol{M} \\circ \\left( \\boldsymbol{X} - \\boldsymbol{Y} \\right) \\right\\|}_{F}^{2} \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\operatorname{Rank} \\left( \\boldsymbol{X} \\right) & \\leq d \\\\\n",
    "\\end{aligned}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### 2.1. Question (Bonus 2 Points)\n",
    "\n",
    "Consider the following function:\n",
    "\n",
    "$$ g \\left( \\boldsymbol{X}, \\boldsymbol{Z} \\right) = {\\left\\| \\boldsymbol{X} - \\boldsymbol{Z} + \\boldsymbol{M} \\circ \\left( \\boldsymbol{Z} - \\boldsymbol{Y} \\right) \\right\\|}_{F}^{2} $$\n",
    "\n",
    "Show that $g \\left( \\cdot, \\cdot \\right)$ surrogates the objective function $f \\left( \\boldsymbol{X} \\right) = {\\left\\| \\boldsymbol{M} \\circ \\left( \\boldsymbol{X} - \\boldsymbol{Y} \\right) \\right\\|}_{F}^{2}$.\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may show $g \\left( \\boldsymbol{X}, \\boldsymbol{Z} \\right) = {\\left\\| \\boldsymbol{M} \\circ \\left( \\boldsymbol{X} - \\boldsymbol{Y} \\right) + \\tilde{\\boldsymbol{M}} \\circ \\left( \\boldsymbol{X} - \\boldsymbol{Z} \\right) \\right\\|}_{F}^{2}$ where $\\tilde{\\boldsymbol{M}} = \\boldsymbol{1} \\boldsymbol{1}^{T} - \\boldsymbol{M}$ is the complement of $\\boldsymbol{M}$, as an intermediate step.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metric Multi Dimensional Scaling (MDS)\n",
    "\n",
    "The metric MDS objective is given by:\n",
    "\n",
    "$$ \\arg \\min_{\\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N}} {\\left\\| \\boldsymbol{\\Delta}_{x} - \\boldsymbol{D}_{z} \\right\\|}_{F}^{2} $$\n",
    "\n",
    "Where:\n",
    "\n",
    " * $\\boldsymbol{\\Delta}_{x} \\left[ i, j \\right] = d \\left( \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\right)$ - The given distance matrix.\n",
    " * $\\boldsymbol{D}_{z} = {\\left\\| \\boldsymbol{z}_{i} - \\boldsymbol{z}_{j} \\right\\|}_{2}$.\n",
    "\n",
    "Consider the surrogate function:\n",
    "\n",
    "$$ g \\left( \\boldsymbol{Z}, \\tilde{\\boldsymbol{Z}} \\right) = {\\left\\| \\boldsymbol{\\Delta}_{x} \\right\\|}_{F}^{2} + 2 N \\operatorname{Tr} \\left( \\boldsymbol{Z} \\boldsymbol{J} \\boldsymbol{Z}^{T} \\right) - 4 \\left \\langle \\boldsymbol{Z}^{T} \\tilde{\\boldsymbol{Z}}, \\boldsymbol{B} \\right \\rangle $$\n",
    "\n",
    "Where:\n",
    "\n",
    " * $\\boldsymbol{J} = \\boldsymbol{I} - \\frac{1}{N} \\boldsymbol{1} \\boldsymbol{1}^{T}$ - The centering matrix.\n",
    " * $\\tilde{\\boldsymbol{D}}_{\\tilde{z}} \\left[ i, j \\right] = {\\left\\| \\tilde{\\boldsymbol{z}}_{i} - \\tilde{\\boldsymbol{z}}_{j} \\right\\|}_{2}$.\n",
    " * $\\boldsymbol{C} \\left[ i, j \\right] = \\begin{cases} 0 & \\text{ if } i = j \\\\ - \\frac{ \\boldsymbol{\\Delta}_{x} \\left[ i, j \\right] }{ \\tilde{\\boldsymbol{D}}_{z} \\left[ i, j \\right] } & \\text{ if } i \\neq j \\end{cases}$.\n",
    " * $\\boldsymbol{B} = \\boldsymbol{C} - \\operatorname{Diag} \\left( \\boldsymbol{C} \\boldsymbol{1} \\right)$.\n",
    "\n",
    "### 3.1. Question\n",
    "\n",
    "Prove that $ \\boldsymbol{B} \\boldsymbol{J} = \\boldsymbol{B} $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Question\n",
    "\n",
    "Show that $g \\left( \\boldsymbol{Z}, \\boldsymbol{Z} \\right) = {\\left\\| \\boldsymbol{\\Delta}_{x} - \\boldsymbol{D}_{z} \\right\\|}_{F}^{2}$.\n",
    "\n",
    "\n",
    " * <font color='brown'>(**#**)</font> Hints (See _lecture notes_):\n",
    "     * ${\\left\\| \\boldsymbol{\\Delta}_{x} - \\boldsymbol{D}_{z} \\right\\|}_{F}^{2} = {\\left\\| \\boldsymbol{\\Delta}_{x} \\right\\|}_{F}^{2} - 2 \\left \\langle \\boldsymbol{\\Delta}_{x}, \\boldsymbol{D}_{z} \\right \\rangle + {\\left\\| \\boldsymbol{D}_{z} \\right\\|}_{F}^{2}$.\n",
    "     * ${\\left\\| \\boldsymbol{D}_{z} \\right\\|}_{F}^{2} = 2 N \\operatorname{Tr} \\left( \\boldsymbol{Z} \\boldsymbol{J} \\boldsymbol{Z}^{T} \\right)$.\n",
    "     * $\\boldsymbol{D}^{\\circ 2}_{z} \\left[ i, j \\right] = \\boldsymbol{p} \\boldsymbol{1}^{T} - 2 \\boldsymbol{Z}^{T} \\boldsymbol{Z} + 1 \\boldsymbol{p}^{T}, \\; \\boldsymbol{p} = \\begin{bmatrix} {\\left\\| \\boldsymbol{z}_{1} \\right\\|}_{2}^{2} \\\\ {\\left\\| \\boldsymbol{z}_{2} \\right\\|}_{2}^{2} \\\\ \\vdots {\\left\\| \\boldsymbol{z}_{N} \\right\\|}_{2}^{2} \\end{bmatrix}$.\n",
    "     * For $\\tilde{\\boldsymbol{Z}} = \\boldsymbol{Z}$ we have $\\left \\langle \\boldsymbol{\\Delta}_{x}, \\boldsymbol{D}_{z} \\right \\rangle = - \\left \\langle \\boldsymbol{C}, \\boldsymbol{D}^{\\circ 2}_{z} \\right \\rangle$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. IsoMap\n",
    "\n",
    "Let $G = \\left( V, E, W \\right) $ be a simple, undirected and weighted graph with no negative weights / edges.  \n",
    "Let $\\boldsymbol{D} \\in \\mathbb{R}^{N \\times N}$ be the shortest path distance matrix where $ \\left| V \\right| = N$.\n",
    "\n",
    "\n",
    "### 4.1. Question\n",
    "\n",
    "Prove or disprove: There is an embedding ${\\left\\{ \\boldsymbol{z}_{i} \\in \\mathbb{R}^{d} \\right\\}}_{i = 1}^{N}$ for some $d \\in \\mathbb{N}$ such that:\n",
    "\n",
    "$$ \\forall i, j \\; \\boldsymbol{D} \\left[ i, j \\right] = {\\left\\| \\boldsymbol{z}_{i} - \\boldsymbol{z}_{j} \\right\\|}_{2} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Question\n",
    "\n",
    " * Let $\\mathcal{X} = \\left\\{ \\boldsymbol{x}_{i} \\in \\mathbb{R}^{D} \\right\\}_{i = 1}^{N}$ be the training set.\n",
    " * Let $\\mathcal{Z} = \\left\\{ \\boldsymbol{z}_{i} \\right\\}_{i = 1}^{N}$ be the representation obtained by IsoMap (Encoded data).\n",
    " * Consider a new point $\\boldsymbol{x}^{\\ast}$ where $\\boldsymbol{x}^{\\ast} = \\boldsymbol{x}_{k}, \\; k \\in \\left\\{ 1, 2, \\ldots, N \\right\\}$.\n",
    " * Consider a new point $\\boldsymbol{x}^{\\dagger}$ where $\\nexists l : \\, \\boldsymbol{x}^{\\dagger} = \\boldsymbol{x}_{l}, \\; l \\in \\left\\{ 1, 2, \\ldots, N \\right\\}$.\n",
    " * Let $\\boldsymbol{z}^{\\ast}$ be the out of sample encoding applied to $\\boldsymbol{x}^{\\ast}$.\n",
    " * Let $\\boldsymbol{z}^{\\dagger}$ be the out of sample encoding applied to $\\boldsymbol{x}^{\\dagger}$.\n",
    "\n",
    "1. Prove or disprove: $\\boldsymbol{z}^{\\ast} = \\boldsymbol{z}_{k}$.\n",
    "1. Prove or disprove: Must exists $l$ such that $\\boldsymbol{z}^{\\dagger} = \\boldsymbol{z}_{l}$.\n",
    "\n",
    " * <font color='brown'>(**#**)</font> The out of sample encoding is as shown in _lecture notes_.\n",
    " * <font color='brown'>(**#**)</font> The question is basically if the out of sample extension is equivalent to having the point in the training set for such case.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Laplacian Eigenmaps\n",
    "\n",
    " * Let $\\mathcal{X} = \\left\\{ \\boldsymbol{x}_{i} \\in \\mathbb{R}^{D} \\right\\}_{i = 1}^{N}$.\n",
    " * Let $G = \\left( V, E, W \\right)$ be a weighted graph with with $V = \\mathcal{X}$.\n",
    " * Define $\\boldsymbol{W} \\left[ i, j \\right] = \\begin{cases} \\exp \\left( - \\frac{ {\\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{x}_{j} \\right\\|}_{2}^{2} }{2 {\\sigma}^{2}} \\right) & \\text{ if } \\boldsymbol{x}_{i} \\in \\mathcal{N}_{j} \\text{ or } \\boldsymbol{x}_{j} \\in \\mathcal{N}_{i} \\\\ 0 & \\text{ else } \\end{cases}$.\n",
    " * Then ${e}_{ij} \\in E$ if $\\boldsymbol{W} \\left[ i, j \\right] \\neq 0$.\n",
    " * The _Graph Laplacian_ $\\boldsymbol{L} = \\boldsymbol{D} - \\boldsymbol{W}$.\n",
    " * The _Degree Matrix_ $\\boldsymbol{D} = \\operatorname{Diag} \\left( \\boldsymbol{W} \\boldsymbol{1} \\right)$.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1. Question\n",
    "\n",
    " * Let $\\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N}$ be a set of data with $\\boldsymbol{z}_{i}$ being the $i$ -th column of $\\boldsymbol{Z}$.\n",
    " * Define $\\boldsymbol{D}_{z} \\in \\mathbb{R}^{N \\times N}$ where $\\boldsymbol{D}_{z} \\left[ i, j \\right] = {\\left\\| \\boldsymbol{z}_{i} - \\boldsymbol{z}_{j} \\right\\|}_{2}^{2}$.  \n",
    "\n",
    "Show that:\n",
    "\n",
    "$$ \\frac{1}{2} \\left \\langle \\boldsymbol{W}, \\boldsymbol{D}_{z} \\right \\rangle = \\operatorname{Tr} \\left(  \\boldsymbol{Z} \\boldsymbol{L} \\boldsymbol{Z}^{T} \\right) $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $G$ be an undirected graph with a non negative weights with the corresponding graph laplacian matrix $\\boldsymbol{L}$.  \n",
    "The matrix $\\boldsymbol{L}$ has the eigen value $0$ with multiplicity of $k$.\n",
    "\n",
    "### 5.3. Question\n",
    "\n",
    "Show that the number of connected components of the graph is $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SNE & t-SNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $ p $ be the perplexity hyper parameter of the _SNE_ algorithm.  \n",
    "\n",
    "### 6.2. Question\n",
    "\n",
    "* Given the perplexity, explain the motivation behind using $K$ or $\\epsilon$ graphs in the context of the algorithm?\n",
    "* How will the algorithm behave for $p \\to \\infty$?\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The definition for $K$ or $\\epsilon$ graphs is given in the lecture notes of _IsoMap_ and _Laplacian Eigenmaps_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
