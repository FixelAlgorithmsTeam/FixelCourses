{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/qkg2E2D.png)\n",
    "\n",
    "# UnSupervised Learning Methods\n",
    "\n",
    "## Exercise 003 - Part II\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 28/05/2023 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/UnSupervisedLearningMethods/2023_08/Exercise0003Part002.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_openml, load_breast_cancer, load_digits, load_iris, load_wine\n",
    "\n",
    "# Computer Vision\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import math\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "#%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FILE_URL   = r'None'\n",
    "DATA_FILE_NAME  = r'None'\n",
    "\n",
    "T_MNIST_IMG_SIZE = (28, 28)\n",
    "\n",
    "TOTAL_RUN_TIME = 30 #<! Don't touch it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def BalancedSubSample( dfX: pd.DataFrame, colName: str, numSamples: int ):\n",
    "    \n",
    "    # TODO: Validate the number of samples\n",
    "    # TODO: Validate the column name (Existence and categorical values)\n",
    "    return dfX.groupby(colName, as_index = False, group_keys = False).apply(lambda dfS: dfS.sample(numSamples, replace = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    " - Fill the full names and ID's of the team members in the `Team Members` section.\n",
    " - Answer all questions / tasks within the Jupyter Notebook.\n",
    " - Use MarkDown + MathJaX + Code to answer.\n",
    " - Verify the rendering on VS Code.\n",
    " - Submission in groups (Single submission per group).\n",
    " - You may and _should_ use the forums for questions.\n",
    " - Don't use `pip install` on the submitted notebook!  \n",
    "   If you need a package that is not imported make it clear by a comment.\n",
    " - Good Luck!\n",
    "\n",
    "<font color='red'>Total run time must be **less than `TOTAL_RUN_TIME` seconds**</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Time\n",
    "print(f'The total run time must not exceed: {TOTAL_RUN_TIME} [Sec]')\n",
    "startTime = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    " - `<FULL>_<NAME>_<ID001>`.\n",
    " - `<FULL>_<NAME>_<ID002>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The `Import Packages` section above imports most needed tools to apply the work. Please use it.\n",
    "* <font color='brown'>(**#**)</font> You may replace the suggested functions to use with functions from other packages.\n",
    "* <font color='brown'>(**#**)</font> Whatever not said explicitly to implement maybe used by a 3rd party packages.\n",
    "* <font color='brown'>(**#**)</font> The total run time of this notebook must be **lower than 60 [Sec]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students Packages to Import\n",
    "# If you need a package not listed above, use this cell\n",
    "# Do not use `pip install` in the submitted notebook\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "# This section downloads data from the given URL if needed.\n",
    "\n",
    "if (DATA_FILE_NAME != 'None') and (not os.path.exists(DATA_FILE_NAME)):\n",
    "    urllib.request.urlretrieve(DATA_FILE_URL, DATA_FILE_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA\n",
    "\n",
    "### 3.1. PCA Algorithm\n",
    "\n",
    "In this section we'll implement a SciKit Learn API compatible class for the PCA.  \n",
    "The class should implement the following methods:\n",
    "\n",
    "1. `__init____()` - The object constructor by the encoder dimension.  \n",
    "2. `fit()` - Given a data set builds the encoder / decoder.  \n",
    "3. `transform()` - Applies the encoding on the input data.  \n",
    "4. `inverse_transform()` - Applies the decoding on the input data.  \n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may use the [SciKit Learn's PCA module](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) as a reference.\n",
    "* <font color='brown'>(**#**)</font> Both encoding and decoding applied as out of sample encoding / decoding.\n",
    "* <font color='brown'>(**#**)</font> Pay attention to data structure (`N x D`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, d: int = 2):\n",
    "        '''\n",
    "        Constructing the object.\n",
    "        Args:\n",
    "            d - Number of dimensions of the encoder output.\n",
    "        '''\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Keep the model parameters.\n",
    "\n",
    "        ?????\n",
    "        #===============================================================#\n",
    "        \n",
    "    def fit(self, mX: np.ndarray):\n",
    "        '''\n",
    "        Fitting model parameters to the input.\n",
    "        Args:\n",
    "            mX - Input data with shape N x D.\n",
    "        Output:\n",
    "            self\n",
    "        '''\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Build the model encoder.\n",
    "        # 2. Build the model decoder.\n",
    "        # 3. Optimize calculation by the dimensions of `mX`.\n",
    "        # !! You may find `scipy.sparse.linalg.svds()` useful.\n",
    "        # !! You may find `scipy.sparse.linalg.eigsh()` useful.\n",
    "\n",
    "        ?????\n",
    "        #===============================================================# \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, mX: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Applies (Out of sample) encoding\n",
    "        Args:\n",
    "            mX - Input data with shape N x D.\n",
    "        Output:\n",
    "            mZ - Low dimensional representation (embeddings) with shape N x d.\n",
    "        '''\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Encode data using the model encoder.\n",
    "        # return (mX - np.atleast_1d(self.vMean)) @ self.mUd\n",
    "        \n",
    "        ?????\n",
    "        #===============================================================#\n",
    "\n",
    "        return mZ\n",
    "    \n",
    "    def inverse_transform(self, mZ: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Applies (Out of sample) decoding\n",
    "        Args:\n",
    "            mZ - Low dimensional representation (embeddings) with shape N x d.\n",
    "        Output:\n",
    "            mX - Reconstructed data with shape N x D.\n",
    "        '''\n",
    "        #===========================Fill This===========================#\n",
    "        # 1. Encode data using the model decoder.\n",
    "        # return (mZ @ self.mUd.T) + np.atleast_1d(self.vMean)\n",
    "        \n",
    "        ?????\n",
    "        #===============================================================#\n",
    "\n",
    "        return mX\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> In the class we use _out of sample_ encoding / decoding. What if we use the same `mX` for training and the encoding?  \n",
    "Make sure to understand this before proceeding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. PCA Application\n",
    "\n",
    "In this section the PCA (Using the above class) will be applied on several data sets:\n",
    "\n",
    " * Breast Cancer Dataset - Loaded using `load_breast_cancer()`.\n",
    " * Digits Dataset - Loaded using `load_digits()`.\n",
    " * Iris Dataset - Loaded using `load_iris()`.\n",
    " * Wine Dataset - Loaded using `load_wine()`.\n",
    "\n",
    "For each data set:\n",
    "\n",
    "1. Make yourself familiar with the data set:\n",
    "    * How many features are there ($D$).\n",
    "    * How many samples are there ($N$).\n",
    "    * Do all features have the same unit?\n",
    "2. Apply a Pre Process Step  \n",
    "   In ML, usually, if the features do not have the same unit they are normalized.  \n",
    "   Namely, make each feature with zero mean and unit standard deviation.   \n",
    "   Write a function to normalize input data.\n",
    "3. Apply the PCA  \n",
    "   Set `d` to be visualization friendly and apply PCA from $D$ to $d$.  \n",
    "   The obtained the low dimensional data represents $\\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N}$.\n",
    "4. Plot Low Dimensional Data  \n",
    "   Make a scatter plot of $\\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N}$ and color the data points according to the data labels.  \n",
    "   For each data set show result with the normalization step and without it.\n",
    "5. Calculate Lost Energy  \n",
    "   For each plot, show the value of ${\\left\\| \\tilde{\\boldsymbol{X}} - \\boldsymbol{X} \\right\\|}_{F}^{2}$.  \n",
    "   Do this by applying `inverse_transform()` on the low dimensional data and calculate the norm.\n",
    "\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Pay attention to the difference in dimensions of the data to the derived Math formulations.\n",
    "* <font color='brown'>(**#**)</font> The output should be plots figures for each data set. Show them in a single figure using sub plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Implement the normalization function.\n",
    "# !! Make sure to address the remark.\n",
    "\n",
    "def NormalizeData(mX: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Normalize data so each feature has zero mean and unit standard deviation.\n",
    "    Args:\n",
    "        mX  - Input data with shape N x d.\n",
    "    Output:\n",
    "        mY  - Output data with shape N x d.\n",
    "    Remarks:\n",
    "        - Features with zero standard deviation are not scaled (Only centered).\n",
    "    '''\n",
    "\n",
    "    ????\n",
    "\n",
    "    return mY\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Set parameter `d`.\n",
    "# 2. Load each data set.\n",
    "# 3. Apply PCA to each data set with and without normalization.\n",
    "# 4. Display results as scatter data.\n",
    "# !! The figure should be 2 x numDataSets.\n",
    "\n",
    "????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Question\n",
    "\n",
    "In the above, why does the results of the normalized and non normalized data are different?  \n",
    "Address the geometry of the results and the value of the reconstruction error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Denoising\n",
    "\n",
    "In this section the PCA algorithm will be used for denoising images from the [MNIST Dataset](https://en.wikipedia.org/wiki/MNIST_database).  \n",
    "In this section:\n",
    "\n",
    " 1. Load Data  \n",
    "    Load the MNIST data set and sub sample it.  \n",
    "    We'll have a perfectly balanced data set.\n",
    "    The data will be in `mX` and labels in `vY`.  \n",
    "    This is already implemented.\n",
    " 2. Add Noise  \n",
    "    We'll add noise to the data.  \n",
    "    The noise of the data will be modeled as a Poisson Noise (Also known as [_Shot Noise_](https://en.wikipedia.org/wiki/Shot_noise)).  \n",
    "    The _Shot Noise_ is a classic model of noise gathered by imaging sensors.  \n",
    "    This is already implemented.\n",
    " 3. Analyze the Data  \n",
    "    Analyze the spectrum of the data and choose an appropriate ste of parameters for denoising.\n",
    " 3. Apply Denoising  \n",
    "    Apply denoising by utilizing the PCA algorithm.\n",
    " 4. Analyze Result  \n",
    "    Show the results as a function of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "numSamplesClass = 600\n",
    "λ               = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# If you get SSL error, uncomment the following 2 lines\n",
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "dfX, dfY = fetch_openml(name = 'mnist_784', version = 1, return_X_y = True, as_frame = True, parser = 'auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub Sample Data\n",
    "dfData = pd.concat((dfX, dfY), axis = 1)\n",
    "\n",
    "# Balanced Sub Sample\n",
    "# End Result: 'numSamplesClass' samples per digit\n",
    "dfData = BalancedSubSample(dfData, 'class', numSamplesClass)\n",
    "vY = dfData['class'].to_numpy(dtype = np.uint8)\n",
    "mX = dfData.drop(columns = ['class']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Poisson Noise\n",
    "mN = np.random.poisson(λ, size = mX.shape) #<! Noise samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Noise\n",
    "# Make sure values are in {0, 1, 2, ..., 255} range\n",
    "mXRef = mX.copy() #<! Reference with no noise\n",
    "mXRef = mXRef / 255\n",
    "\n",
    "mX += mN\n",
    "mX = np.minimum(mX, 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Samples\n",
    "\n",
    "lIdx = [np.flatnonzero(vY == ii)[0] for ii in range(10)]\n",
    "\n",
    "_, mHA = plt.subplots(1, 10, figsize = (16, 4))\n",
    "for ii, hA in enumerate(mHA.flat):\n",
    "    idx = lIdx[ii]\n",
    "    mI  = np.reshape(mX[idx], T_MNIST_IMG_SIZE)\n",
    "    # mI  = np.clip(mI, 0, 1)\n",
    "    hA.imshow(mI, cmap = 'gray')\n",
    "    hA.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. The Data Spectrum\n",
    "\n",
    "In this section:\n",
    "\n",
    " 1. Pre Process the data (Optional).  \n",
    "    Do this step if you think it is needed.\n",
    " 2. Plot the Spectrum of the Eigen Values of the data.\n",
    " 3. Choose **a range** (5 values) of `d` for the low dimensionality reduction.\n",
    " 4. For each `d` value, calculate the **relative energy loss**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Pre Process Data (Optional).\n",
    "# !! Make sure to keep the name of the data `mX`.\n",
    "# !! Don't change the order of the data so it matches `vY`.\n",
    "\n",
    "?????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Calculate the spectrum of the Eigen Values of the data.\n",
    "\n",
    "????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Display the Spectrum.\n",
    "# !! You may show both the spectrum and the relative energy.\n",
    "\n",
    "????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Choose a range of `d` values.\n",
    "# 2. Per `d` plot / display the relative energy loss.\n",
    "# !! Don't choose too many, keep running time and visualization reasonable.\n",
    "# !! The choice should be in order to show the effect of `d` on the results and not only the optimal `d`.\n",
    "\n",
    "????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. PCA Based Denoising\n",
    "\n",
    "In this section, per `d` value:\n",
    "\n",
    " 1. Build the _Encoder_ and _Decoder_. \n",
    " 2. Denoise the images listed in the index list `lIdx`.\n",
    " 3. Show results per `d`\n",
    "      * For each image show the reconstruction error vs. the noisy sample (`mX`).\n",
    "      * For each image show the estimation error vs. the non noisy sample (`mXRef`).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Make sure when you use the whole data (`mX`) and when the sub set to analyze.\n",
    "* <font color='brown'>(**#**)</font> For the PCA you may only use `mX`.\n",
    "* <font color='brown'>(**#**)</font> The output should be the 10 images per row where the number of rows is the number of `d` values + 2 (For the reference / noisy images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Build the encoder / decoder using the `PCA` class above.\n",
    "# 2. Per `d` denoise the images in `lIdx`.\n",
    "# !! Only use `mX` for the PCA step.\n",
    "\n",
    "????\n",
    "    \n",
    "\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Create a subplot of `len(d) + 2 x 10` plots.\n",
    "# 2. In the 1st row, show the clean images (`mXRef`).\n",
    "# 3. In the 2nd row, show the noisy images (`mX`).\n",
    "# 4. In the next rows show the sample per different `d`.  \n",
    "#    Per row, show `d`.\n",
    "\n",
    "????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Create 2 sub plots where the `x` is the image index {0, 1, ..., 9}.\n",
    "# 2. The 1st plot, per `d`, shows the reconstruction error.\n",
    "# 3. The 2nd plot, per `d`, shows the estimation error.\n",
    "\n",
    "????\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Question\n",
    "\n",
    "Address the following remarks:\n",
    "\n",
    " - How does the noise model effect the performance of the denoising?  \n",
    "   Specifically, if the noise model was Gaussian with the same variance, what would change?\n",
    " - Would you use the reconstruction error as an estimation of the estimation error?  \n",
    "   Answer in general and specifically for Images.\n",
    " - Explain the idea behind the PCA denoising.  \n",
    "   Specifically address the trade off between small and large values of `d`.\n",
    " - If the data was 1D (Audio instead of Image), would you expect it to perform better?  \n",
    "   Think if the model has any knowledge about the data being 2D."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. PCA Denoising with Labels\n",
    "\n",
    "In the above we used no knowledge on the label of the image.  \n",
    "In this section you should use the labels information in order to improve results.\n",
    "\n",
    " 1. Write a code which take advantage of the labels `vY` (Be creative).\n",
    " 2. Show the plots of the reconstruction and estimation error.\n",
    " 3. Explain, in words, your idea.\n",
    " 4. Explain, in words, the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Choose the maximum `d` used in the previous section.\n",
    "# 2. Apply PCA Denoising on the list of images.\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Display the reconstruction and estimation error per image.\n",
    "# 2. Compare to the previous result for the same `d`.\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Time\n",
    "# Check Total Run Time.\n",
    "# Don't change this!\n",
    "\n",
    "endTime = time.time()\n",
    "\n",
    "totalRunTime = endTime - startTime\n",
    "print(f'Total Run Time: {totalRunTime} [Sec].')\n",
    "\n",
    "if (totalRunTime > TOTAL_RUN_TIME):\n",
    "    raise ValueError(f'You have exceeded the allowed run time as {totalRunTime} > {TOTAL_RUN_TIME}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
