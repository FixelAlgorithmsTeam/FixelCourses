{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Deep Learning Methods\n",
    "\n",
    "## Vision Transformer (ViT) - Self Attention for Signal Smoothing\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 27/12/2025 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0090DeepLearningPyTorchTensorBoard.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchinfo\n",
    "import torchvista\n",
    "\n",
    "# Miscellaneous\n",
    "from enum import auto, Enum, unique\n",
    "import math\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, Generator, List, Optional, Self, Set, Tuple, Union\n",
    "from numpy.typing import NDArray\n",
    "from torch import Tensor\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    "```python\n",
    "# You need to start writing\n",
    "?????\n",
    "```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# Improve performance by benchmarking\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Reproducibility (Per PyTorch Version on the same device)\n",
    "# torch.manual_seed(seedNum)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark     = False #<! Makes things slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n",
    "\n",
    "DATA_FOLDER_PATH    = 'Data'\n",
    "TENSOR_BOARD_BASE   = 'TB'\n",
    "\n",
    "π = math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Auxiliary Modules for Google Colab\n",
    "if runInGoogleColab:\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataManipulation.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DataVisualization.py\n",
    "    !wget https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/master/AIProgram/2024_02/DeepLearningPyTorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n",
    "\n",
    "from DataVisualization import PlotLabelsHistogram, PlotMnistImages\n",
    "from DeepLearningPyTorch import NNMode\n",
    "from DeepLearningPyTorch import RunEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n",
    "\n",
    "@unique\n",
    "class SignalType(Enum):\n",
    "    CHIRP           = auto()\n",
    "    ECG_LIKE        = auto()\n",
    "    PIECEWISE_SINE  = auto()\n",
    "    RANDOM_WALK     = auto()\n",
    "    SAWTOOTH        = auto()\n",
    "    STEPS           = auto()\n",
    "\n",
    "def GenSignal( signalType: SignalType, dSignalParams: Dict, /, *, seedNum: int = seedNum ) -> Tuple[NDArray, NDArray, NDArray]:\n",
    "    \"\"\"\n",
    "    Generate synthetic 1D signal.\n",
    "    \"\"\"\n",
    "    \n",
    "    oRng       = np.random.default_rng(seedNum)\n",
    "    numSamples = dSignalParams['numSamples']\n",
    "    vT         = np.linspace(0.0, 1.0, numSamples, endpoint = False)\n",
    "\n",
    "    vC = np.zeros(numSamples) #<! Clean signal\n",
    "\n",
    "    dParams = dSignalParams[signalType]\n",
    "\n",
    "    match signalType:\n",
    "        case SignalType.CHIRP:\n",
    "            f0, f1 = dParams['chirpFreq0'], dParams['chirpFreq1']\n",
    "            segPhase = 2 * π * (f0 * vT + 0.5 * (f1 - f0) * vT * vT)\n",
    "            vC = np.sin(segPhase)\n",
    "            \n",
    "        case SignalType.ECG_LIKE:\n",
    "            vC = np.zeros(numSamples)\n",
    "            centers = np.linspace(0.1, 0.9, dParams['ecgHeartbeats'])\n",
    "            for c in centers:\n",
    "                vC += 2.2 * np.exp(-0.5 * ((vT - c) / dParams['ecgWidth']) ** 2)\n",
    "                vC += 0.3 * np.exp(-0.5 * ((vT - (c - 0.06)) / (dParams['ecgWidth'] * 2.5)) ** 2)\n",
    "                vC += 0.5 * np.exp(-0.5 * ((vT - (c + 0.08)) / (dParams['ecgWidth'] * 4.0)) ** 2)\n",
    "            vC -= vC.mean()\n",
    "            vC /= (vC.std() + 1e-6)\n",
    "        \n",
    "        case SignalType.PIECEWISE_SINE:\n",
    "            vE = np.linspace(0, numSamples, dParams['numSegments'] + 1, dtype = int) #<! Segment edges\n",
    "            vC += (dParams['trendStrength'] * (vT - 0.5))\n",
    "\n",
    "            for ss in range(dParams['numSegments']):\n",
    "                i0, i1 = vE[ss], vE[ss + 1]\n",
    "                segAmp = oRng.uniform(*dParams['ampRange'])\n",
    "                segFreq = oRng.uniform(*dParams['freqRange'])\n",
    "                segPhase = oRng.uniform(*dParams['phaseRange'])\n",
    "                vTSeg = vT[i0:i1]\n",
    "                vC[i0:i1] += segAmp * np.sin(2 * π * segFreq * vTSeg + segPhase)\n",
    "\n",
    "                if ss > 0 and (oRng.uniform() < dParams['stepProb']):\n",
    "                    # Add a step change\n",
    "                    valStep  = oRng.uniform(-dParams['stepScale'], dParams['stepScale'])\n",
    "                    vC[i0:] += valStep\n",
    "        \n",
    "        case SignalType.RANDOM_WALK:\n",
    "            steps = oRng.normal(loc = dParams['rwDrift'], scale = dParams['rwStepStd'], size = numSamples)\n",
    "            vC = np.cumsum(steps)\n",
    "            vC -= vC.mean()\n",
    "            vC /= (vC.std() + 1e-6)\n",
    "\n",
    "        case SignalType.SAWTOOTH:\n",
    "            vX = dParams['sawFreq'] * vT\n",
    "            vC = 2.0 * (vX - np.floor(vX)) - 1.0\n",
    "            \n",
    "        case SignalType.STEPS:\n",
    "            lStepPoints = sorted(oRng.choice(np.arange(10, numSamples - 10), size = dParams['numSteps'], replace = False).tolist())\n",
    "            stepLvl = 0.0\n",
    "            stepStartIdx = 0\n",
    "            for stepEndIdx in lStepPoints + [numSamples]:\n",
    "                vC[stepStartIdx:stepEndIdx] = stepLvl\n",
    "                stepLvl += oRng.uniform(dParams['stepMin'], dParams['stepMax'])\n",
    "                stepStartIdx = stepEndIdx\n",
    "\n",
    "        case _:\n",
    "            raise ValueError(f'Unknown `signalType`: {signalType}')\n",
    "    \n",
    "    vN = oRng.normal(0.0, dSignalParams['noiseStd'], size = numSamples) #<! Noise\n",
    "\n",
    "    vS = np.zeros(numSamples) #<! Spikes signal\n",
    "    if dSignalParams['spikeProb'] > 0:\n",
    "        vM = oRng.uniform(size = numSamples) < dSignalParams['spikeProb'] #<! Mask for spikes\n",
    "        vS[vM] = oRng.normal(0.0, dSignalParams['spikeScale'], size = int(vM.sum()))\n",
    "\n",
    "    vSignal = vC + vN + vS\n",
    "\n",
    "    return vT, vC, vSignal\n",
    "\n",
    "def KernelRegression( vT: NDArray, vSignal: NDArray, /, *, σ: float = 0.01, ε: float = 1e-6 ) -> Tuple[NDArray, NDArray]:\n",
    "    \"\"\"\n",
    "    Perform kernel regression smoothing on 1D signal.\n",
    "    \"\"\"\n",
    "\n",
    "    numSamples      = vT.shape[0]\n",
    "    vSignalSmoothed = np.zeros(numSamples)\n",
    "\n",
    "    mD = sp.spatial.distance.squareform(sp.spatial.distance.pdist(vT[:, None], metric = 'sqeuclidean')) #<! Distance matrix\n",
    "    mA = np.exp(-0.5 * mD / (σ ** 2)) #<! Affinity matrix (Non adaptive \"Attention\")\n",
    "    mA /= (mA.sum(axis = 1, keepdims = True) + ε) #<! Normalize\n",
    "\n",
    "    vSignalSmoothed = mA @ vSignal #<! Smooth signal\n",
    "    vSignalSmoothed = np.squeeze(vSignalSmoothed)\n",
    "\n",
    "    return vSignalSmoothed, mA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch & TensorBoard\n",
    "\n",
    "[TensorBoard](https://www.tensorflow.org/tensorboard) is a tool to analyze runs of models.    \n",
    "The concept is to save data to HD while running and display it using the server.   \n",
    "This policy prevents loss of information in case of a failure.  \n",
    "It also adds the ability to \"babysit\" the model while running.\n",
    "\n",
    "Using _TensorBoard_ is based on:\n",
    "\n",
    " * Defining a `SummaryWriter` object which documents a session.\n",
    " * Using the `SummaryWriter`'s method to add data: Scalars, Figures, Images, etc...\n",
    "\n",
    "\n",
    "This notebook shows more capabilities of [`SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard):\n",
    "\n",
    " - Working with a Scalar (`add_scalar()`).\n",
    " - Working with Scalars (`add_scalars()`).\n",
    " - Working with Figures (`add_figure()`).\n",
    " - Working with Hyper Parameters (`add_hparams()`).\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> While [TensorBoard](https://www.tensorflow.org/tensorboard) is common in the DL world, it might used to handle any ML analysis.\n",
    "* <font color='brown'>(**#**)</font> See [`torch.utils.tensorboard.writer.SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard) documentation.\n",
    "* <font color='brown'>(**#**)</font> Alternatives: [ClearML](https://clear.ml), [Weights & Biases](https://wandb.ai), [ML Flow](https://mlflow.org), [Neptune AI](https://neptune.ai).\n",
    "* <font color='brown'>(**#**)</font> [Deep Dive Into TensorBoard: Tutorial With Examples](https://neptune.ai/blog/tensorboard-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "signalType = SignalType.ECG_LIKE\n",
    "\n",
    "dSignalParams = {\n",
    "    'numSamples': 256,\n",
    "    'noiseStd': 0.15,\n",
    "    'spikeProb': 0.02,\n",
    "    'spikeScale': 2.5,\n",
    "    SignalType.CHIRP: {\n",
    "        'chirpFreq0': 1.0,\n",
    "        'chirpFreq1': 10.0,\n",
    "    },\n",
    "    SignalType.ECG_LIKE: {\n",
    "        'ecgHeartbeats': 4,\n",
    "        'ecgWidth': 0.02,   # relative width of QRS peaks\n",
    "    },\n",
    "    SignalType.PIECEWISE_SINE: {\n",
    "        'numSegments': 4,\n",
    "        'ampRange': (0.6, 1.3),\n",
    "        'freqRange': (1.0, 5.0),    # cycles across entire signal\n",
    "        'phaseRange': (0.0, 2 * π),\n",
    "        'trendStrength': 0.2,\n",
    "        'stepProb': 0.25,\n",
    "        'stepScale': 0.8,\n",
    "    },\n",
    "    SignalType.RANDOM_WALK: {\n",
    "        'rwDrift': 0.0,\n",
    "        'rwStepStd': 0.15,\n",
    "    },\n",
    "    SignalType.SAWTOOTH: {\n",
    "        'sawFreq': 4.0,\n",
    "    },\n",
    "    SignalType.STEPS: {\n",
    "        'numSteps': 3,\n",
    "        'stepMin': -1.0,\n",
    "        'stepMax': 1.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Kernel Regression\n",
    "σ = 0.02\n",
    "\n",
    "# Model\n",
    "dataDim = 1\n",
    "attnDim = 32\n",
    "\n",
    "# Training\n",
    "batchSize   = 256\n",
    "numWork     = 2 #<! Number of workers\n",
    "nEpochs     = 10\n",
    "\n",
    "# Visualization\n",
    "numImg = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data\n",
    "\n",
    "Load the [The Street View House Numbers (SVHN) Dataset](http://ufldl.stanford.edu/housenumbers).  \n",
    "It is composed of 73,257 RGB train and 26,032 test images of size `32x32`.  \n",
    "The data is **imbalanced**.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The dataset is retrieved using [Torch Vision](https://pytorch.org/vision/stable/index.html)'s built in datasets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "\n",
    "vT, vC, vSignal = GenSignal(signalType, dSignalParams, seedNum = seedNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Signal\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (7, 7))\n",
    "hA.plot(vT, vC, lw = 2, label = 'Reference Signal')\n",
    "hA.plot(vT, vSignal, lw = 2, alpha = 0.5, label = 'Input Signal')\n",
    "hA.set_xlabel('Time [Sec]')\n",
    "hA.set_ylabel('Signal Amplitude')\n",
    "hA.set_title('Generated Signal')\n",
    "hA.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Regression Smoothing\n",
    "\n",
    "vSignalSmoothed, mA = KernelRegression(vT, vSignal, σ = σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Smoothed Signal\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (7, 7))\n",
    "hA.plot(vT, vC, lw = 2, label = 'Reference Signal')\n",
    "hA.plot(vT, vSignal, lw = 2, alpha = 0.5, label = 'Input Signal')\n",
    "hA.plot(vT, vSignalSmoothed, lw = 2, alpha = 0.8, label = 'Smoothed Signal')\n",
    "hA.set_xlabel('Time [Sec]')\n",
    "hA.set_ylabel('Signal Amplitude')\n",
    "hA.set_title('Kernel Regression Smoothing')\n",
    "hA.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Attention Matrix\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (7, 7))\n",
    "hA.imshow(np.log1p(mA), cmap = 'viridis', aspect = 'auto')\n",
    "hA.set_title('Kernel Regression Affinity Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Symmetric, Attention score is shift invariant for uniformly sampled grid.\n",
    "* <font color='brown'>(**#**)</font> On 1D data sampled uniformly, the output will be equivalent of using FIR filter with Gaussian Kernel weights (Ignoring boundary effects). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "\n",
    "def SinusoidalPosEnc1d( numGridPts: int, dataDim: int, runDevice = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate 1D Sinusoidal Positional Encoding.\n",
    "    \"\"\"\n",
    "\n",
    "    mPosEnc = torch.zeros(numGridPts, dataDim, device = runDevice)\n",
    "    mPos    = torch.arange(numGridPts, device = runDevice).unsqueeze(1)\n",
    "    mFctr   = torch.exp(torch.arange(0, dataDim, 2, device = runDevice) * (-math.log(10000.0) / dataDim))\n",
    "    \n",
    "    mPosEnc[:, 0::2] = torch.sin(mPos * mFctr) #<! Even indices\n",
    "    mPosEnc[:, 1::2] = torch.cos(mPos * mFctr) #<! Odd indices\n",
    "    \n",
    "    return mPosEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self Attention Model\n",
    "\n",
    "class SelfAttention1D(nn.Module):\n",
    "    # Single Head of Scaled Dot Product Attention for 1D token sequences\n",
    "    def __init__(self, dataDim: int, attnDim: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dataDim = dataDim\n",
    "        self.attnDim = attnDim\n",
    "\n",
    "        self.mWq = nn.Linear(dataDim, attnDim, bias = False)\n",
    "        self.mWk = nn.Linear(dataDim, attnDim, bias = False)\n",
    "        self.mWv = nn.Linear(dataDim, 1,       bias = False) #<! Scalar value for smoothing\n",
    "        self.mA  = None #<! Store attention matrix for visualization\n",
    "\n",
    "    def forward(self, mX: Tensor) -> Tensor:\n",
    "        # `mX``: (N, dataDim]\n",
    "        # Calculation is Row Major\n",
    "        mQ = self.mWq(mX) #<! (N, attnDim)\n",
    "        mK = self.mWk(mX) #<! (N, attnDim)\n",
    "        mV = self.mWv(mX) #<! (N, 1)\n",
    "\n",
    "        mA = (mQ @ mK.T) / math.sqrt(self.attnDim) #<! (N, N)\n",
    "        # mA = torch.matmul(mQ, mK.T) / math.sqrt(self.attnDim) #<! (N, N)\n",
    "        mA = torch.softmax(mA, dim = -1)           #<! (N, N)\n",
    "        vY = mA @ mV                               #<! (N, 1)\n",
    "\n",
    "        # Copy values into `self.mA` for visualization (No gradient tracking)\n",
    "        self.mA = mA.detach()\n",
    "        \n",
    "        return vY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Positional Encoding\n",
    "\n",
    "mPe = SinusoidalPosEnc1d(dSignalParams['numSamples'], dataDim = attnDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Positional Encoding  \n",
    "\n",
    "hF, hA = plt.subplots(figsize = (7, 7))\n",
    "hA.imshow(mPe.T, aspect='auto', cmap='viridis')\n",
    "hF.colorbar(hA.imshow(mPe.T, aspect='auto', cmap='viridis'), label='Encoding Value')\n",
    "hA.set_title('Positional Encoding')\n",
    "hA.set_xlabel('Position')\n",
    "hA.set_ylabel('Encoding Dimension');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "mX = torch.concat( (torch.tensor(vSignal).unsqueeze(1).float(), torch.tensor(vT).unsqueeze(1).float()), dim = 1 ) #<! (N, dataDim)\n",
    "\n",
    "mT = np.power(vT[:, None], np.reshape(np.arange(7), (1, -1))) #<! (N, 4)\n",
    "mX = torch.cat((torch.tensor(mT).float(), torch.tensor(vSignal).unsqueeze(1).float()), dim = 1)  #<! (N, 33)\n",
    "\n",
    "# mX = torch.cat((mPe, torch.tensor(vSignal).unsqueeze(1).float()), dim = 1)  #<! (N, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "oModel = SelfAttention1D(dataDim = mX.shape[1], attnDim = attnDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Model Blocks\n",
    "\n",
    "torchvista.trace_model(oModel, mX, forced_module_tracing_depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oModel = SelfAttention1D(dataDim = 2, attnDim = attnDim)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    mZ = oModel(mX)\n",
    "\n",
    "mZ.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oModel.mA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vT, vSignal)\n",
    "plt.plot(vT, mZ.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "oModel = SelfAttention1D(dataDim = mX.shape[1], attnDim = attnDim)\n",
    "\n",
    "numSteps = 50_000\n",
    "logEvery = 1_000\n",
    "learnRate = 3e-4\n",
    "learnRate = 5e-4\n",
    "\n",
    "oOpt  = torch.optim.Adam(oModel.parameters(), lr = learnRate)\n",
    "oSch = torch.optim.lr_scheduler.OneCycleLR(oOpt, max_lr = learnRate, total_steps = numSteps)\n",
    "oLoss = torch.nn.MSELoss()\n",
    "\n",
    "vCC = torch.tensor(vC).unsqueeze(1).float()\n",
    "\n",
    "for ii in range(1, numSteps + 1):\n",
    "    oOpt.zero_grad(set_to_none = True)\n",
    "    mZ = oModel(mX)\n",
    "    valLoss = oLoss(mZ, vCC)\n",
    "    valLoss.backward()\n",
    "    oOpt.step()\n",
    "    oSch.step()\n",
    "\n",
    "    if (ii % logEvery == 0) or (ii == 1):\n",
    "        print(f\"step {ii:4d} | mse {valLoss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    mZ = oModel(mX)\n",
    "\n",
    "plt.plot(vT, vC, label = 'Reference Signal')\n",
    "plt.plot(vT, vSignal, label = 'Input Signal')\n",
    "plt.plot(vT, mZ.detach(), label = 'Smoothed Signal')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mA = oModel.mA.numpy()\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (7, 7))\n",
    "hA.imshow(np.log1p(mA), cmap = 'viridis', aspect = 'auto')\n",
    "hA.set_title('Kernel Regression Affinity Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "# PyTorch \n",
    "dsTrain = torchvision.datasets.SVHN(root = DATA_FOLDER_PATH, split = 'train',  download = True, transform = torchvision.transforms.ToTensor())\n",
    "dsTest  = torchvision.datasets.SVHN(root = DATA_FOLDER_PATH, split = 'test', download = True, transform = torchvision.transforms.ToTensor())\n",
    "lClass  = np.unique(dsTrain.labels)\n",
    "\n",
    "\n",
    "print(f'The training data set data shape: {dsTrain.data.shape}')\n",
    "print(f'The test data set data shape: {dsTest.data.shape}')\n",
    "print(f'The unique values of the labels: {np.unique(lClass)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The dataset is indexible (Subscriptable). It returns a tuple of the features and the label.\n",
    "* <font color='brown'>(**#**)</font> While data is arranged as `H x W x C` the transformer, when accessing the data, will convert it into `C x H x W`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element of the Data Set\n",
    "\n",
    "mX, valY = dsTrain[0]\n",
    "\n",
    "print(f'The features shape: {mX.shape}')\n",
    "print(f'The label value: {valY}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "\n",
    "tX = dsTrain.data #<! NumPy Tensor (NDarray)\n",
    "mX = np.reshape(tX, (tX.shape[0], -1))\n",
    "vY = dsTrain.labels #<! NumPy Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder Data\n",
    "# Data is C x H x W -> H x W x C for displaying\n",
    "mX = np.reshape(mX, (mX.shape[0], *T_IMG_SIZE_SVHN[::-1]))\n",
    "mX = np.transpose(mX, (0, 2, 3, 1))\n",
    "mX = np.reshape(mX, (mX.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "hF = PlotMnistImages(mX, vY, numImg, tuImgSize = T_IMG_SIZE_SVHN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> If data is converted into _grayscale_, how would it effect the performance of the classifier? Explain.  \n",
    "  You may assume the conversion is done using the mean value of the RGB pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY, lClass = L_CLASSES_SVHN);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Explain the given distribution of classes. Think about the origin of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Process Data\n",
    "\n",
    "This section:\n",
    "\n",
    " * Normalizes the data in a predefined manner.\n",
    " * Takes a sub set of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub Set of Data - Indices\n",
    "\n",
    "numCls = len(L_CLASSES_SVHN)\n",
    "mIdxTrain   = np.zeros(shape = (numSamplesPerClsTrain, numCls), dtype = np.int_)\n",
    "mIdxVal     = np.zeros(shape = (numSamplesPerClsVal, numCls), dtype = np.int_)\n",
    "\n",
    "for valCls in range(numCls):\n",
    "    mIdxTrain[:, valCls] = np.random.choice(np.flatnonzero(dsTrain.labels == valCls), size = numSamplesPerClsTrain, replace = False)\n",
    "    mIdxVal[:, valCls] = np.random.choice(np.flatnonzero(dsTest.labels == valCls), size = numSamplesPerClsVal, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub Set of Data - Subset\n",
    "dsTrain = torch.utils.data.Subset(dsTrain, np.ravel(mIdxTrain))\n",
    "dsTest = torch.utils.data.Subset(dsTest, np.ravel(mIdxVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(dsTrain.dataset.labels[dsTrain.indices], lClass = L_CLASSES_SVHN);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "hA = PlotLabelsHistogram(dsTest.dataset.labels[dsTest.indices], lClass = L_CLASSES_SVHN);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Transformer\n",
    "\n",
    "oDataTrns = torchvision.transforms.Compose([    #<! Chaining transformations\n",
    "    torchvision.transforms.ToTensor(),          #<! Convert to Tensor (C x H x W), Normalizes into [0, 1] (https://pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html)\n",
    "    torchvision.transforms.Normalize(0.5, 0.5),\n",
    "    ])\n",
    "\n",
    "# Update the DS transformer\n",
    "dsTrain.transform = oDataTrns\n",
    "dsTest.transform  = oDataTrns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> What does the `Normalize(0.5, 0.5)` do? What are the value boundaries of the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Normalized\" Image\n",
    "\n",
    "mX, valY = dsTrain[5]\n",
    "\n",
    "hF, hA = plt.subplots()\n",
    "hImg = hA.imshow(np.transpose(mX, (1, 2, 0)))\n",
    "hF.colorbar(hImg);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders\n",
    "\n",
    "This section defines the data loaded.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Adjust the size of the actual data set according to performance of the system.\n",
    "* <font color='brown'>(**#**)</font> First tuning and runs of a script might be better done with a small data.  \n",
    "* <font color='brown'>(**#**)</font> Sub sampling the data can be achieved using `torch.utils.data.Subset`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "\n",
    "dlTrain  = torch.utils.data.DataLoader(dsTrain, shuffle = True, batch_size = 1 * batchSize, num_workers = numWork, persistent_workers = True)\n",
    "dlTest   = torch.utils.data.DataLoader(dsTest, shuffle = False, batch_size = 2 * batchSize, num_workers = numWork, persistent_workers = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why is the size of the batch twice as big for the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate on the Loader\n",
    "# The first batch.\n",
    "tX, vY = next(iter(dlTrain)) #<! PyTorch Tensors\n",
    "\n",
    "print(f'The batch features dimensions: {tX.shape}')\n",
    "print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping\n",
    "for ii, (tX, vY) in zip(range(1), dlTest): #<! https://stackoverflow.com/questions/36106712\n",
    "    print(f'The batch features dimensions: {tX.shape}')\n",
    "    print(f'The batch labels dimensions: {vY.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "\n",
    "The model is defined as a sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# Defining a sequential model.\n",
    "\n",
    "numFeatures = np.prod(tX.shape[1:])\n",
    "\n",
    "def BuildModel( activationLyrType: ActivationLayerCls = ActivationLayerCls.RELU, poolLayerType: PoolLayerCls = PoolLayerCls.MAX ) -> nn.Module:\n",
    "\n",
    "    if activationLyrType is ActivationLayerCls.ELU:\n",
    "        ActivationLayer = nn.ELU\n",
    "    elif activationLyrType is ActivationLayerCls.GELU:\n",
    "        ActivationLayer = nn.GELU\n",
    "    elif activationLyrType is ActivationLayerCls.LEAKY_RELU:\n",
    "        ActivationLayer = nn.LeakyReLU\n",
    "    elif activationLyrType is ActivationLayerCls.RELU:\n",
    "        ActivationLayer = nn.ReLU\n",
    "    elif activationLyrType is ActivationLayerCls.SILU:\n",
    "        ActivationLayer = nn.SiLU\n",
    "    else:\n",
    "        raise ValueError(f'The value of `activationLyrType` {activationLyrType} is not supported')\n",
    "    \n",
    "    if poolLayerType is PoolLayerCls.AVERAGE:\n",
    "        PoolLayer = nn.AvgPool2d\n",
    "    elif poolLayerType is PoolLayerCls.MAX:\n",
    "        PoolLayer = nn.MaxPool2d\n",
    "    else:\n",
    "        raise ValueError(f'The value of `poolLayerType` {activationLyrType} is not supported')\n",
    "    \n",
    "    oModel = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        \n",
    "        nn.Conv2d(3,    16, 3, bias = False), nn.BatchNorm2d(16),                ActivationLayer(),\n",
    "        nn.Conv2d(16,   32, 3, bias = False), nn.BatchNorm2d(32),  PoolLayer(2), ActivationLayer(),\n",
    "        nn.Conv2d(32,   64, 3, bias = False), nn.BatchNorm2d(64),  PoolLayer(2), ActivationLayer(),\n",
    "        nn.Conv2d(64,  128, 3, bias = False), nn.BatchNorm2d(128),               ActivationLayer(),\n",
    "        nn.Conv2d(128, 256, 3, bias = False), nn.BatchNorm2d(256),               ActivationLayer(),\n",
    "        \n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256, len(lClass)),\n",
    "    )\n",
    "\n",
    "    return oModel\n",
    "\n",
    "oModel = BuildModel()\n",
    "\n",
    "torchinfo.summary(oModel, tX.shape, col_names = ['kernel_size', 'output_size', 'num_params'], device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why is `bias = False` used above?\n",
    "* <font color='brown'>(**#**)</font> Using a multiplication by 8 number of channels accelerate the run time (In most cases).\n",
    "* <font color='brown'>(**#**)</font> Pay attention to model size and the RAM fo the GPU. Rule of thumb, up to ~40%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "This section trains the model using different schedulers:\n",
    "\n",
    " - Updates the training function to use more features of _TensorBoard_.\n",
    " - Trains the model with different _hyper parameters_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Device\n",
    "\n",
    "runDevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #<! The 1st CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Score Function\n",
    "\n",
    "hL = nn.CrossEntropyLoss()\n",
    "hS = MulticlassAccuracy(num_classes = len(lClass), average = 'micro')\n",
    "hL = hL.to(runDevice) #<! Not required!\n",
    "hS = hS.to(runDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "def TrainModel( oModel: nn.Module, dlTrain: DataLoader, dlVal: DataLoader, oOpt: Optimizer, numEpoch: int, hL: Callable, hS: Callable, oSch: Optional[LRScheduler] = None, oTBWriter: Optional[SummaryWriter] = None) -> Tuple[nn.Module, List, List, List, List]:\n",
    "\n",
    "    lTrainLoss  = []\n",
    "    lTrainScore = []\n",
    "    lValLoss    = []\n",
    "    lValScore   = []\n",
    "    lLearnRate  = []\n",
    "\n",
    "    # Support R2\n",
    "    bestScore = -1e9 #<! Assuming higher is better\n",
    "\n",
    "    learnRate = oOpt.param_groups[0]['lr']\n",
    "\n",
    "    for ii in range(numEpoch):\n",
    "        startTime           = time.time()\n",
    "        trainLoss, trainScr = RunEpoch(oModel, dlTrain, hL, hS, oOpt, opMode = NNMode.TRAIN) #<! Train\n",
    "        valLoss,   valScr   = RunEpoch(oModel, dlVal, hL, hS, oOpt, opMode = NNMode.INFERENCE) #<! Score Validation\n",
    "        if oSch is not None:\n",
    "            # Adjusting the scheduler on Epoch level\n",
    "            learnRate = oSch.get_last_lr()[0]\n",
    "            oSch.step()\n",
    "        epochTime           = time.time() - startTime\n",
    "\n",
    "        # Aggregate Results\n",
    "        lTrainLoss.append(trainLoss)\n",
    "        lTrainScore.append(trainScr)\n",
    "        lValLoss.append(valLoss)\n",
    "        lValScore.append(valScr)\n",
    "        lLearnRate.append(learnRate)\n",
    "\n",
    "        if oTBWriter is not None:\n",
    "            oTBWriter.add_scalars('Loss (Epoch)', {'Train': trainLoss, 'Validation': valLoss}, ii)\n",
    "            oTBWriter.add_scalars('Score (Epoch)', {'Train': trainScr, 'Validation': valScr}, ii)\n",
    "            oTBWriter.add_scalar('Learning Rate (Epoch)', learnRate, ii)\n",
    "\n",
    "            runDevice = next(oModel.parameters()).device\n",
    "            oModel.eval()\n",
    "            lYHat   = []\n",
    "            lY      = []\n",
    "            for jj, (mX, vY) in enumerate(dlVal):\n",
    "                mX = mX.to(runDevice) #<! Lazy\n",
    "\n",
    "                with torch.inference_mode():\n",
    "                    mZ = oModel(mX)\n",
    "                    vYHat = torch.argmax(mZ, dim = 1)\n",
    "                \n",
    "                lYHat.extend(vYHat.cpu().numpy())\n",
    "                lY.extend(vY.numpy())\n",
    "            \n",
    "            vYHat   = np.array(lYHat)\n",
    "            vY      = np.array(lY)\n",
    "\n",
    "            hF, hA = plt.subplots(figsize = (9, 5)) #<! Complex axes, hence `cla()` won't do it\n",
    "            hA, _ = PlotConfusionMatrix(vY, vYHat, hA)\n",
    "            oTBWriter.add_figure('Confusion Matrix (Epoch)', hF, ii, close = True)\n",
    "        \n",
    "        # Display (Babysitting)\n",
    "        print('Epoch '              f'{(ii + 1):4d} / ' f'{numEpoch}:', end = '')\n",
    "        print(' | Train Loss: '     f'{trainLoss          :6.3f}', end = '')\n",
    "        print(' | Val Loss: '       f'{valLoss            :6.3f}', end = '')\n",
    "        print(' | Train Score: '    f'{trainScr           :6.3f}', end = '')\n",
    "        print(' | Val Score: '      f'{valScr             :6.3f}', end = '')\n",
    "        print(' | Epoch Time: '     f'{epochTime          :5.2f}', end = '')\n",
    "\n",
    "        # Save best model (\"Early Stopping\")\n",
    "        if valScr > bestScore:\n",
    "            bestScore = valScr\n",
    "            print(' | <-- Checkpoint!', end = '')\n",
    "            try:\n",
    "                dCheckpoint = {'Model' : oModel.state_dict(), 'Optimizer' : oOpt.state_dict()}\n",
    "                if oSch is not None:\n",
    "                    dCheckpoint['Scheduler'] = oSch.state_dict()\n",
    "                torch.save(dCheckpoint, 'BestModel.pt')\n",
    "            except:\n",
    "                pass\n",
    "        print(' |')\n",
    "    \n",
    "    # Load best model (\"Early Stopping\")\n",
    "    # dCheckpoint = torch.load('BestModel.pt')\n",
    "    # oModel.load_state_dict(dCheckpoint['Model'])\n",
    "\n",
    "    return oModel, lTrainLoss, lTrainScore, lValLoss, lValScore, lLearnRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Some schedulers (For instance `OneCycleLR`) do not allow iterations beyond what is defined.\n",
    "* <font color='brown'>(**#**)</font> Some schedulers are score / loss event driven. See `torch.optim.ReduceLROnPlateau`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Grid\n",
    "\n",
    "dParamGrid = ParameterGrid({'activationLyrType': [ActivationLayerCls.ELU, ActivationLayerCls.GELU, ActivationLayerCls.LEAKY_RELU, ActivationLayerCls.RELU, ActivationLayerCls.SILU], \n",
    "                            'poolLayerType': [PoolLayerCls.AVERAGE, PoolLayerCls.MAX]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "learnRate = 4e-3\n",
    "\n",
    "dModelHist = {}\n",
    "\n",
    "for ii, dModelParams in enumerate(dParamGrid):\n",
    "    print(f'Training with the {(ii + 1): 02d} model parameters combination')\n",
    "    oTBWriter = SummaryWriter(log_dir = os.path.join(TENSOR_BOARD_BASE, f'Model{(ii + 1):03d}'))\n",
    "    oModel = BuildModel(**dModelParams) #<! Just for graphing\n",
    "    oTBWriter.add_graph(oModel, tX) #<! Model Graph\n",
    "    oModel = BuildModel(**dModelParams)\n",
    "    oModel = oModel.to(runDevice) #<! Transfer model to device\n",
    "    oOpt = torch.optim.AdamW(oModel.parameters(), lr = learnRate, betas = (0.9, 0.99), weight_decay = 1e-4) #<! Define optimizer\n",
    "    oScd = torch.optim.lr_scheduler.OneCycleLR(oOpt, max_lr = learnRate, total_steps = nEpochs)\n",
    "    _, lTrainLoss, lTrainScore, lValLoss, lValScore, lLearnRate = TrainModel(oModel, dlTrain, dlTest, oOpt, nEpochs, hL, hS, oScd, oTBWriter)\n",
    "    oTBWriter.add_hparams({'Activation Layer': dModelParams['activationLyrType'].name, 'Pool Layer': dModelParams['poolLayerType'].name}, \n",
    "                          {'Loss (Train)': min(lTrainLoss), 'Score (Train)': max(lTrainScore), 'Loss (Validation)': min(lValLoss), 'Score (Validation)': max(lValScore)})\n",
    "    dModelHist[ii] = lTrainLoss, lTrainScore, lValLoss, lValScore, lLearnRate\n",
    "    oTBWriter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='blue'>(**!**)</font> Plot the data (`dModelHist`) using _MatPlotLib_.\n",
    "* <font color='blue'>(**!**)</font> Add an image of some of mislabeled images. See [PyTorch TensorBoard Tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html).\n",
    "* <font color='blue'>(**!**)</font> Add a PR Curve for the TB result. See [PyTorch TensorBoard Tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearningMethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
