{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Deep Learning Methods </center>\n",
    "## <center> Lecture 07 - PyTorch</center>\n",
    "### <center> PyTorch Basics</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colab users should use GPU runtime:\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/DeepLearningMethods/07_PyTorch/MainPytorchBasics1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful PyTorch tutorials:\n",
    "https://pytorch.org/tutorials/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-- Wide screen:\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#-- Auto reload:\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#-- Imports:\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rc('font', **{'size' : 16})\n",
    "\n",
    "#-- torch:\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tensors\n",
    "Tensors are similar to NumPy’s ndarrays,  \n",
    "Tensors can also be used on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mX = torch.ones(2, 3)\n",
    "mX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.FloatTensor', torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- type, shape & size:\n",
    "mX.type(), mX.shape, mX.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 1],\n",
       "         [1, 1, 1]]),\n",
       " 'torch.LongTensor')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- dytpe = int:\n",
    "mX = torch.ones(2, 3, dtype=int)\n",
    "mX, mX.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.1429, 1.2857, 1.4286, 1.5714, 1.7143, 1.8571, 2.0000, 2.1429,\n",
       "        2.2857, 2.4286, 2.5714, 2.7143, 2.8571, 3.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- To NumPy:\n",
    "vX = torch.linspace(1, 3, 15)\n",
    "vX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.       , 1.1428572, 1.2857143, 1.4285715, 1.5714285, 1.7142857,\n",
       "       1.8571429, 2.       , 2.142857 , 2.2857141, 2.4285715, 2.5714285,\n",
       "       2.7142856, 2.857143 , 3.       ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vX.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Notice the difference between the following two cells:\n",
    "(be careful when initialize a tensor with round numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 5., 6.]), 'torch.FloatTensor')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vX = torch.tensor([1, 2, 5, 6.])\n",
    "vX, vX.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 5, 6]), 'torch.LongTensor')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vX = torch.tensor([1, 2, 5, 6])\n",
    "vX, vX.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Autograd\n",
    "Consider the following function:\n",
    "$$y=f\\left(x\\right)=x^{2}+3$$\n",
    "$$\\implies f'\\left(x\\right)=2x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f = lambda x: x**2 + 3\n",
    "x = torch.tensor(7., requires_grad=True)\n",
    "y = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#-- compute gradients:\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- check that f'(7) = 14:\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider now:\n",
    "$$y=f\\left(\\boldsymbol{x},\\boldsymbol{w}\\right)=\\boldsymbol{w}^{T}\\boldsymbol{x}$$\n",
    "$$\\implies\\nabla_{\\boldsymbol{x}}f=\\boldsymbol{w}$$\n",
    "and\n",
    "$$\\implies\\nabla_{\\boldsymbol{w}}f=\\boldsymbol{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f  = lambda vX, vW: vW[None,:] @ vX[:,None]\n",
    "vX = torch.tensor([1., 3], requires_grad=True)\n",
    "vW = torch.tensor([2., 5], requires_grad=True)\n",
    "y  = f(vX, vW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#-- compute gradients:\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5.])\n",
      "tensor([1., 3.])\n"
     ]
    }
   ],
   "source": [
    "#-- check that:\n",
    "#--     1. ∇xf = w\n",
    "#--     2. ∇wf = x\n",
    "print(vX.grad)\n",
    "print(vW.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why do we need to set to zero the gradients?\n",
    "Let us repeat the code from the cells above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = f(vX, vW)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10.])\n",
      "tensor([2., 6.])\n"
     ]
    }
   ],
   "source": [
    "print(vX.grad)\n",
    "print(vW.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the results are different now.  \n",
    "This is because we did not reset the gradients.  \n",
    "Let us try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vX.grad.data.zero_()\n",
    "vW.grad.data.zero_()\n",
    "\n",
    "y = f(vX, vW)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5.])\n",
      "tensor([1., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(vX.grad)\n",
    "print(vW.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider:\n",
    "$$\\boldsymbol{y}=f\\left(\\boldsymbol{x}\\right)=\\boldsymbol{W}\\boldsymbol{x}$$\n",
    "$$\\implies\\nabla_{\\boldsymbol{x}}f\\left[\\boldsymbol{h}\\right]=\\boldsymbol{W}\\boldsymbol{h}$$\n",
    "$$\\implies\\nabla_{\\boldsymbol{x}}f=\\boldsymbol{W}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since $\\boldsymbol{y}$ is a vector, applying:\n",
    "$$\\boldsymbol{y}\\text{.backward}\\left(\\boldsymbol{h}\\right)$$\n",
    "results in $\\boldsymbol{h}^{T}\\boldsymbol{\\nabla}\\boldsymbol{y}$  \n",
    "(or $\\boldsymbol{h}^{T}\\boldsymbol{\\nabla}f$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f  = lambda mW, vX: mW @ vX\n",
    "vX = torch.tensor([1., 4], requires_grad=True)\n",
    "mW = torch.tensor([[1., 4],\n",
    "                   [2,  1]], requires_grad=True)\n",
    "\n",
    "vY = f(mW, vX)\n",
    "vH = torch.ones(2)\n",
    "vY.backward(vH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 5.])\n",
      "tensor([3., 5.], grad_fn=<SqueezeBackward3>)\n"
     ]
    }
   ],
   "source": [
    "#-- check that:\n",
    "#--     x.grad = h^T @ ∇xf\n",
    "print(vX.grad)\n",
    "print(vH.T @ mW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential model:\n",
    "$$\\hat{\\boldsymbol{y}}=f\\left(\\boldsymbol{x}\\right)=\\boldsymbol{W}_{3}\\sigma\\left(\\boldsymbol{W}_{2}\\sigma\\left(\\boldsymbol{W}_{1}\\boldsymbol{x}+\\boldsymbol{b}_{1}\\right)+\\boldsymbol{b}_{2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 50]                  5,050\n",
      "├─ReLU: 1-2                              [-1, 50]                  --\n",
      "├─Linear: 1-3                            [-1, 25]                  1,275\n",
      "├─ReLU: 1-4                              [-1, 25]                  --\n",
      "├─Linear: 1-5                            [-1, 10]                  250\n",
      "==========================================================================================\n",
      "Total params: 6,575\n",
      "Trainable params: 6,575\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.01\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.03\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oModel = nn.Sequential(\n",
    "    nn.Linear(100, 50), nn.ReLU(), #-- z1 = σ(W1 * x + b1)\n",
    "    nn.Linear(50,  25), nn.ReLU(), #-- z2 = σ(W2 * z1 + b2)\n",
    "    nn.Linear(25,  10, bias=False) #-- y  = W3 * z2\n",
    ")\n",
    "\n",
    "torchsummary.summary(oModel, (100,)); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Custom module (layer)\n",
    "Consider the following architecture:\n",
    "$$\\hat{\\boldsymbol{y}}=f\\left(\\boldsymbol{x}\\right)=\\boldsymbol{W}_{3}\\left(\\sigma_{1}\\left(\\boldsymbol{W}_{1}\\boldsymbol{x}\\right)+\\sigma_{2}\\left(\\boldsymbol{W}_{2}\\boldsymbol{x}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> <img src=\"https://github.com/FixelAlgorithmsTeam/FixelCourses/blob/master/DeepLearningMethods/07_PyTorch/ParallelNetwork.png?raw=true\" alt=\"a\" style=\"width: 500px;\"/> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "since we compute $\\sigma_{1}\\left(\\boldsymbol{W}_{1}\\boldsymbol{x}\\right)$ and $\\sigma_{2}\\left(\\boldsymbol{W}_{2}\\boldsymbol{x}\\right)$ in parallel  \n",
    "this model can not be implemented using sequential model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"https://github.com/FixelAlgorithmsTeam/FixelCourses/blob/master/DeepLearningMethods/07_PyTorch/ParallelNetwork.png?raw=true\" alt=\"a\" style=\"width: 200px;\"/> </center>\n",
    "$$\\hat{\\boldsymbol{y}}=f\\left(\\boldsymbol{x}\\right)=\\boldsymbol{W}_{3}\\left(\\sigma_{1}\\left(\\boldsymbol{W}_{1}\\boldsymbol{x}\\right)+\\sigma_{2}\\left(\\boldsymbol{W}_{2}\\boldsymbol{x}\\right)\\right)$$\n",
    "\n",
    "#### Option I: Define a new (custom) layer:\n",
    "$$\\text{NewLayer}\\left(\\boldsymbol{x}\\right)=\\sigma_{1}\\left(\\boldsymbol{W}_{1}\\boldsymbol{x}\\right)+\\sigma_{2}\\left(\\boldsymbol{W}_{2}\\boldsymbol{x}\\right)$$\n",
    "and then use `nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class NewLayer(nn.Module):\n",
    "    def __init__(self, dIn, dOut):\n",
    "        super(NewLayer, self).__init__() #-- always do this\n",
    "        self.Linear1 = nn.Linear(dIn, dOut, bias=False)\n",
    "        self.Linear2 = nn.Linear(dIn, dOut, bias=False)\n",
    "\n",
    "    def forward(self, mX):\n",
    "        mZ1 = torch.sigmoid(self.Linear1(mX)) #-- σ1(W1 * x)\n",
    "        mZ2 = torch.tanh(self.Linear2(mX))    #-- σ2(W2 * x)\n",
    "        return mZ1 + mZ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─NewLayer: 1-1                          [-1, 50]                  --\n",
      "|    └─Linear: 2-1                       [-1, 50]                  5,000\n",
      "|    └─Linear: 2-2                       [-1, 50]                  5,000\n",
      "├─Linear: 1-2                            [-1, 10]                  500\n",
      "==========================================================================================\n",
      "Total params: 10,500\n",
      "Trainable params: 10,500\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.02\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.04\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oModel = nn.Sequential(\n",
    "    NewLayer(100, 50),            #-- z = σ1(W1 * x) + σ2(W2 * x)\n",
    "    nn.Linear(50, 10, bias=False) #-- y = W3 * z\n",
    ")\n",
    "torchsummary.summary(oModel, (100,)); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\\hat{\\boldsymbol{y}}=f\\left(\\boldsymbol{x}\\right)=\\boldsymbol{W}_{3}\\left(\\sigma_{1}\\left(\\boldsymbol{W}_{1}\\boldsymbol{x}\\right)+\\sigma_{2}\\left(\\boldsymbol{W}_{2}\\boldsymbol{x}\\right)\\right)$$\n",
    "#### Option II: Manually define the architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class ParallelModel(nn.Module):\n",
    "    def __init__(self, dIn, dHidden, dOut):\n",
    "        super(ParallelModel, self).__init__() #-- always do this\n",
    "        self.Linear1 = nn.Linear(dIn,     dHidden, bias=False)\n",
    "        self.Linear2 = nn.Linear(dIn,     dHidden, bias=False)\n",
    "        self.Linear3 = nn.Linear(dHidden, dOut,    bias=False)\n",
    "\n",
    "    def forward(self, mX):\n",
    "        mZ1 = torch.sigmoid(self.Linear1(mX)) #-- σ1(W1 * x)\n",
    "        mZ2 = torch.tanh(self.Linear2(mX))    #-- σ2(W2 * x)\n",
    "        mY  = self.Linear3(mZ1 + mZ2)         #-- W3 * (σ1(W1 * x) + σ2(W2 * x))\n",
    "        return mY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 50]                  5,000\n",
      "├─Linear: 1-2                            [-1, 50]                  5,000\n",
      "├─Linear: 1-3                            [-1, 10]                  500\n",
      "==========================================================================================\n",
      "Total params: 10,500\n",
      "Trainable params: 10,500\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.01\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.04\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oModel = ParallelModel(100, 50, 10)\n",
    "\n",
    "torchsummary.summary(oModel, (100,)); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using GPU\n",
    "To move data to the GPU we use `.cuda()`, or `.to.('cuda')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3708, -2.2602,  0.6343,  0.9463],\n",
       "        [-0.4742,  1.5674, -1.5246,  0.5486]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mX = torch.randn(2, 4).cuda()\n",
    "mX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.1211e-04,  1.2354e+00, -4.9935e-01,  1.7026e-01],\n",
       "        [-9.4099e-01, -6.5428e-01, -4.9636e-01,  1.9003e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mX = torch.randn(2, 4).to('cuda')\n",
    "mX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9882, -0.5427,  0.3424, -0.2295],\n",
       "        [ 0.0432,  0.7909, -1.9155, -0.5075]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Generate data directly inside the GPU\n",
    "mX = torch.randn(2, 4, device='cuda')\n",
    "mX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Move the parameters of the model to the GPU:\n",
    "oModel.to('cuda')\n",
    "next(oModel.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Back to cpu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mX = mX.cpu()\n",
    "#-- or:\n",
    "mX = mX.to('cpu')\n",
    "mX.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The End"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 413,
   "position": {
    "height": "435px",
    "left": "1650px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
