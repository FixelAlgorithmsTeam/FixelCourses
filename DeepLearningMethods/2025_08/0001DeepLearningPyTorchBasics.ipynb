{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Deep Learning Methods\n",
    "\n",
    "## Introduction to Deep Learning - PyTorch Basics\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.004 | 19/09/2025 | Royi Avital | Updated link of Google Colab                                       |\n",
    "| 1.0.003 | 17/09/2025 | Royi Avital | Added example to iterate over parameters                           |\n",
    "| 1.0.002 | 08/05/2025 | Royi Avital | Added a sketch of High Dimensional Tensors                         |\n",
    "| 1.0.001 | 26/04/2025 | Royi Avital | Updated code to match PyTorch 2.5 and 2.6                          |\n",
    "| 1.0.000 | 25/04/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/DeepLearningMethods/2025_08/0001DeepLearningPyTorchBasics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "\n",
    "# Miscellaneous\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, Dict, List, Optional, Self, Set, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    "```python\n",
    "# You need to start writing\n",
    "?????\n",
    "```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "In our days _PyTorch_ is considered to be the _Go To_ Deep Learning framework.\n",
    "\n",
    "![Papers with Code: PyTorch vs. TensorFlow](https://i.imgur.com/BybdtbK.png)\n",
    "![Code Repositories: PyTorch vs. TensorFlow](https://i.imgur.com/z9N8Ywc.png)\n",
    "\n",
    "Source [AssemblyAI - PyTorch vs TensorFlow in 2023](https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2023/).\n",
    "\n",
    "Modern DL framework is composed of the following components:\n",
    "\n",
    " - **Data Structure**  \n",
    "   The container of the multidimensional arrays.\n",
    " - **Layers**  \n",
    "   Set of Mathematical operations on data.  \n",
    "   Built by atoms: Dense, Convolution, Attention, Activations, etc...\n",
    " - **Loss Functions**  \n",
    "   Different objectives for various applications.  \n",
    "   Often used in the \"Heads\" of the net.\n",
    " - **Automatic Differentiation Engine**  \n",
    "   Being able to calculate the Gradients of the computational graph of the net.\n",
    " - **Optimizers & Schedulers**  \n",
    "   Applying update rules on the weights and step size.\n",
    " - **Data Loaders**  \n",
    "   Loading data from storage, unpacking, caching, augmentation phase.\n",
    " - **Dashboard** (Optional)  \n",
    "   A tool to analyze multiple experiments with nets during run time and after.\n",
    " - **Model Zoo** (Optional)  \n",
    "   A set of pre defined architectures and pre trained weights.\n",
    "\n",
    "PyTorch _claim to fame_ is its natural extension to _Python_ with its _dynamic_ (Eager) mode of operation.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Any modern DL framework must support various accelerators: GPU's, TPU's, NPU's, etc...  \n",
    "  The most common accelerator is based on NVIDIA GPU (See [PyTorch `cuda` Backend](https://docs.pytorch.org/docs/stable/cuda.html)).  \n",
    "  PyTorch also supports Intel GPU's (See [PyTorch `xpu` Backend](https://docs.pytorch.org/docs/stable/xpu.html)) and Apple Silicon GPU (See [PyTorch `mps` Backend](https://docs.pytorch.org/docs/stable/mps.html)).\n",
    "* <font color='brown'>(**#**)</font> PyTorch is backed by _Facebook_ from its start.\n",
    "* <font color='brown'>(**#**)</font> PyTorch is originated from _Torch_ which was a DL framework for [Lua Programming Language](https://en.wikipedia.org/wiki/Lua).\n",
    "* <font color='brown'>(**#**)</font> [PyTorch official tutorials](https://pytorch.org/tutorials).\n",
    "* <font color='brown'>(**#**)</font> [PyTorch User Forum](https://discuss.pytorch.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "\n",
    "import torch\n",
    "\n",
    "# Torch Version\n",
    "print(torch.__version__)\n",
    "\n",
    "# Check for CUDA based GPU\n",
    "print(f'CUDA is available to PyTorch: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure\n",
    "\n",
    "PyTorch's native data structure is the Tensor.\n",
    "\n",
    "![PyTorch Tensor](https://i.imgur.com/xnjH0rU.jpeg)\n",
    "\n",
    "From [What Do You Mean by Tensor](https://www.i2tutorials.com/what-do-you-mean-by-tensor-and-explain-about-tensor-datatype-and-ranks).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> [PyTorch Tensor Tutorial](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html).\n",
    "* <font color='brown'>(**#**)</font> The PyTorch's `tensor` is similar to NumPy's `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Vector\n",
    "\n",
    "vX = torch.tensor([0.5, -7.5, 3.25])\n",
    "vX #<! With the default `dtype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Data Initializers\n",
    "\n",
    "mX = torch.ones(2, 3)\n",
    "vX = torch.linspace(1, 3, 15)\n",
    "print(mX)\n",
    "print(vX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Default Type\n",
    "\n",
    "print(mX.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The default of _Torch_ is `Float32` as opposed to _NumPY_ which is `Float64`.\n",
    "* <font color='brown'>(**#**)</font> In our days it is common to use `Float16` (Actually [`BFloat16`](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format)) and even `Float8` (`BFloat16`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported Types\n",
    "vX1 = torch.tensor([1, 2, 5, 6.])\n",
    "vX2 = torch.tensor([1, 2, 5, 6])\n",
    "print(vX1.type())\n",
    "print(vX2.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> You may read on PyTorch's types: [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes of the Tensor\n",
    "mX = torch.rand((2, 3))\n",
    "print(f'mX Shape: {mX.shape}')\n",
    "print(f'mX Size: {mX.size()}') #<! See https://github.com/pytorch/pytorch/issues/5544\n",
    "print(f'mX Size at 1st Dimension: {mX.size(0)}')\n",
    "print(f'mX NumPy Size: {mX.numpy().size}') #<! Convert to Numpy\n",
    "print(f'mX Number of Elements: {mX.numel()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From NumPy\n",
    "mX = torch.from_numpy(np.random.randn(10, 2, 3))\n",
    "mX = torch.tensor(np.random.randn(10, 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors data structure tools for _high dimensional data_:\n",
    "\n",
    "![](https://i.imgur.com/TcrVkkn.png)\n",
    "<!-- ![](https://i.postimg.cc/sgmkscFc/image.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device\n",
    "\n",
    "The _Tensor_ can be generated / transferred into an accelerator.  \n",
    "In our case, a _CUDA Device_ (NVIDIA GPU).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> See the [`torch.cuda` Module](https://pytorch.org/docs/stable/cuda.html).\n",
    "* <font color='brown'>(**#**)</font> See [Check if PyTorch Uses the GPU](https://stackoverflow.com/questions/48152674), [List Available GPU's in PyTorch](https://stackoverflow.com/questions/64776822).\n",
    "* <font color='brown'>(**#**)</font> PyTorch has support for [`MPS Backend`](https://pytorch.org/docs/stable/notes/mps.html) which is the Apple Silicon GPU.  \n",
    "  It is heavily invested yet still not on par with `CUDA`. Its main advantage is less overhead and larger memory.  \n",
    "  See [`torch.mps` Module](https://pytorch.org/docs/stable/mps.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Device\n",
    "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #<! You may use `cuda:0` for the first device\n",
    "print(f'The chosen device: {TORCH_DEVICE}')\n",
    "\n",
    "# MPS:\n",
    "# TORCH_DEVICE = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Data to Device\n",
    "\n",
    "mX = torch.randn(10, 2)\n",
    "print(f'The data device: {mX.device}')\n",
    "mX = mX.to(TORCH_DEVICE) #<! Creates a copy!\n",
    "print(f'The data device: {mX.device}')\n",
    "mX = mX.cpu()\n",
    "print(f'The data device: {mX.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy from GPU\n",
    "# One must make sure the data on CPU before converting into NumPY\n",
    "\n",
    "mX = torch.randn(10, 2, device = TORCH_DEVICE) #<! Generated on GPU\n",
    "print(f'The data device: {mX.device}')\n",
    "# mX = mX.numpy() #<! This will raise an error if `mX`` is on GPU\n",
    "mX = mX.cpu().numpy() #<! Chaining\n",
    "print(f'The data type: {type(mX)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Time - CPU\n",
    "\n",
    "numRows = 10_000\n",
    "numCols = numRows\n",
    "\n",
    "mX1 = torch.randn(numRows, numCols)\n",
    "mX2 = torch.randn(numRows, numCols)\n",
    "\n",
    "startTime = time.time()\n",
    "mX3       = mX1 @ mX2\n",
    "mX3[0, 0] = 1.0\n",
    "endTime   = time.time()\n",
    "\n",
    "print(f'CPU time: {endTime - startTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Time - GPU\n",
    "mX1 = torch.randn(numRows, numCols, device = TORCH_DEVICE)\n",
    "mX2 = torch.randn(numRows, numCols, device = TORCH_DEVICE)\n",
    "mX3 = mX1 @ mX2\n",
    "\n",
    "startTime = time.time()\n",
    "for _ in range(10):\n",
    "    mX3 = mX1 @ mX2\n",
    "torch.cuda.synchronize() #<! To actually measure\n",
    "endTime = time.time()\n",
    "# mX3 = mX3.cpu()\n",
    "\n",
    "print(f'GPU time: {endTime - startTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Time - GPU\n",
    "# More Accurate Method: [How to Measure Run Time in PyTorch](https://discuss.pytorch.org/t/26964)\n",
    "startEvent = torch.cuda.Event(enable_timing = True)\n",
    "endEvent   = torch.cuda.Event(enable_timing = True)\n",
    "\n",
    "mX1 = torch.randn(numRows, numCols, device = TORCH_DEVICE)\n",
    "mX2 = torch.randn(numRows, numCols, device = TORCH_DEVICE)\n",
    "mX3 = mX1 @ mX2\n",
    "\n",
    "startEvent.record()\n",
    "for _ in range(10):\n",
    "    mX3 = mX1 @ mX2\n",
    "endEvent.record()\n",
    "\n",
    "# Waits for everything to finish running\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(f'Run Time: {(startEvent.elapsed_time(endEvent) / 1000.0): 0.3f} [Second]') #<! Like `tic()` and `toc()` in MATLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy & SciPy Functionality\n",
    "\n",
    "PyTorch can be used as a general Linear Algebra + Scientific Computing library accelerated with GPU ot other accelerators.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> See [`torch.fft`](https://pytorch.org/docs/stable/fft.html), [`torch.linalg`](https://pytorch.org/docs/stable/linalg.html), [`torch.signal`](https://pytorch.org/docs/stable/signal.html), [`torch.special`](https://pytorch.org/docs/stable/special.html), [`torch.optim`](https://pytorch.org/docs/stable/optim.html), [`torch.random`](https://pytorch.org/docs/stable/random.html), [`torch.sparse`](https://pytorch.org/docs/stable/sparse.html).\n",
    "* <font color='brown'>(**#**)</font> See [CuPy](https://github.com/cupy/cupy) and [JaX](https://github.com/google/jax).\n",
    "* <font color='brown'>(**#**)</font> [JaX](https://github.com/google/jax) is the backbone of other DL frameworks (Google's spiritual successor of _TensorFlow_).\n",
    "* <font color='brown'>(**#**)</font> Mind the overhead and accuracy (By default `Float32`) when using CUDA devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "numRows = 10\n",
    "numCols = 7 \n",
    "\n",
    "mX = torch.rand(numRows, numCols, device = TORCH_DEVICE)\n",
    "mY = torch.rand(numCols, numCols, device = TORCH_DEVICE)\n",
    "\n",
    "# Accelerated\n",
    "mX @ mY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers & Loss Functions\n",
    "\n",
    "PyTorch has a vast number of layers in the [`torch.nn`](https://pytorch.org/docs/stable/nn.html) module.  \n",
    "The layers have both a _Class_ form and _Function_ (See [`torch.nn.functional`](https://pytorch.org/docs/stable/nn.functional.html)) form.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The layer initialization happens using [`torch.nn.init`](https://pytorch.org/docs/master/nn.init.html).\n",
    "* <font color='brown'>(**#**)</font> [Loss Function as Classes](https://pytorch.org/docs/stable/nn.html#loss-functions), [Loss Functions as Functions](https://pytorch.org/docs/stable/nn.functional.html#loss-functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear (Dense / Fully Connected) Layer\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "# The layer parameters are a Matrix and a Vector.\n",
    "\n",
    "dimIn       = 10\n",
    "dimOut      = 3\n",
    "batchSize   = 4\n",
    "\n",
    "mX = torch.rand(batchSize, dimIn) #<! N x d\n",
    "\n",
    "# Initialization happens in `__init__`\n",
    "oLinLayer = nn.Linear(dimIn, dimOut) #<! Look at `device = `\n",
    "print(f'The Linear Layer weights: {oLinLayer.weight}') #<! Parameter Object (Registered for Computational Graph)\n",
    "print(f'The Linear Layer bias: {oLinLayer.bias}') #<! Parameter Object (Registered for Computational Graph)\n",
    "print(f'The Linear Layer weights array: {oLinLayer.weight.data}') #<! Values (Array in Memory)\n",
    "\n",
    "# Apply (Data in Rows)\n",
    "print(f'Output by `forward()`: {oLinLayer.forward(mX)}') #<! Forward\n",
    "print(f'Output by `call()`: {oLinLayer(mX)[0]}') #<! Call\n",
    "\n",
    "LinearFun = F.linear\n",
    "# No automatic computational graph (`grad_fn=`)\n",
    "print(f'Output by the functional form: {LinearFun(mX, oLinLayer.weight.data, oLinLayer.bias.data)}') #<! Useful for lower overhead for operations with no parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate Over Parameters\n",
    "# May use `oLinLayer.parameters()` or `oLinLayer.named_parameters()`\n",
    "for name, param in oLinLayer.named_parameters():\n",
    "    print(f'Layer Parameter: {name} with shape {param.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Parameters by Name\n",
    "oLinLayer.get_parameter('weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation\n",
    "\n",
    "[_Auto Diff_](https://en.wikipedia.org/wiki/Automatic_differentiation) is the most challenging part of a DL framework.  \n",
    "There 3 main approaches to the design:\n",
    "\n",
    " * Symbolic  \n",
    "   Build the operations in a symbolic way and try solving the gradient.  \n",
    "   Usually it is slow and not scalable.\n",
    "   This is how [Wolfram Mathematica](https://en.wikipedia.org/wiki/Wolfram_Mathematica) works.\n",
    " * Numerically  \n",
    "   Either by [_Finite Difference_](https://en.wikipedia.org/wiki/Finite_difference_method) (Slow) or [_Dual Numbers_](https://en.wikipedia.org/wiki/Dual_number).\n",
    " * Computational Graph & Overloading / Code Transform  \n",
    "   Those are the most advanced approaches as they proved to be fast and scalable.\n",
    "\n",
    "PyTorch implements _Automatic Differentiation_ in [`torch.autograd`](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Function\n",
    "# The function could be `def` style function or a Lambda function.\n",
    "# It should be Rn -> R function.\n",
    "\n",
    "def MadeUpFun( vX: torch.Tensor, vW: torch.Tensor ) -> torch.FloatType:\n",
    "\n",
    "    return torch.pow(torch.dot(vX, vW), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "numElm = 5\n",
    "\n",
    "# Using `requires_grad` to make PyTorch build the graph\n",
    "vX = torch.tensor([1.4, 3.2], requires_grad = True) #<! The `requires_grad = False` is the default\n",
    "vW = torch.tensor([2.3, 5.1], requires_grad = True)\n",
    "\n",
    "valY = MadeUpFun(vX, vW) #<! Build the Computational Graph\n",
    "valY.backward() #<! Back Propagation\n",
    "\n",
    "# ∇xf = 2 w' * x * w\n",
    "# ∇wf = 2 w' * x * x\n",
    "print(vX.grad)\n",
    "print(vW.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _Computational Graph_ is updated with any operation.  \n",
    "Hence, it should be reset if the operation it to be redone.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without a Reset\n",
    "\n",
    "valY = MadeUpFun(vX, vW) #<! Build the Computational Graph\n",
    "valY.backward() #<! Back Propagation\n",
    "\n",
    "# ∇xf = 2 w' * x * w\n",
    "# ∇wf = 2 w' * x * x\n",
    "print(vX.grad)\n",
    "print(vW.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Gradients are accumulated per iteration.  \n",
    "  It is motivated to allow multiple iterations before applying optimization step and / or by using multiple GPU's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Gradients\n",
    "\n",
    "vX.grad.data.zero_() #<! Inplace \n",
    "vW.grad.data.zero_() #<! Inplace\n",
    "\n",
    "valY = MadeUpFun(vX, vW) #<! Build the Computational Graph\n",
    "valY.backward() #<! Back Propagation\n",
    "\n",
    "# ∇xf = 2 w' * x * w\n",
    "# ∇wf = 2 w' * x * x\n",
    "print(vX.grad)\n",
    "print(vW.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> Leaf, the starting points of the graph, can not be changed in place.\n",
    "* <font color='brown'>(**#**)</font> PyTorch is optimized for the case the output of the _computational graph_ is a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detaching from Graph\n",
    "\n",
    "An object can be detached (A view) from the  graph by using [`.torch.Tensor.detach()`](https://pytorch.org/docs/stable/generated/torch.Tensor.detach.html).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> See [`torch.clone()`](https://pytorch.org/docs/stable/generated/torch.clone.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detach an Object\n",
    "vXDetach = vX.detach()\n",
    "vS = torch.square(vXDetach) #<! No graph / gradient\n",
    "valY = MadeUpFun(vS, vW)\n",
    "valY.backward()\n",
    "print(vS.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition of Operations\n",
    "\n",
    "Using the _atoms_ one can build a composed operation where PyTorch will create its computational graph automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model\n",
    "\n",
    "This section implements a composition of mathematical operations using [PyTorch Sequential Model](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
    "\n",
    "$$\\hat{\\boldsymbol{y}} = f \\left( \\boldsymbol{x} \\right) = \\boldsymbol{W}_{3} \\sigma \\left( \\boldsymbol{W}_{2} \\sigma \\left( \\boldsymbol{W}_{1} \\boldsymbol{x} + \\boldsymbol{b}_{1} \\right) + \\boldsymbol{b}_{2} \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model\n",
    "\n",
    "oModel = nn.Sequential(\n",
    "    nn.Identity(),                              #<! For the summary (Shows the input)\n",
    "    nn.Linear(100, 50),              nn.ReLU(), #<! z1 = σ(W1 * x + b1)\n",
    "    nn.Linear(50,  25),              nn.ReLU(), #<! z2 = σ(W2 * z1 + b2)\n",
    "    nn.Linear(25,  10, bias = False)            #<! y  = W3 * z2 (No Bias)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Device\n",
    "print(f'The model device: {next(oModel.parameters()).device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "# In order to see the model summary once must supply an input.\n",
    "\n",
    "numSamples  = 16\n",
    "dataDim     = 100\n",
    "\n",
    "torchinfo.summary(oModel, input_size = (numSamples, dataDim), device = 'cpu') #<! By default tries on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Device\n",
    "print(f'The model device: {next(oModel.parameters()).device}') #<! Checks the first, assumes all on the same GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model\n",
    "# No need for computational graph\n",
    "\n",
    "# https://pytorch.org/docs/2.3/notes/autograd.html#evaluation-mode-nn-module-eval\n",
    "oModel.eval() #<! Evaluation / Inference mode (for layers which requires it)\n",
    "\n",
    "mX = torch.rand(numSamples, dataDim, requires_grad = False)\n",
    "\n",
    "# https://pytorch.org/docs/2.3/notes/autograd.html#inference-mode\n",
    "with torch.inference_mode():\n",
    "    mY = oModel(mX)\n",
    "\n",
    "# `no_grad()` vs. `inference_mode()`: https://stackoverflow.com/questions/74191070\n",
    "# with torch.no_grad():\n",
    "#     mY = oModel(mX)\n",
    "\n",
    "print(mY)\n",
    "print(mY.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model\n",
    "# Selective calculation of the gradient.\n",
    "\n",
    "oModel = nn.Sequential(\n",
    "    nn.Identity(),                            #<! For the summary (Shows the input)\n",
    "    nn.Linear(100, 50),            nn.ReLU(), #<! z1 = σ(W1 * x + b1)\n",
    "    nn.Linear(50,  25),            nn.ReLU(), #<! z2 = σ(W2 * z1 + b2)\n",
    "    nn.Linear(25,  10, bias = False)          #<! y  = W3 * z2\n",
    "    )\n",
    "\n",
    "# https://pytorch.org/docs/2.3/notes/autograd.html#evaluation-mode-nn-module-eval\n",
    "oModel.eval() #<! Evaluation / Inference mode (for layers which requires it)\n",
    "for p in oModel.parameters():\n",
    "    # Disable the gradient calculation per parameter\n",
    "    # Could be achieved with `no_grad` context (https://pytorch.org/docs/stable/generated/torch.no_grad.html)\n",
    "    p.requires_grad_(False)\n",
    "    # p.requires_grad\n",
    "\n",
    "# Equivalent\n",
    "# oModel.requires_grad_(False)\n",
    "\n",
    "mX = torch.rand(numSamples, dataDim, requires_grad = False)\n",
    "mY = oModel(mX)\n",
    "\n",
    "print(mY)\n",
    "print(mY.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Composition\n",
    "\n",
    "This section implements a module (`torch.nn`) based on the function:\n",
    "\n",
    "$$\\hat{\\boldsymbol{y}}=f\\left(\\boldsymbol{x}\\right)=\\boldsymbol{W}_{3}\\left(\\sigma_{1}\\left(\\boldsymbol{W}_{1}\\boldsymbol{x}\\right)+\\sigma_{2}\\left(\\boldsymbol{W}_{2}\\boldsymbol{x}\\right)\\right)$$\n",
    "\n",
    "<center> <img src=\"https://media.githubusercontent.com/media/FixelAlgorithmsTeam/FixelCourses/refs/heads/master/DeepLearningMethods/2023_02/05_PyTorch/ParallelNetwork.png\" style=\"width: 500px;\"/></center>\n",
    "\n",
    "By its architecture, it can not be implemented as a sequential model.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Actually if there a module which implements the parallel section it can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option I - Custom Layer\n",
    "\n",
    "Define a new layer operation\n",
    "\n",
    "$$\\text{NewLayer}\\left(\\boldsymbol{x}\\right)=\\sigma_{1}\\left(\\boldsymbol{W}_{1}\\boldsymbol{x}\\right)+\\sigma_{2}\\left(\\boldsymbol{W}_{2}\\boldsymbol{x}\\right)$$\n",
    "\n",
    "Which will be used in a sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NewLayer\n",
    "\n",
    "class NewLayer(nn.Module):\n",
    "    def __init__( self, dIn: int, dOut: int ) -> None:\n",
    "        \n",
    "        super().__init__() #<! Do this to get all initialization of Layer\n",
    "        self.oLinear1 = nn.Linear(dIn, dOut, bias = False)\n",
    "        self.oLinear2 = nn.Linear(dIn, dOut, bias = False)\n",
    "\n",
    "    def forward( self, mX: torch.Tensor ) -> torch.Tensor:\n",
    "        \n",
    "        mZ1 = torch.relu(self.oLinear1(mX)) #<! σ1(W1 * x)\n",
    "        mZ2 = torch.relu(self.oLinear2(mX)) #<1 σ2(W2 * x)\n",
    "\n",
    "        return mZ1 + mZ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why is the `backward()` method missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model\n",
    "\n",
    "oModel = nn.Sequential(\n",
    "    NewLayer (100, 50),              #<! z = σ1(W1 * x) + σ2(W2 * x)\n",
    "    nn.Linear(50,  10, bias = False) #<! y = W3 * z\n",
    ")\n",
    "\n",
    "torchinfo.summary(oModel, (16, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Device\n",
    "print(f'The model device: {next(oModel.parameters()).device}') #<! GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option II - Complete Architecture\n",
    "\n",
    "This will build a net which implements the whole architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net Model\n",
    "\n",
    "class ParallelModel(nn.Module):\n",
    "    def __init__( self, dIn: int, dHidden: int, dOut: int ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.oLinear1 = nn.Linear(dIn, dHidden, bias = False)  #<! W1\n",
    "        self.oLinear2 = nn.Linear(dIn, dHidden, bias = False)  #<! W2\n",
    "        self.oLinear3 = nn.Linear(dHidden, dOut, bias = False) #<! W3\n",
    "\n",
    "    def forward( self, mX: torch.Tensor ) -> torch.Tensor:\n",
    "        \n",
    "        mZ1 = torch.sigmoid(self.oLinear1(mX)) #<! σ1(W1 * x)\n",
    "        mZ2 = torch.tanh(self.oLinear2(mX))    #<! σ2(W2 * x)\n",
    "        mY  = self.oLinear3(mZ1 + mZ2)         #<! W3 * (σ1(W1 * x) + σ2(W2 * x))\n",
    "        \n",
    "        return mY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net Model\n",
    "\n",
    "oModel = ParallelModel(100, 50, 10)\n",
    "\n",
    "torchinfo.summary(oModel, (16, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='green'>(**@**)</font> Build a _Logistic Regression_ classifier using PyTorch (Binary Classification)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIProgram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
