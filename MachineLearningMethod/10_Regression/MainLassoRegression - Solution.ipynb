{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Machine Learning Methods </center>\n",
    "## <center> Lecture 10 - Regression</center>\n",
    "### <center> Regression and LASSO Regularization - Solution</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/MachineLearningMethod/10_Regression/MainLassoRegression1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rc('font', **{'size' : 16})\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(vX):\n",
    "    return 2/3 * vX**2 + 2*vX + 5\n",
    "\n",
    "N  = 30\n",
    "vX = np.linspace(-2, 2, N, endpoint=True) + np.random.randn(N) / 20   \n",
    "vY = f(vX) + np.random.randn(N) / 3\n",
    "\n",
    "#-- Plot:\n",
    "plt.figure()\n",
    "plt.plot(vX, vY, '.r', markersize=10, label=r'$y_i = \\frac{2}{3}x_i^2 + 2x_i + 5 + \\epsilon_i$')\n",
    "plt.xlabel('$x$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "lAxis = plt.axis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Lasso funciton:\n",
    "$$\\arg\\min_{\\boldsymbol{w},b}\\left\\Vert \\boldsymbol{y}-\\boldsymbol{\\Phi}\\boldsymbol{w}-b\\right\\Vert _{2}^{2}+\\lambda\\left\\Vert \\boldsymbol{w}\\right\\Vert _{1}$$\n",
    "where:\n",
    "$$\\boldsymbol{\\Phi}=\\left[\\begin{matrix}x_{1} & x_{1}^{2} & \\cdots & x_{1}^{P}\\\\\n",
    "x_{2} & x_{2}^{2} & \\cdots & x_{2}^{P}\\\\\n",
    "\\vdots & \\vdots &  & \\vdots\\\\\n",
    "x_{N} & x_{N}^{2} & \\cdots & x_{N}^{P}\n",
    "\\end{matrix}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model  import Lasso\n",
    "from sklearn.metrics       import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def PlotRegression(lam):\n",
    "    P = 15\n",
    "\n",
    "    if lam == 0:\n",
    "        vW  = np.polyfit(vX, vY, P)\n",
    "    else:\n",
    "        #-- Apply Lasso:\n",
    "#         mX   = np.c_[[vX**p for p in range(1, P+1)]].T\n",
    "        mX   = PolynomialFeatures(degree=P, include_bias=False).fit_transform(vX[:,None])\n",
    "        oMdl = Lasso(alpha=lam, fit_intercept=True, max_iter=20000).fit(mX, vY)\n",
    "        vW   = np.r_[oMdl.coef_[::-1], oMdl.intercept_]\n",
    "#         print(vW)\n",
    "\n",
    "    #-- R2 score:\n",
    "    vHatY = np.polyval(vW, vX)\n",
    "    R2    = r2_score(vY, vHatY)\n",
    "        \n",
    "    #-- Plot:\n",
    "    x = np.linspace(lAxis[0], lAxis[1], 1001)\n",
    "    y = np.polyval(vW, x)\n",
    "\n",
    "    _, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    ax[0].plot(vX, vY, '.r', markersize=10)\n",
    "    ax[0].plot(x,  y,  'b',  lw=2)\n",
    "    ax[0].axis(lAxis)\n",
    "    ax[0].grid(True)\n",
    "    ax[0].set_title(f'$\\lambda = {lam}$\\n$R^2 = {R2}$')\n",
    "    \n",
    "    ax[1].stem(vW[::-1], use_line_collection=True)\n",
    "    ax[1].set_title('Coefficients')\n",
    "    ax[1].set_xlabel('$w$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Lasso regularization promotes sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec630ea0fdeb4baaaea20ba1ad35bd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='lam', layout=Layout(width='80%'), max=1.0, step=0.00â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, FloatSlider, Layout\n",
    "\n",
    "lamSlider = FloatSlider(min=0, max=1, step=0.001, value=0, layout=Layout(width='80%'))\n",
    "interact(PlotRegression, lam=lamSlider)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "* Use the Boston house-prices dataset.\n",
    "* Use cross-validation with $K=20$.\n",
    "* Try to achieve the best R2 score you can.\n",
    "* Hint 1:\n",
    "    * Use `sklearn.preprocessing.PolynomialFeatures` to obtain polynomial features.\n",
    "    * Use `sklearn.linear_model.LinearRegression` to compute a linear regressor model.\n",
    "    * Use `cross_val_predict` instead of `cross_val_score` when performing regression.\n",
    "* Hint 2: consider to normalize your features (and data),  \n",
    "that is, zero mean and unit variance.\n",
    "\n",
    "* Which value of $P$ provides the best result?  \n",
    "Did you use regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Boston house-prices dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "dData = sklearn.datasets.load_boston()\n",
    "print(dData.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mX = dData.data\n",
    "vY = dData.target\n",
    "\n",
    "mX.shape, vY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us try regression (without regularization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.406318e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.235415e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.641390e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     P            R2\n",
       "1  2.0  8.406318e-01\n",
       "0  1.0  7.235415e-01\n",
       "2  3.0 -2.641390e+10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing   import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "\n",
    "mX = mX - np.mean(mX, axis=0)\n",
    "mX = mX / np.std(mX,  axis=0)\n",
    "\n",
    "#-- Cross validation regression with Lasso:\n",
    "dRes   = pd.DataFrame(columns=['P', 'R2'])\n",
    "for P in [1, 2, 3]:\n",
    "    mPhi                = PolynomialFeatures(P, include_bias=False).fit_transform(mX)\n",
    "    mPhi                = mPhi - np.mean(mPhi, axis=0)\n",
    "    mPhi[:,1:]          = mPhi[:,1:] / np.std(mPhi[:,1:], axis=0)\n",
    "    vHatY               = cross_val_predict(LinearRegression(), mPhi, vY, cv=KFold(20, shuffle=True))\n",
    "    dRes.loc[len(dRes)] = [P, r2_score(vY, vHatY)]\n",
    "\n",
    "dRes.sort_values(by='R2', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us try regression (with regularization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>lam</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.888895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.888699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.887537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.883055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.881731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.045409</td>\n",
       "      <td>0.881324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.880485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.055317</td>\n",
       "      <td>0.873873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.872479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.872095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.871778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.067386</td>\n",
       "      <td>0.870539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.868030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.867900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.866987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>0.866679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.866422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.082089</td>\n",
       "      <td>0.865249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.865037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>0.861797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.860273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.045409</td>\n",
       "      <td>0.859171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.858536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.067386</td>\n",
       "      <td>0.855389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.055317</td>\n",
       "      <td>0.853564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.851430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.082089</td>\n",
       "      <td>0.849107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.844677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.840050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>0.721635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045409</td>\n",
       "      <td>0.721549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.721355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.721291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.720386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.719166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.718769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.718468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.718269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.717513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.082089</td>\n",
       "      <td>0.715724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055317</td>\n",
       "      <td>0.715260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067386</td>\n",
       "      <td>0.714214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.714094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.707277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      P       lam        R2\n",
       "36  3.0  0.020620  0.888895\n",
       "37  3.0  0.025119  0.888699\n",
       "35  3.0  0.016927  0.887537\n",
       "38  3.0  0.030599  0.883055\n",
       "34  3.0  0.013895  0.881731\n",
       "40  3.0  0.045409  0.881324\n",
       "39  3.0  0.037276  0.880485\n",
       "41  3.0  0.055317  0.873873\n",
       "18  2.0  0.011406  0.872479\n",
       "16  2.0  0.007686  0.872095\n",
       "31  3.0  0.007686  0.871778\n",
       "42  3.0  0.067386  0.870539\n",
       "20  2.0  0.016927  0.868030\n",
       "23  2.0  0.030599  0.867900\n",
       "24  2.0  0.037276  0.866987\n",
       "32  3.0  0.009363  0.866679\n",
       "21  2.0  0.020620  0.866422\n",
       "43  3.0  0.082089  0.865249\n",
       "22  2.0  0.025119  0.865037\n",
       "19  2.0  0.013895  0.863034\n",
       "17  2.0  0.009363  0.861797\n",
       "44  3.0  0.100000  0.860273\n",
       "25  2.0  0.045409  0.859171\n",
       "15  2.0  0.006310  0.858536\n",
       "27  2.0  0.067386  0.855389\n",
       "26  2.0  0.055317  0.853564\n",
       "33  3.0  0.011406  0.851430\n",
       "28  2.0  0.082089  0.849107\n",
       "29  2.0  0.100000  0.844677\n",
       "30  3.0  0.006310  0.840050\n",
       "2   1.0  0.009363  0.721635\n",
       "10  1.0  0.045409  0.721549\n",
       "0   1.0  0.006310  0.721355\n",
       "4   1.0  0.013895  0.721291\n",
       "1   1.0  0.007686  0.720386\n",
       "9   1.0  0.037276  0.719166\n",
       "7   1.0  0.025119  0.718769\n",
       "6   1.0  0.020620  0.718468\n",
       "8   1.0  0.030599  0.718269\n",
       "5   1.0  0.016927  0.717513\n",
       "13  1.0  0.082089  0.715724\n",
       "11  1.0  0.055317  0.715260\n",
       "12  1.0  0.067386  0.714214\n",
       "3   1.0  0.011406  0.714094\n",
       "14  1.0  0.100000  0.707277"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#-- Cross validation regression with Lasso:\n",
    "vLam   = np.logspace(-2.2, -1, 15)\n",
    "dRes   = pd.DataFrame(columns=['P', 'lam', 'R2'])\n",
    "for P in [1, 2, 3]:\n",
    "    for lam in vLam:\n",
    "        mPhi                = PolynomialFeatures(P, include_bias=False).fit_transform(mX)\n",
    "        mPhi                = mPhi - np.mean(mPhi, axis=0)\n",
    "        mPhi                = mPhi / np.std(mPhi,  axis=0)\n",
    "        vHatY               = cross_val_predict(Lasso(alpha=lam, max_iter=10000), mPhi, vY, cv=KFold(20, shuffle=True))\n",
    "        dRes.loc[len(dRes)] = [P, lam, r2_score(vY, vHatY)]\n",
    "\n",
    "dRes.sort_values(by='R2', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
