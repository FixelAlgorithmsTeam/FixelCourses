{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Optimization Methods\n",
    "\n",
    "## Convex Optimization - Constraint Optimization - Least Squares with Equality Constraints\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.001 | 04/12/2024 | Royi Avital | Added the $\\frac{1}{2}$ factor to the LS formulation               |\n",
    "| 1.0.000 | 27/09/2024 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0012LinearFitL1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "# Optimization\n",
    "import autograd.numpy as anp\n",
    "import autograd.scipy as asp\n",
    "from autograd import grad\n",
    "import cvxpy as cp\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import math\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "vallToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    "```python\n",
    "# You need to start writing\n",
    "?????\n",
    "```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "# sns.set_palette(\"tab10\")\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "from AuxFun import ConvMode\n",
    "from AuxFun import ProxGradientDescent\n",
    "from AuxFun import GenConvMtx1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "numCoeff    = 11\n",
    "numSamples  = 110\n",
    "noiseStd    = 0.005\n",
    "convMode    = ConvMode.VALID\n",
    "\n",
    "\n",
    "# Solver\n",
    "μ             = 0.001 #<! Step Size\n",
    "numIterations = 2500\n",
    "\n",
    "# Verification\n",
    "ε      = 1e-6 #<! Error threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares (Linear Fit) with Equality Constraints\n",
    "\n",
    "The _Linear Fit_ / _Least Squares_ with Equality Constraints is given by:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\arg \\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2} {\\left\\| \\boldsymbol{A} \\boldsymbol{x} - \\boldsymbol{b} \\right\\|}_{2}^{2} \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\boldsymbol{C} \\boldsymbol{x} & = \\boldsymbol{d} \\\\\n",
    "\\end{aligned}\n",
    "\\end{align}$$\n",
    "\n",
    "## Least Squares with Sum Constraints\n",
    "\n",
    "An _High Pass Filter_ (HPF) is a filter decays low frequencies.  \n",
    "A simplistic way to force an HPF is to force it will vanish the DC component.  \n",
    "This can be done by forcing the sum of its coefficients to be zero.\n",
    "\n",
    "This notebook deals with estimating an High Pass Filter (HPF) using Projected Gradient Descent.  \n",
    "The problems equivalent to a Least Squares problem with a linear equality constraint.\n",
    "\n",
    "This notebook shows how to solve the problem:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\arg \\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2} {\\left\\| \\boldsymbol{A} \\boldsymbol{x} - \\boldsymbol{b} \\right\\|}_{2}^{2} \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\sum {x}_{i} & = 0 \\\\\n",
    "\\end{aligned}\n",
    "\\end{align}$$\n",
    "\n",
    "The notebook:\n",
    "\n",
    " - Calculates a solution using DCP Solver (Reference).\n",
    " - Calculates a solution using _Projected Gradient Descent_.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Constraints are useful for undetermined case where the number of solutions is infinite.\n",
    "* <font color='red'>(**?**)</font> Formulate the constraint as a dot product (Vector).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data model is a stream of samples going through an LTI system.  \n",
    "In our case the LTI system is built by an HPF filter:\n",
    "\n",
    "$$ \\boldsymbol{y} = \\operatorname{conv} \\left( \\boldsymbol{x}, \\boldsymbol{h} \\right) + \\boldsymbol{n} $$\n",
    "\n",
    "Where:\n",
    " - $\\boldsymbol{x}$ - The data samples.\n",
    " - $\\boldsymbol{h}$ - The filter coefficients.\n",
    " - $\\boldsymbol{n}$ - The white noise samples (AWGN).\n",
    "\n",
    "Since the model is linear is can be written in a matrix form:\n",
    "\n",
    "$$ \\boldsymbol{y} = \\boldsymbol{X} \\boldsymbol{h} + \\boldsymbol{n} $$\n",
    "\n",
    "Where $\\boldsymbol{X}$ is the convolution matrix form of the samples.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Since the model is a convolution (LTI) system, the matrix $\\boldsymbol{X}$ is a [Toeplitz Matrix](https://en.wikipedia.org/wiki/Toeplitz_matrix).\n",
    "* <font color='brown'>(**#**)</font> Read on [`numpy.convolve()`](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html) and [`scipy.signal.convolve()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve.html). Pay attention to the `method` option in [`scipy.signal.convolve()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve.html).\n",
    "* <font color='brown'>(**#**)</font> Unlike MATLAB, [`numpy.convolve()`](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html), is commutative for the case of `valid` and `same`. The reason is the switch the signals so the kernel is always the shorter one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate / Load the Data\n",
    "\n",
    "vX = sp.signal.sawtooth(range(numSamples))\n",
    "for ii in range(2, 11):\n",
    "    vX = vX + sp.signal.sawtooth(range(ii, numSamples + ii))\n",
    "\n",
    "# High Pass Filter (HPF): Zero mean.\n",
    "vHRef  = np.random.randn(numCoeff)\n",
    "vHRef -= np.mean(vHRef) #<! Zero Mean -> High Pass Filter (Though the worst one!)\n",
    "\n",
    "numSamplesY = numSamples - numCoeff + 1; #<! Output of the output ov `valid` convolution\n",
    "\n",
    "vN = noiseStd * np.random.randn(numSamplesY)\n",
    "vY = np.convolve(vX, vHRef, 'valid') + vN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Analysis\n",
    "\n",
    "mH = np.zeros(shape = (numCoeff, numIterations)) #<! Initialization is the zero vector\n",
    "vObjVal = np.zeros(numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Data\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (12, 6))\n",
    "hA.plot(range(numSamplesY), vY, lw = 2, label = 'Samples')\n",
    "hA.set_xlabel('Sample Index')\n",
    "hA.set_ylabel('Sample Value')\n",
    "hA.set_title('Measured Data')\n",
    "\n",
    "hA.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Matrix\n",
    "\n",
    "This section transforms the data $\\boldsymbol{x}$ (`vX`) into a convolution matrix $\\boldsymbol{X}$ (`mX`) such that $\\boldsymbol{y} \\approx \\boldsymbol{X} \\boldsymbol{h}$ (`vY ≈ mX @ vHRef`).\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The problem can be solved without generating the explicit matrices using operators.\n",
    "* <font color='red'>(**?**)</font> If $\\boldsymbol{X}$ stands for the convolution operator. What's the meaning of the adjoint $\\boldsymbol{X}^{T}$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Matrix\n",
    "\n",
    "mX = GenConvMtx1D(vX, numCoeff, convMode = convMode)\n",
    "\n",
    "assertCond = np.linalg.norm(mX @ vHRef - np.convolve(vX, vHRef, 'valid'), np.inf) <= ε\n",
    "assert assertCond, f'The matrix convolution deviation exceeds the threshold {ε}'\n",
    "print('The matrix convolution implementation is verified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "\n",
    "The objective function:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\arg \\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2} {\\left\\| \\boldsymbol{h} \\ast \\boldsymbol{x} - \\boldsymbol{y} \\right\\|}_{2}^{2} \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\sum {h}_{i} & = 0 \\\\\n",
    "\\end{aligned}\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "* <font color='red'>(**?**)</font> Write the problem in a matrix form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function\n",
    "\n",
    "hObjFun = lambda vH: 0.5 * np.sum(np.square(np.convolve(vX, vH, 'valid') - vY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Function\n",
    "\n",
    "The gradient of the objective can be derived from the matrix form of the problem. \n",
    "\n",
    "* <font color='red'>(**?**)</font> Derive the gradient of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gradient Function\n",
    "\n",
    "hGradFun   = lambda vH: mX.T @ (mX @ vH - vY)\n",
    "# Auto Grad only support SciPy's `convolve()`\n",
    "hAutoGradF = grad(lambda vH: (0.5 * anp.sum(anp.square(asp.signal.convolve(vX, anp.array(vH), mode = 'valid') - anp.array(vY)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vT = np.random.randn(numCoeff)\n",
    "\n",
    "vG = hAutoGradF(vT)\n",
    "assertCond = np.linalg.norm(hGradFun(vT) - vG, np.inf) <= (ε * np.linalg.norm(vG))\n",
    "assert assertCond, f'The gradient calculation deviation exceeds the threshold {ε}'\n",
    "\n",
    "print('The gradient implementation is verified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection Function\n",
    "\n",
    "The projection function should project a vector onto the set $\\mathcal{H} = \\left\\{ \\boldsymbol{h} \\mid \\boldsymbol{h}^{T} \\boldsymbol{1} = 0 \\right\\}$.\n",
    "\n",
    "The projection function is the solution of the following optimization problem:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\arg \\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2} {\\left\\| \\boldsymbol{x} - \\boldsymbol{y} \\right\\|}_{2}^{2} \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\boldsymbol{x}^{T} \\boldsymbol{1} & = 0 \\\\\n",
    "\\end{aligned}\n",
    "\\end{align}$$\n",
    "\n",
    "* <font color='red'>(**?**)</font> Derive the projection function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Projection Function\n",
    "\n",
    "hProjFun = lambda vY, λ: vY - np.mean(vY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection Function\n",
    "# This section verify the projection function using CVX\n",
    "\n",
    "# Model Data\n",
    "vXX = cp.Variable(numCoeff)\n",
    "vYY = np.random.randn(numCoeff)\n",
    "\n",
    "# Model Problem\n",
    "cpObjFun = cp.Minimize(0.5 * cp.sum_squares(vXX - vYY)) #<! Objective Function\n",
    "cpConst = [cp.sum(vXX) == 0] #<! Constraints\n",
    "oCvxPrb = cp.Problem(cpObjFun, cpConst) #<! Problem\n",
    "\n",
    "oCvxPrb.solve(solver = cp.CLARABEL)\n",
    "\n",
    "assert (oCvxPrb.status == 'optimal'), 'The problem is not solved.'\n",
    "print('Problem is solved.')\n",
    "\n",
    "assertCond = np.linalg.norm(vXX.value - hProjFun(vYY, 0.0), np.inf) <= (ε * np.linalg.norm(vXX.value))\n",
    "assert assertCond, f'The projection calculation deviation exceeds the threshold {ε}'\n",
    "\n",
    "print('The projection implementation is verified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected Gradient Descent\n",
    "\n",
    "The _Projected Gradient Descent_ is a generalization of the _Gradient Descent_ method for the case:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\arg \\min_{\\boldsymbol{x}} \\quad & f \\left( \\boldsymbol{x} \\right) \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\boldsymbol{x} & \\in \\mathcal{C} \\\\\n",
    "\\end{aligned}\n",
    "\\end{align}$$\n",
    "\n",
    "Where $f \\left( \\cdot \\right)$ is a _smooth convex_ function and the projection onto $\\mathcal{C}$ can be calculated efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Projected Gradient Descent\n",
    "\n",
    "vH = np.zeros(numCoeff)\n",
    "oProjGrad = ProxGradientDescent(vH, hGradFun, μ, 0.0, hProxFun = hProjFun, useAccel = False)\n",
    "lH = oProjGrad.ApplyIterations(numIterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Analysis\n",
    "\n",
    "objValRef   = hObjFun(vHRef)\n",
    "vObjVal     = np.empty(numIterations)\n",
    "vArgErr     = np.empty(numIterations)\n",
    "\n",
    "for ii in range(numIterations):\n",
    "    vObjVal[ii] = hObjFun(lH[ii])\n",
    "    vArgErr[ii] = np.linalg.norm(lH[ii] - vHRef)\n",
    "\n",
    "vObjVal = 20 * np.log10(np.abs(vObjVal - objValRef) / max(np.abs(objValRef), np.sqrt(np.spacing(1.0))))\n",
    "vArgErr = 20 * np.log10(np.abs(vArgErr) / max(np.linalg.norm(vHRef), np.sqrt(np.spacing(1.0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (12, 6))\n",
    "hA.plot(range(numIterations), vObjVal, lw = 2, label = 'Objective Function')\n",
    "hA.plot(range(numIterations), vArgErr, lw = 2, label = 'Argument Error')\n",
    "hA.set_xlabel('Iteration Index')\n",
    "hA.set_ylabel('Relative Error [dB]')\n",
    "hA.set_title('Projected Gradient Convergence')\n",
    "\n",
    "hA.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Why do we have this dip in the graph and then up? Think about the reference.\n",
    "* <font color='red'>(**?**)</font> Solve the closed form solution for the Least Squares with Equality Constraints.   \n",
    "  Write the Normal Equations of the Lagrangian and Constraints as a combined linear system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
