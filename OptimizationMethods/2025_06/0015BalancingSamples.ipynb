{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Fixel Algorithms](https://fixelalgorithms.co/images/CCExt.png)](https://fixelalgorithms.gitlab.io)\n",
    "\n",
    "# Optimization Methods\n",
    "\n",
    "## Convex Optimization - Constrained Optimization - Balancing Classes for Machine Learning Training \n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 17/07/2025 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/AIProgram/2024_02/0002PointLine.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:52:07.921383Z",
     "start_time": "2022-02-02T17:52:07.649130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Optimization\n",
    "import cvxpy as cp\n",
    "\n",
    "# Miscellaneous\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Typing\n",
    "from typing import List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought.\n",
    "\n",
    "Code Notations:\n",
    "\n",
    "```python\n",
    "someVar    = 2; #<! Notation for a variable\n",
    "vVector    = np.random.rand(4) #<! Notation for 1D array\n",
    "mMatrix    = np.random.rand(4, 3) #<! Notation for 2D array\n",
    "tTensor    = np.random.rand(4, 3, 2, 3) #<! Notation for nD array (Tensor)\n",
    "tuTuple    = (1, 2, 3) #<! Notation for a tuple\n",
    "lList      = [1, 2, 3] #<! Notation for a list\n",
    "dDict      = {1: 3, 2: 2, 3: 1} #<! Notation for a dictionary\n",
    "oObj       = MyClass() #<! Notation for an object\n",
    "dfData     = pd.DataFrame() #<! Notation for a data frame\n",
    "dsData     = pd.Series() #<! Notation for a series\n",
    "hObj       = plt.Axes() #<! Notation for an object / handler / function handler\n",
    "```\n",
    "\n",
    "### Code Exercise\n",
    "\n",
    " - Single line fill\n",
    "\n",
    "```python\n",
    "valToFill = ???\n",
    "```\n",
    "\n",
    " - Multi Line to Fill (At least one)\n",
    "\n",
    " ```python\n",
    " # You need to start writing\n",
    " ?????\n",
    " ```\n",
    "\n",
    " - Section to Fill\n",
    "\n",
    "```python\n",
    "#===========================Fill This===========================#\n",
    "# 1. Explanation about what to do.\n",
    "# !! Remarks to follow / take under consideration.\n",
    "mX = ???\n",
    "\n",
    "?????\n",
    "#===============================================================#\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# Matplotlib default color palette\n",
    "lMatPltLibclr = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "# sns.set_palette(\"tab10\")\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "FIG_SIZE_DEF    = (8, 8)\n",
    "ELM_SIZE_DEF    = 50\n",
    "CLASS_COLOR     = ('b', 'r')\n",
    "EDGE_COLOR      = 'k'\n",
    "MARKER_SIZE_DEF = 10\n",
    "LINE_WIDTH_DEF  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def DisplayClassBalance(vClassBalance: np.ndarray, *, figSize: Tuple[float, float] = (6.0, 6.0), hA: Optional[plt.Axes] = None) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = figSize)\n",
    "    \n",
    "    numClasses = len(vClassBalance)\n",
    "    \n",
    "    hA.bar(np.arange(numClasses), vClassBalance, width = 0.85)\n",
    "    hA.set_xlabel('Class Index')\n",
    "    hA.set_ylabel('Number of Samples')\n",
    "    hA.set_title('Class Balance')\n",
    "\n",
    "    return hA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balancing in Machine Learning\n",
    "\n",
    "### Balanced and Imbalanced Data Set\n",
    "\n",
    "The _Classification_ task in _Machine Learning_ by default assumes balanced data.  \n",
    "Namely, the number of samples per _Class_ is similar among classes.\n",
    "\n",
    "<img src=\"https://i.imgur.com/PytqYsy.png\" width=\"750\"/>\n",
    "<!-- ![](https://i.imgur.com/PytqYsy.png) -->\n",
    "<!-- ![](https://i.postimg.cc/3RwJGjhv/68e7d3ca-1f1c-4ea4-a56d-ac0b0116306f.png) -->\n",
    "\n",
    "* <font color='brown'>(**#**)</font> While balanced data is the ideal, there are methods to handle imbalanced data in Machine Learning Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Data Set by Weighted Oversampling  \n",
    "\n",
    "Let $\\boldsymbol{a}_{i} \\in \\mathbb{R}^{n}$ be the vector of class appearances in the data sample $i$.  \n",
    "The sample (For example an image in _Object Detection_ task) contains different numbers of examples per class.  \n",
    "This case, for $m$ samples and $n$ classes can be represented by a matrix $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$:\n",
    "\n",
    " * Each row is the number of class examples per sample.\n",
    " * Each column is the number of examples of a certain class per sample.\n",
    "\n",
    "Assuming one may _oversample_ each sample (Row), with a factor ${x}_{i}$ then the factoring can be formulated as:\n",
    "\n",
    "$$ \\boldsymbol{y} = \\boldsymbol{A}^{T} \\boldsymbol{x}, \\; \\boldsymbol{x} \\in \\mathbb{N}_{+}^{m} $$\n",
    "\n",
    "Namely, the value ${x}_{i} \\in \\mathbb{N}_{+}$ is the number of copies of the sample $i$ in the balanced data set.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> A better way the an actually oversample / replicate the sample is to increase its weight or increase the class weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Formulation of the Problem\n",
    "\n",
    "Conceptually the problem is given by:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\arg \\min_{\\boldsymbol{x}} \\quad & R \\left( \\boldsymbol{y} \\right) \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\boldsymbol{A}^{T} \\boldsymbol{x} & = \\boldsymbol{y} \\\\\n",
    "\\boldsymbol{x} & \\geq \\boldsymbol{1}\n",
    "\\end{aligned}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where $R \\left( \\cdot \\right)$ is a function which penalizes high variance vectors / promotes near constant vectors.\n",
    "\n",
    "This notebook explores different formulations to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of Vector Unevenness / Curvature\n",
    "\n",
    "In order force nearly constant vector one need to define $R \\left( \\cdot \\right)$ to measure the _Unevenness_ (_Curvature_ / _Roughness_) of the vector.  \n",
    "This section introduces several ideas (Limited to _Convex_ functions):\n",
    "\n",
    " - Variance - $\\frac{1}{n} \\sum_{i = 1}^{n} {\\left( {y}_{i} - \\frac{1}{n} \\sum_{j = 1}^{n} {y}_{j} \\right)}^{2}$  \n",
    "   Can be also formulated as $\\frac{1}{2 {n}^{2}} \\sum_{i, j = 1}^{n} {\\left( {y}_{i} - {y}_{j} \\right)}^{2}$.\n",
    " - Mean Absolute Deviation - $\\frac{1}{n} \\sum_{i = 1}^{n} \\left| {y}_{i} - \\frac{1}{n} \\sum_{j = 1}^{n} {y}_{j} \\right|$  \n",
    "   Can be formulated as a _Linear PRogramming_ problem.\n",
    " - Maximum Absolute Deviation - ${\\left\\| \\boldsymbol{y} - \\bar{y} \\boldsymbol{1} \\right\\|}_{\\infty}$  \n",
    "   Where $\\bar{y} = \\frac{1}{n} \\sum_{j = 1}^{n} {y}_{j}$.  \n",
    "   Can be formulated as a _Linear PRogramming_ problem.\n",
    " - Huber based Deviation - $\\frac{1}{n} \\sum_{i = 1}^{n} {\\delta}^{2} \\left( \\sqrt{ 1 + \\frac{ {\\left( {y}_{i} - \\bar{y} \\right)}^{2} }{{\\delta}^{2}} } - 1 \\right)$  \n",
    "   Outliers robust Variance (Combines _Variance_ and _Mean Absolute Deviation_).\n",
    " - Invariance to Filtration by Mean Filter - ${\\left\\| \\boldsymbol{C} \\boldsymbol{y} - \\boldsymbol{y} \\right\\|}_{2}^{2}$  \n",
    "   Where ${C}_{i, j} = \\frac{1}{n}$.  \n",
    "   The norm can be replaces with the ${L}_{1}$ or ${L}_{\\infty}$ norm.\n",
    " - Relative Entropy to Uniform Distribution - $\\operatorname{D}_{KL} \\left( \\boldsymbol{y}, \\boldsymbol{u} \\right) = \\sum_{i = 1}^{n} {y}_{i} \\log \\left( \\frac{ {y}_{i} }{ 1 / n } \\right) = \\log \\left( n \\right) + \\sum_{i = 1}^{n} {y}_{i} \\log \\left( {y}_{i} \\right)$  \n",
    "   Requires a discrete distribution. Yet the _Entropy Measure_ can be used and maximized.  \n",
    "   See [Better Intuition for Information Theory](https://www.blackhc.net/blog/2019/better-intuition-for-information-theory), [Less Wrong - Six Intuitions for KL Divergence](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data\n",
    "dataFileUrl        = r'https://raw.githubusercontent.com/FixelAlgorithmsTeam/FixelCourses/refs/heads/master/DataSets/ClassBalancing.csv'\n",
    "numSamplesDiscrete = 10_000\n",
    "\n",
    "# Model\n",
    "upperbound = 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "\n",
    "This section loads a real world case (Credit to Michael Kaster) as a sample case for the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:53:07.834772Z",
     "start_time": "2022-02-02T17:53:07.448832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data of Real World Case\n",
    "\n",
    "mA = np.loadtxt(dataFileUrl, dtype = np.float64, delimiter = ',')\n",
    "\n",
    "print(f'The Data Shape            : {mA.shape}')\n",
    "print(f'The Data Number of Samples: {mA.shape[0]}')\n",
    "print(f'The Data Number of Classes: {mA.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Class Balance\n",
    "\n",
    "numSamples = mA.shape[0]\n",
    "numClasses = mA.shape[1]\n",
    "\n",
    "hA = DisplayClassBalance(np.sum(mA, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation 001 - Discrete\n",
    "\n",
    "Since the values of ${x}_{i}$ stands for counting one could force the problem to be a _Discrete Optimization_ problem.  \n",
    "In order to make it feasible, one can limit itself to cases where the objective, defined by $R \\left( \\cdot \\right)$, can be formulated using _Integer Linear Programming_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 001\n",
    "\n",
    "Using the _Maximum Absolute Deviation_ the problem is given by:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\arg \\min_{\\boldsymbol{x} \\in \\mathbb{N}_{+}^{m}, \\mu} \\quad & {\\left\\| \\boldsymbol{A}^{T} \\boldsymbol{x} - \\mu \\boldsymbol{1} \\right\\|}_{\\infty} \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\boldsymbol{x} & \\geq \\boldsymbol{1} \\\\\n",
    "\\boldsymbol{x} & \\leq u \\boldsymbol{1} \\\\\n",
    "\\frac{1}{m} \\boldsymbol{1}^{T} \\boldsymbol{A}^{T} \\boldsymbol{x} & = \\mu\n",
    "\\end{aligned}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This formulation also adds an upper bound to the number of copies ($u$).\n",
    "\n",
    "Formulate the problem as a _Integer Linear Programming_ (Linear objective, Linear constraints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 001\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Absolute Deviation - Original Formulation\n",
    "# Using the straight forward formulation, the problem can be solved using a convex optimization solver.\n",
    "\n",
    "def SolveDiscreteInfNormOrg( mA: np.ndarray, upBound: float ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Solve the discrete infinity norm optimization problem.\n",
    "    \n",
    "    Input:\n",
    "     mA     - Input matrix where each row represents a sample and each column represents a class.\n",
    "    upBound - Upper bound for the number of copies of the rows.\n",
    "    \n",
    "    Output:\n",
    "     vX     - Solution vector representing the number of copies of each class.\n",
    "    \n",
    "    Remarks:\n",
    "    - The problem size (number of elements in `mA`) should be relatively small.\n",
    "    \"\"\"\n",
    "    \n",
    "    numSamples = np.size(mA, 0)\n",
    "    numClasses = np.size(mA, 1)\n",
    "    \n",
    "    # Variables\n",
    "    vX = cp.Variable(numSamples, integer = True)  #<! Integer variable for class counts\n",
    "    μ  = cp.Variable(1) #<! Mean of the class counts\n",
    "\n",
    "    # Problem\n",
    "    cpObjFun = cp.Minimize(cp.norm(mA.T @ vX - μ, p = 'inf'))  #<! Objective function\n",
    "    cpConst  = [vX >= 1, vX <= upBound, cp.mean(mA.T @ vX) == μ]  #<! Constraints\n",
    "    oCvxPrb  = cp.Problem(cpObjFun, cpConst) #<! Create the convex problem instance\n",
    "    \n",
    "    # Solution\n",
    "    oCvxPrb.solve(solver = cp.HIGHS)  #<! Solve the problem\n",
    "    \n",
    "    assert (oCvxPrb.status == 'optimal'), 'The problem is not solved.'\n",
    "    \n",
    "    return vX.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Point to Minimize Sum of Squared Euclidean Distances\n",
    "\n",
    "def SolveDiscreteInfNorm( mA: np.ndarray, upBound: float ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Solve the discrete infinity norm optimization problem.\n",
    "    \n",
    "    Input:\n",
    "     mA     - Input matrix where each row represents a sample and each column represents a class.\n",
    "    upBound - Upper bound for the number of copies of the rows.\n",
    "    \n",
    "    Output:\n",
    "     vX     - Solution vector representing the number of copies of each class.\n",
    "    \n",
    "    Remarks:\n",
    "    - The problem size (number of elements in `mA`) should be relatively small.\n",
    "    \"\"\"\n",
    "    \n",
    "    numSamples = np.size(mA, 0)\n",
    "    numClasses = np.size(mA, 1)\n",
    "\n",
    "    #===========================Fill This===========================#\n",
    "    # 1. Set the optimization variables.\n",
    "    # 2. Define the objective.\n",
    "    # 3. Define the constraints.\n",
    "    # !! The solution should match the original formulation.\n",
    "    \n",
    "    # Variables\n",
    "    vX = ??? #<! Integer variable for class counts\n",
    "    μ  = ??? #<! Mean of the class counts\n",
    "    t  = ??? #<! Boundary variable for the maximum absolute deviation\n",
    "\n",
    "    # Problem\n",
    "    cpObjFun = ??? #<! Objective function\n",
    "    cpConst  = ??? #<! Constraints\n",
    "    oCvxPrb  = ??? #<! Create the convex problem instance\n",
    "    #===============================================================#\n",
    "    \n",
    "    oCvxPrb.solve(solver = cp.HIGHS)  #<! Solve the problem\n",
    "    \n",
    "    assert (oCvxPrb.status == 'optimal'), 'The problem is not solved.'\n",
    "    \n",
    "    return vX.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function Value\n",
    "\n",
    "def ObjFunMaxAbsDev( vX: np.ndarray, mA: np.ndarray ) -> float:\n",
    "\n",
    "    vY = mA.T @ vX\n",
    "    μ = np.mean(vY)\n",
    "    \n",
    "    return np.max(np.abs(vY - μ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of the Solution\n",
    "\n",
    "vXRef = SolveDiscreteInfNormOrg(mA, upBound = upperbound)\n",
    "vX    = SolveDiscreteInfNorm(mA, upBound = upperbound)\n",
    "\n",
    "assert np.allclose(vX, vXRef), 'The solutions do not match.'\n",
    "print('The solutions match.')\n",
    "\n",
    "print(f'Objective Function Value: {ObjFunMaxAbsDev(vX, mA):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Class Balance\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 4))\n",
    "hA = DisplayClassBalance(np.sum(mA, axis = 0), hA = vHa[0])\n",
    "hA.set_title(f'Original Class Balance, Objective: {ObjFunMaxAbsDev(np.ones(np.size(mA, 0)), mA):0.2f}')\n",
    "hA = DisplayClassBalance(mA.T @ vXRef, hA = vHa[1])\n",
    "hA.set_title(f'Balanced Class Balance, Objective: {ObjFunMaxAbsDev(vXRef, mA):0.2f}')\n",
    "vYlim = hA.get_ylim()\n",
    "vHa[0].set_ylim(vYlim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation 002 - Continuous\n",
    "\n",
    "One can promote flat continuous vector and use rounding to achieve discrete solution.  \n",
    "While not guaranteed to yield optimal discrete solution, it might yield good enough solution while being faster and scale better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 002\n",
    "\n",
    "Formulate the problem with the objective defined by **maximization** of the Entropy: $-\\sum_{i} {y}_{i} \\log \\left( {y}_{i} \\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 002\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Point to Minimize Sum of Squared Euclidean Distances\n",
    "\n",
    "def SolveContEntropy( mA: np.ndarray, upBound: float ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Solve the continuous entropy optimization problem.\n",
    "    Input:\n",
    "     mA     - Input matrix where each row represents a sample and each column represents a class\n",
    "    upBound - Upper bound for the number of copies of the rows.\n",
    "    Output:\n",
    "     vX     - Solution vector representing the number of copies of each class.\n",
    "    Remarks:\n",
    "     - The solution of the optimization problem should be rounded to generate a discrete solution.\n",
    "    \"\"\"\n",
    "    \n",
    "    numSamples = np.size(mA, 0)\n",
    "    numClasses = np.size(mA, 1)\n",
    "\n",
    "    #===========================Fill This===========================#\n",
    "    # 1. Set the optimization variables.\n",
    "    # 2. Define the objective.\n",
    "    # 3. Define the constraints.\n",
    "    # !! You may find `cp.entr()` useful.\n",
    "    \n",
    "    # Variables\n",
    "    vX = ??? #<! Objective variable for class counts\n",
    "    vY = ??? #<! Auxiliary variable\n",
    "\n",
    "    # Problem\n",
    "    cpObjFun = ??? #<! Objective function\n",
    "    cpConst  = ??? #<! Constraints\n",
    "    oCvxPrb  = ??? #<! Create the convex problem instance\n",
    "    #===============================================================#\n",
    "    \n",
    "    oCvxPrb.solve(solver = cp.ECOS)  #<! Solve the problem\n",
    "    \n",
    "    assert (oCvxPrb.status == 'optimal'), 'The problem is not solved.'\n",
    "    \n",
    "    return vX.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the Continuous Entropy Problem\n",
    "\n",
    "vX  = SolveDiscreteInfNorm(mA, upBound = upperbound)\n",
    "vXR = np.round(vX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function\n",
    "\n",
    "def ObjFunEntropy( vX: np.ndarray, mA: np.ndarray ) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the entropy of the class distribution.\n",
    "    \n",
    "    Input:\n",
    "     vX     - Solution vector representing the number of copies of each class.\n",
    "     mA     - Input matrix where each row represents a sample and each column represents a class.\n",
    "    \n",
    "    Output:\n",
    "     valE - The entropy value of the class distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    vY = mA.T @ vX\n",
    "    valE = sp.stats.entropy(vY)  #<! Adding a small constant to avoid log(0)\n",
    "    \n",
    "    return valE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Class Balance\n",
    "\n",
    "hF, vHa = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 4))\n",
    "hA = DisplayClassBalance(np.sum(mA, axis = 0), hA = vHa[0])\n",
    "hA.set_title(f'Original Class Balance, Objective: {ObjFunEntropy(np.ones(np.size(mA, 0)), mA):0.2f}')\n",
    "hA = DisplayClassBalance(mA.T @ vXR, hA = vHa[1])\n",
    "hA.set_title(f'Balanced Class Balance, Objective: {ObjFunEntropy(vXR, mA):0.2f}')\n",
    "vYlim = hA.get_ylim()\n",
    "vHa[0].set_ylim(vYlim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>(**?**)</font> Can the code be implemented without the _auxiliary variable_?\n",
    "* <font color='green'>(**@**)</font> Implement another Discrete Formulation of the problem.\n",
    "* <font color='green'>(**@**)</font> Implement another Continuous Formulation of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation 003 - Discrete / Continuous\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\arg \\min_{\\boldsymbol{x}, \\boldsymbol{e}, c} \\quad & \\sum_{i = 1}^{n} \\left| {e}_{i} \\right| + c \\\\\n",
    "\\text{subject to} \\quad & \\begin{aligned} \n",
    "\\boldsymbol{A}^{T} \\boldsymbol{x} + \\boldsymbol{e} & = c \\boldsymbol{1} \\\\\n",
    "c & \\geq \\min \\left( {A}^{T} \\boldsymbol{1} \\right) \\\\\n",
    "\\boldsymbol{x} & \\geq \\boldsymbol{1} \\\\\n",
    "\\boldsymbol{x} & \\leq u \\boldsymbol{1} \\\\\n",
    "\\end{aligned}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "* <font color='red'>(**?**)</font> Explain how the formulation work.  \n",
    "   Explain the roles of $c$ and $\\boldsymbol{e}$. In practice, will the constraint on $c$ be active?\n",
    "* <font color='blue'>(**!**)</font> Implement the formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalency of Variance and Pair Wise Sum Square\n",
    "# Show empirical equivalency of the _Variance_ and _Pair Wise Sum Square_.\n",
    "\n",
    "def PairWiseSumSquare( vX: np.ndarray ) -> float:\n",
    "    \"\"\"\n",
    "    Computes the sum of pairwise squared differences for a given vector `vX`.\n",
    "    \"\"\"\n",
    "    numSamples = len(vX)\n",
    "    return np.sum(np.square(vX[:, None] - vX[None, :])) / (2 * numSamples * numSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Equivalency\n",
    "numSamples = 1000\n",
    "vX = np.random.randn(numSamples)\n",
    "\n",
    "print(f'Variance: {np.mean(np.square(vX - np.mean(vX))):0.5f}')\n",
    "print(f'Sum of Pair Wise Square: {PairWiseSumSquare(vX):0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximizing Entropy Promotes Constant Vectors\n",
    "\n",
    "vX   = cp.Variable(10)\n",
    "\n",
    "cpObjFun = cp.Maximize( cp.sum(cp.entr(vX)) ) #<! Objective Function\n",
    "cpConst  = [vX >= 1.2] #<! Constraint per each sample\n",
    "oCvxPrb  = cp.Problem(cpObjFun, cpConst)   \n",
    "\n",
    "oCvxPrb.solve(solver = cp.CLARABEL) #<! Solve the problem\n",
    "\n",
    "assert (oCvxPrb.status == 'optimal'), 'The problem is not solved.'\n",
    "print('Problem is solved.')\n",
    "\n",
    "vX.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
